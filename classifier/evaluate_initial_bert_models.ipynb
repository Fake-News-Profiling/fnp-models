{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "preprocessing_path = 'C:\\\\Users\\\\joshh\\\\Desktop\\\\Uni\\\\Soton Year 3\\\\COMP3200\\\\fake-news-profiling\\\\classifier\\\\preprocessing'\n",
    "if preprocessing_path not in sys.path:\n",
    "    sys.path.insert(1, preprocessing_path)\n",
    "\n",
    "notif_path = 'C:\\\\Users\\\\joshh\\\\Desktop\\\\Uni\\\\Soton Year 3\\\\COMP3200\\\\fake-news-profiling\\\\classifier\\\\notifications'\n",
    "if notif_path not in sys.path:\n",
    "    sys.path.insert(1, notif_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import ipynb.fs.full.parse_datasets as datasets\n",
    "import ipynb.fs.full.preprocessing as pp\n",
    "import ipynb.fs.full.bert_fake_news_classifier as bclf\n",
    "from ipynb.fs.full.notif_email import send_email"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data, label_data = datasets.parse_dataset(\"datasets\", \"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "tweet_preprocessor = pp.TweetPreprocessor(\n",
    "    preprocess_funcs = [\n",
    "        pp.tag_indicators,\n",
    "        pp.replace_xml_and_html,\n",
    "        pp.replace_emojis,\n",
    "        pp.remove_punctuation,\n",
    "        pp.replace_tags,\n",
    "        pp.remove_hashtag_chars,\n",
    "        pp.replace_accented_chars,\n",
    "        pp.tag_numbers,\n",
    "        pp.remove_stopwords,\n",
    "        pp.remove_extra_spacing,\n",
    "    ])\n",
    "tweet_preprocessor.preprocess(tweet_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data_individual = tweet_preprocessor.get_individual_tweets_dataset()\n",
    "tweet_data_feed = tweet_preprocessor.get_tweet_feed_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "(tweet_train, label_train, \n",
    " tweet_val, label_val, \n",
    " tweet_test, label_test) = datasets.split_dataset(tweet_data_individual, label_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Individual Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_bert_url = \"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1\"\n",
    "bert_encoder_individual = hub.KerasLayer(\n",
    "    small_bert_url, \n",
    "    trainable=True,\n",
    ")\n",
    "\n",
    "bert_input_size_individual = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_tokenizer = bclf.BertIndividualTweetTokenizer(bert_encoder_individual, bert_input_size_individual)\n",
    "bert_model_individual = bclf.create_bert_model(bert_encoder_individual, bert_input_size_individual)\n",
    "bert_model_individual.compile(Adam(lr=1e-5), 'binary_crossentropy', ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a checkpoint for training\n",
    "checkpoint_path_individual = \"training/bert_training_individual_1/cp.ckpt\"\n",
    "\n",
    "bert_checkpoint_callback_individual = ModelCheckpoint(\n",
    "    filepath=checkpoint_path_individual,\n",
    "    save_weights_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tweet_individual_train = individual_tokenizer.tokenize_input(tweet_train)\n",
    "label_individual_train = individual_tokenizer.tokenize_labels(label_train)\n",
    "tweet_individual_val = individual_tokenizer.tokenize_input(tweet_val)\n",
    "label_individual_val = individual_tokenizer.tokenize_labels(label_val)\n",
    "tweet_individual_test = individual_tokenizer.tokenize_input(tweet_test)\n",
    "label_individual_test = individual_tokenizer.tokenize_labels(label_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding optimal hyper parameters (batch_size, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "329/329 [==============================] - 81s 246ms/step - loss: 0.6682 - accuracy: 0.5874\n",
      "Epoch 2/10\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.6340 - accuracy: 0.6392\n",
      "Epoch 3/10\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.6187 - accuracy: 0.6549\n",
      "Epoch 4/10\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.5999 - accuracy: 0.6768\n",
      "Epoch 5/10\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.5834 - accuracy: 0.6926\n",
      "Epoch 6/10\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.5652 - accuracy: 0.7097\n",
      "Epoch 7/10\n",
      "329/329 [==============================] - 81s 246ms/step - loss: 0.5473 - accuracy: 0.7217\n",
      "Epoch 8/10\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.5304 - accuracy: 0.7325\n",
      "Epoch 9/10\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.5142 - accuracy: 0.7476\n",
      "Epoch 10/10\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.4966 - accuracy: 0.7599\n",
      "141/141 [==============================] - 6s 42ms/step - loss: 0.7258 - accuracy: 0.6438\n",
      "{'batch_size': 64, 'epochs': 10, 'loss': 0.725799024105072, 'accuracy': 0.6437777876853943}\n",
      "Epoch 1/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.6675 - accuracy: 0.5849\n",
      "Epoch 2/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.6373 - accuracy: 0.6348\n",
      "Epoch 3/50\n",
      "329/329 [==============================] - 81s 248ms/step - loss: 0.6210 - accuracy: 0.6556\n",
      "Epoch 4/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.6013 - accuracy: 0.6748\n",
      "Epoch 5/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.5870 - accuracy: 0.6868\n",
      "Epoch 6/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.5705 - accuracy: 0.7022\n",
      "Epoch 7/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.5506 - accuracy: 0.7178\n",
      "Epoch 8/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.5337 - accuracy: 0.7310\n",
      "Epoch 9/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.5162 - accuracy: 0.7440\n",
      "Epoch 10/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.5007 - accuracy: 0.7552\n",
      "Epoch 11/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.4855 - accuracy: 0.7650\n",
      "Epoch 12/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.4693 - accuracy: 0.7762\n",
      "Epoch 13/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.4535 - accuracy: 0.7846\n",
      "Epoch 14/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.4432 - accuracy: 0.7926\n",
      "Epoch 15/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.4250 - accuracy: 0.8017\n",
      "Epoch 16/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.4130 - accuracy: 0.8084\n",
      "Epoch 17/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.3982 - accuracy: 0.8176\n",
      "Epoch 18/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.3882 - accuracy: 0.8230\n",
      "Epoch 19/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.3713 - accuracy: 0.8344\n",
      "Epoch 20/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.3604 - accuracy: 0.8385\n",
      "Epoch 21/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.3503 - accuracy: 0.8455\n",
      "Epoch 22/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.3419 - accuracy: 0.8488\n",
      "Epoch 23/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.3281 - accuracy: 0.8574\n",
      "Epoch 24/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.3175 - accuracy: 0.8609\n",
      "Epoch 25/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.3039 - accuracy: 0.8677\n",
      "Epoch 26/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.2986 - accuracy: 0.8721\n",
      "Epoch 27/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.2861 - accuracy: 0.8782\n",
      "Epoch 28/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.2801 - accuracy: 0.8797\n",
      "Epoch 29/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.2720 - accuracy: 0.8842\n",
      "Epoch 30/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.2623 - accuracy: 0.8892\n",
      "Epoch 31/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.2534 - accuracy: 0.8934\n",
      "Epoch 32/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.2464 - accuracy: 0.8994\n",
      "Epoch 33/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.2390 - accuracy: 0.9009\n",
      "Epoch 34/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.2288 - accuracy: 0.9050\n",
      "Epoch 35/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.2200 - accuracy: 0.9079\n",
      "Epoch 36/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.2117 - accuracy: 0.9137\n",
      "Epoch 37/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.2072 - accuracy: 0.9151\n",
      "Epoch 38/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.2022 - accuracy: 0.9154\n",
      "Epoch 39/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.1959 - accuracy: 0.9206\n",
      "Epoch 40/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.1913 - accuracy: 0.9209\n",
      "Epoch 41/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.1832 - accuracy: 0.9259\n",
      "Epoch 42/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.1751 - accuracy: 0.9272\n",
      "Epoch 43/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.1680 - accuracy: 0.9310\n",
      "Epoch 44/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.1686 - accuracy: 0.9327\n",
      "Epoch 45/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.1600 - accuracy: 0.9360\n",
      "Epoch 46/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.1538 - accuracy: 0.9382\n",
      "Epoch 47/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.1507 - accuracy: 0.9387\n",
      "Epoch 48/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.1504 - accuracy: 0.9412\n",
      "Epoch 49/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.1421 - accuracy: 0.9447\n",
      "Epoch 50/50\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.1409 - accuracy: 0.9453\n",
      "141/141 [==============================] - 6s 42ms/step - loss: 1.4172 - accuracy: 0.6007\n",
      "{'batch_size': 64, 'epochs': 50, 'loss': 1.4171788692474365, 'accuracy': 0.6006666421890259}\n",
      "Epoch 1/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.6698 - accuracy: 0.5900\n",
      "Epoch 2/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.6373 - accuracy: 0.6343\n",
      "Epoch 3/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.6187 - accuracy: 0.6573\n",
      "Epoch 4/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.6033 - accuracy: 0.6720\n",
      "Epoch 5/100\n",
      "329/329 [==============================] - 82s 248ms/step - loss: 0.5861 - accuracy: 0.6903\n",
      "Epoch 6/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.5716 - accuracy: 0.7026\n",
      "Epoch 7/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.5514 - accuracy: 0.7180\n",
      "Epoch 8/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.5372 - accuracy: 0.7263\n",
      "Epoch 9/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.5229 - accuracy: 0.7405\n",
      "Epoch 10/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.5041 - accuracy: 0.7526\n",
      "Epoch 11/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.4880 - accuracy: 0.7659\n",
      "Epoch 12/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.4755 - accuracy: 0.7714\n",
      "Epoch 13/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.4594 - accuracy: 0.7842\n",
      "Epoch 14/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.4424 - accuracy: 0.7936\n",
      "Epoch 15/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.4319 - accuracy: 0.8002\n",
      "Epoch 16/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.4131 - accuracy: 0.8091\n",
      "Epoch 17/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.4057 - accuracy: 0.8139\n",
      "Epoch 18/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.3897 - accuracy: 0.8245\n",
      "Epoch 19/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.3792 - accuracy: 0.8281\n",
      "Epoch 20/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.3696 - accuracy: 0.8358\n",
      "Epoch 21/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.3486 - accuracy: 0.8451\n",
      "Epoch 22/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.3392 - accuracy: 0.8492\n",
      "Epoch 23/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.3348 - accuracy: 0.8530\n",
      "Epoch 24/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.3168 - accuracy: 0.8631\n",
      "Epoch 25/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.3130 - accuracy: 0.8646\n",
      "Epoch 26/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.2983 - accuracy: 0.8709\n",
      "Epoch 27/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.2949 - accuracy: 0.8744\n",
      "Epoch 28/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.2815 - accuracy: 0.8796\n",
      "Epoch 29/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.2729 - accuracy: 0.8846\n",
      "Epoch 30/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.2652 - accuracy: 0.8871\n",
      "Epoch 31/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.2554 - accuracy: 0.8932\n",
      "Epoch 32/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.2456 - accuracy: 0.8962\n",
      "Epoch 33/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.2393 - accuracy: 0.8998\n",
      "Epoch 34/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.2316 - accuracy: 0.9025\n",
      "Epoch 35/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.2296 - accuracy: 0.9048\n",
      "Epoch 36/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.2193 - accuracy: 0.9088\n",
      "Epoch 37/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.2104 - accuracy: 0.9136\n",
      "Epoch 38/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.2030 - accuracy: 0.9153\n",
      "Epoch 39/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.2011 - accuracy: 0.9170\n",
      "Epoch 40/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.1846 - accuracy: 0.9250\n",
      "Epoch 41/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.1850 - accuracy: 0.9237\n",
      "Epoch 42/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.1820 - accuracy: 0.9260\n",
      "Epoch 43/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.1770 - accuracy: 0.9267\n",
      "Epoch 44/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.1655 - accuracy: 0.9324\n",
      "Epoch 45/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.1608 - accuracy: 0.9365\n",
      "Epoch 46/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.1557 - accuracy: 0.9387\n",
      "Epoch 47/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.1529 - accuracy: 0.9383\n",
      "Epoch 48/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.1469 - accuracy: 0.9421\n",
      "Epoch 49/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.1424 - accuracy: 0.9431\n",
      "Epoch 50/100\n",
      "329/329 [==============================] - 82s 248ms/step - loss: 0.1413 - accuracy: 0.9450\n",
      "Epoch 51/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.1409 - accuracy: 0.9440\n",
      "Epoch 52/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.1323 - accuracy: 0.9471\n",
      "Epoch 53/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.1336 - accuracy: 0.9481\n",
      "Epoch 54/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.1280 - accuracy: 0.9491\n",
      "Epoch 55/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.1281 - accuracy: 0.9483\n",
      "Epoch 56/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.1231 - accuracy: 0.9516\n",
      "Epoch 57/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.1142 - accuracy: 0.9564\n",
      "Epoch 58/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.1152 - accuracy: 0.9554\n",
      "Epoch 59/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.1135 - accuracy: 0.9556\n",
      "Epoch 60/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.1098 - accuracy: 0.9569\n",
      "Epoch 61/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.1027 - accuracy: 0.9608\n",
      "Epoch 62/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.1016 - accuracy: 0.9603\n",
      "Epoch 63/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.1015 - accuracy: 0.9595\n",
      "Epoch 64/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.0972 - accuracy: 0.9619\n",
      "Epoch 65/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.0984 - accuracy: 0.9616\n",
      "Epoch 66/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.0892 - accuracy: 0.9651\n",
      "Epoch 67/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.0884 - accuracy: 0.9658\n",
      "Epoch 68/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.0883 - accuracy: 0.9667\n",
      "Epoch 69/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.0846 - accuracy: 0.9663\n",
      "Epoch 70/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.0825 - accuracy: 0.9676\n",
      "Epoch 71/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.0842 - accuracy: 0.9683\n",
      "Epoch 72/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.0788 - accuracy: 0.9693\n",
      "Epoch 73/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.0842 - accuracy: 0.9679\n",
      "Epoch 74/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.0777 - accuracy: 0.9692\n",
      "Epoch 75/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.0780 - accuracy: 0.9701\n",
      "Epoch 76/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.0775 - accuracy: 0.9697\n",
      "Epoch 77/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.0753 - accuracy: 0.9705\n",
      "Epoch 78/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.0707 - accuracy: 0.9730\n",
      "Epoch 79/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.0707 - accuracy: 0.9729\n",
      "Epoch 80/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.0734 - accuracy: 0.9721\n",
      "Epoch 81/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.0686 - accuracy: 0.9716\n",
      "Epoch 82/100\n",
      "329/329 [==============================] - 81s 248ms/step - loss: 0.0675 - accuracy: 0.9730\n",
      "Epoch 83/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.0652 - accuracy: 0.9743\n",
      "Epoch 84/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.0641 - accuracy: 0.9754\n",
      "Epoch 85/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.0604 - accuracy: 0.9750\n",
      "Epoch 86/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.0631 - accuracy: 0.9756\n",
      "Epoch 87/100\n",
      "329/329 [==============================] - 81s 248ms/step - loss: 0.0632 - accuracy: 0.9757\n",
      "Epoch 88/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.0618 - accuracy: 0.9762\n",
      "Epoch 89/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.0626 - accuracy: 0.9753\n",
      "Epoch 90/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.0593 - accuracy: 0.9762\n",
      "Epoch 91/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.0558 - accuracy: 0.9779\n",
      "Epoch 92/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.0596 - accuracy: 0.9773\n",
      "Epoch 93/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.0573 - accuracy: 0.9783\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329/329 [==============================] - 81s 247ms/step - loss: 0.0514 - accuracy: 0.9796\n",
      "Epoch 95/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.0529 - accuracy: 0.9806\n",
      "Epoch 96/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.0484 - accuracy: 0.9811\n",
      "Epoch 97/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.0541 - accuracy: 0.9789\n",
      "Epoch 98/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.0518 - accuracy: 0.9798\n",
      "Epoch 99/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.0523 - accuracy: 0.9791\n",
      "Epoch 100/100\n",
      "329/329 [==============================] - 81s 247ms/step - loss: 0.0497 - accuracy: 0.9812\n",
      "141/141 [==============================] - 6s 42ms/step - loss: 2.0028 - accuracy: 0.6007\n",
      "{'batch_size': 64, 'epochs': 100, 'loss': 2.0028185844421387, 'accuracy': 0.6006666421890259}\n"
     ]
    }
   ],
   "source": [
    "results = [{'batch_size': 1, 'epochs': 10, 'loss': 1.2027349472045898, 'accuracy': 0.570888876914978}, {'batch_size': 8, 'epochs': 10, 'loss': 0.8909910321235657, 'accuracy': 0.5973333120346069}, {'batch_size': 8, 'epochs': 50, 'loss': 2.1527915000915527, 'accuracy': 0.5951111316680908}, {'batch_size': 8, 'epochs': 100, 'loss': 2.6716349124908447, 'accuracy': 0.5737777948379517}, {'batch_size': 32, 'epochs': 10, 'loss': 0.8014382719993591, 'accuracy': 0.5855555534362793}, {'batch_size': 32, 'epochs': 50, 'loss': 1.791918396949768, 'accuracy': 0.5933333039283752}, {'batch_size': 32, 'epochs': 100, 'loss': 2.2307729721069336, 'accuracy': 0.5973333120346069}]\n",
    "batch_sizes = [64]\n",
    "epochs = [10, 50, 100]\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for epoch in epochs:\n",
    "\n",
    "        # Fit the model and then evaluate\n",
    "        with tf.device('gpu:0'):\n",
    "            bert_encoder_individual_test = hub.KerasLayer(\n",
    "                small_bert_url, \n",
    "                trainable=True,\n",
    "            )\n",
    "            bert_model_individual_test = clf.create_bert_model(bert_encoder_individual_test, bert_input_size_individual)\n",
    "            bert_model_individual_test.compile(Adam(lr=1e-5), 'binary_crossentropy', ['accuracy'])\n",
    "            \n",
    "            bert_model_individual_test.fit(\n",
    "                x=tweet_individual_train, \n",
    "                y=label_individual_train, \n",
    "                batch_size=batch_size, \n",
    "                epochs=epoch,\n",
    "            )\n",
    "            \n",
    "            evaluated_results = bert_model_individual_test.evaluate(tweet_individual_val, label_individual_val)\n",
    "            results.append({\n",
    "                'batch_size': batch_size, \n",
    "                'epochs': epoch, \n",
    "                'loss': evaluated_results[0], \n",
    "                'accuracy': evaluated_results[1]\n",
    "            })\n",
    "            print(results[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 64,\n",
       " 'epochs': 10,\n",
       " 'loss': 0.725799024105072,\n",
       " 'accuracy': 0.6437777876853943}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_result = max(results, key=lambda result: result['accuracy'])\n",
    "best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "send_email(\n",
    "    f\"\"\"\n",
    "    Grid Search finished.\n",
    "    Best model: \n",
    "    > batch_size: {best_result['batch_size']}\n",
    "    > epochs: {best_result['epochs']}\n",
    "    > loss: {best_result['loss']}\n",
    "    > accuracy: {best_result['accuracy']}\n",
    "    \n",
    "    All results: {results}\n",
    "    \n",
    "    Now training model.\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [{'batch_size': 1,\n",
    "  'epochs': 10,\n",
    "  'loss': 1.2027349472045898,\n",
    "  'accuracy': 0.570888876914978},\n",
    " {'batch_size': 8,\n",
    "  'epochs': 10,\n",
    "  'loss': 0.8909910321235657,\n",
    "  'accuracy': 0.5973333120346069},\n",
    " {'batch_size': 8,\n",
    "  'epochs': 50,\n",
    "  'loss': 2.1527915000915527,\n",
    "  'accuracy': 0.5951111316680908},\n",
    " {'batch_size': 8,\n",
    "  'epochs': 100,\n",
    "  'loss': 2.6716349124908447,\n",
    "  'accuracy': 0.5737777948379517},\n",
    " {'batch_size': 32,\n",
    "  'epochs': 10,\n",
    "  'loss': 0.8014382719993591,\n",
    "  'accuracy': 0.5855555534362793},\n",
    " {'batch_size': 32,\n",
    "  'epochs': 50,\n",
    "  'loss': 1.791918396949768,\n",
    "  'accuracy': 0.5933333039283752},\n",
    " {'batch_size': 32,\n",
    "  'epochs': 100,\n",
    "  'loss': 2.2307729721069336,\n",
    "  'accuracy': 0.5973333120346069},\n",
    " {'batch_size': 64,\n",
    "  'epochs': 10,\n",
    "  'loss': 0.725799024105072,\n",
    "  'accuracy': 0.6437777876853943},\n",
    " {'batch_size': 64,\n",
    "  'epochs': 50,\n",
    "  'loss': 1.4171788692474365,\n",
    "  'accuracy': 0.6006666421890259},\n",
    " {'batch_size': 64,\n",
    "  'epochs': 100,\n",
    "  'loss': 2.0028185844421387,\n",
    "  'accuracy': 0.6006666421890259}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting with optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.6594 - accuracy: 0.6004\n",
      "Epoch 00001: saving model to training/bert_training_individual_1\\cp.ckpt\n",
      "329/329 [==============================] - 88s 266ms/step - loss: 0.6594 - accuracy: 0.6003 - val_loss: 0.6572 - val_accuracy: 0.6369\n",
      "Epoch 2/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.6308 - accuracy: 0.6431\n",
      "Epoch 00002: saving model to training/bert_training_individual_1\\cp.ckpt\n",
      "329/329 [==============================] - 87s 265ms/step - loss: 0.6309 - accuracy: 0.6430 - val_loss: 0.6558 - val_accuracy: 0.6418\n",
      "Epoch 3/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.6128 - accuracy: 0.6644\n",
      "Epoch 00003: saving model to training/bert_training_individual_1\\cp.ckpt\n",
      "329/329 [==============================] - 87s 265ms/step - loss: 0.6129 - accuracy: 0.6643 - val_loss: 0.6577 - val_accuracy: 0.6456\n",
      "Epoch 4/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.5971 - accuracy: 0.6759\n",
      "Epoch 00004: saving model to training/bert_training_individual_1\\cp.ckpt\n",
      "329/329 [==============================] - 87s 265ms/step - loss: 0.5970 - accuracy: 0.6759 - val_loss: 0.6565 - val_accuracy: 0.6407\n",
      "Epoch 5/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.5816 - accuracy: 0.6888\n",
      "Epoch 00005: saving model to training/bert_training_individual_1\\cp.ckpt\n",
      "329/329 [==============================] - 87s 265ms/step - loss: 0.5816 - accuracy: 0.6889 - val_loss: 0.6641 - val_accuracy: 0.6451\n",
      "Epoch 6/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.5617 - accuracy: 0.7079\n",
      "Epoch 00006: saving model to training/bert_training_individual_1\\cp.ckpt\n",
      "329/329 [==============================] - 87s 265ms/step - loss: 0.5618 - accuracy: 0.7078 - val_loss: 0.6865 - val_accuracy: 0.6400\n",
      "Epoch 7/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.5498 - accuracy: 0.7167\n",
      "Epoch 00007: saving model to training/bert_training_individual_1\\cp.ckpt\n",
      "329/329 [==============================] - 87s 265ms/step - loss: 0.5497 - accuracy: 0.7168 - val_loss: 0.6756 - val_accuracy: 0.6453\n",
      "Epoch 8/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.5317 - accuracy: 0.7300\n",
      "Epoch 00008: saving model to training/bert_training_individual_1\\cp.ckpt\n",
      "329/329 [==============================] - 87s 265ms/step - loss: 0.5316 - accuracy: 0.7301 - val_loss: 0.6962 - val_accuracy: 0.6389\n",
      "Epoch 9/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.5164 - accuracy: 0.7421\n",
      "Epoch 00009: saving model to training/bert_training_individual_1\\cp.ckpt\n",
      "329/329 [==============================] - 87s 265ms/step - loss: 0.5164 - accuracy: 0.7420 - val_loss: 0.7110 - val_accuracy: 0.6480\n",
      "Epoch 10/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.4997 - accuracy: 0.7554\n",
      "Epoch 00010: saving model to training/bert_training_individual_1\\cp.ckpt\n",
      "329/329 [==============================] - 87s 265ms/step - loss: 0.4997 - accuracy: 0.7554 - val_loss: 0.7152 - val_accuracy: 0.6384\n"
     ]
    }
   ],
   "source": [
    "with tf.device('gpu:0'):\n",
    "    # Fit\n",
    "    bert_model_individual.fit(\n",
    "        x=tweet_individual_train, \n",
    "        y=label_individual_train, \n",
    "        batch_size=best_result['batch_size'], \n",
    "        epochs=best_result['epochs'], \n",
    "        callbacks=[bert_checkpoint_callback_individual],\n",
    "        validation_data=(tweet_individual_val, label_individual_val),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 6s 42ms/step - loss: 0.7464 - accuracy: 0.5804\n"
     ]
    }
   ],
   "source": [
    "eval_result = bert_model_individual.evaluate(tweet_individual_test, label_individual_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "send_email(\n",
    "    f\"\"\"\n",
    "    Individual model fit finished.\n",
    "    > loss: {eval_result[0]}\n",
    "    > accuracy: {eval_result[1]}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating for each user (rather than each tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate user predictions from individual tweet data\n",
    "def calculate_user_predictions_from_individual_tweets(model, tweets, labels):\n",
    "    # Get tweets for each user\n",
    "    tweets_per_user = 100\n",
    "    user_tweets = [\n",
    "        {\n",
    "            'input_word_ids': tweets['input_word_ids'][i:i+tweets_per_user],\n",
    "            'input_mask': tweets['input_mask'][i:i+tweets_per_user],\n",
    "            'input_type_ids': tweets['input_type_ids'][i:i+tweets_per_user],\n",
    "        }\n",
    "        for i in range(0, len(tweets['input_word_ids']), tweets_per_user)\n",
    "    ]\n",
    "    user_labels = np.asarray([\n",
    "        labels[i].numpy() for i in range(0, len(labels), tweets_per_user)\n",
    "     ])\n",
    "    \n",
    "    # Evaluate each user\n",
    "    all_predictions = []\n",
    "    for user_label, user_tweet in zip(user_labels, user_tweets):\n",
    "        all_predictions.append(\n",
    "            model.predict(user_tweet).flatten()\n",
    "        )\n",
    "    \n",
    "    return np.asarray(all_predictions), user_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_true_positive(label, prediction):\n",
    "    return label == 1 and prediction == 1\n",
    "    \n",
    "def is_false_positive(label, prediction):\n",
    "    return label == 0 and prediction == 1\n",
    "\n",
    "def is_false_negative(label, prediction):\n",
    "    return label == 1 and prediction == 0 \n",
    "    \n",
    "def is_true_negative(label, prediction):\n",
    "    return label == 0 and prediction == 0\n",
    "\n",
    "# Evaluate the model, returning accuracy, recall, f1, etc\n",
    "# predictions should be of type [(label, [predictions])]\n",
    "def evaluate_model(predictions, labels):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    tn = 0\n",
    "    for prediction, label in zip(predictions, labels):\n",
    "        # Take the mean of the users predictions and compare to threshold\n",
    "        if is_true_positive(label, prediction):\n",
    "            tp += 1\n",
    "        elif is_false_positive(label, prediction):\n",
    "            fp += 1\n",
    "        elif is_false_negative(label, prediction):\n",
    "            fn += 1\n",
    "        elif is_true_negative(label, prediction):\n",
    "            tn += 1\n",
    "        else:\n",
    "            print(\"Error:\", label, prediction)\n",
    "    \n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else float(\"NaN\")\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else float(\"NaN\")\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if precision > 0 and recall > 0 else float(\"NaN\")\n",
    "            \n",
    "    return {\n",
    "        'true_positives': tp,\n",
    "        'false_positives': fp,\n",
    "        'false_negatives': fn,\n",
    "        'true_negatives': tn,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_model(trainable=True):\n",
    "    bert_encoder_individual_test = hub.KerasLayer(\n",
    "        small_bert_url, \n",
    "        trainable=trainable,\n",
    "    )\n",
    "    bert_model_individual_test = bclf.create_bert_model(bert_encoder_individual_test, bert_input_size_individual)\n",
    "    bert_model_individual_test.compile(Adam(lr=1e-5), 'binary_crossentropy', ['accuracy'])\n",
    "    return bert_encoder_individual_test, bert_model_individual_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   1/2625 [..............................] - ETA: 1:10 - loss: 0.6308 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0160s vs `on_train_batch_end` time: 0.0290s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0160s vs `on_train_batch_end` time: 0.0290s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2625/2625 [==============================] - ETA: 0s - loss: 0.6508 - accuracy: 0.6153\n",
      "Epoch 00001: saving model to training/bert_individual/batch8-epoch10-2\\cp.ckpt\n",
      "2625/2625 [==============================] - 107s 41ms/step - loss: 0.6508 - accuracy: 0.6153\n",
      "Epoch 2/10\n",
      "2625/2625 [==============================] - ETA: 0s - loss: 0.6046 - accuracy: 0.6673\n",
      "Epoch 00002: saving model to training/bert_individual/batch8-epoch10-2\\cp.ckpt\n",
      "2625/2625 [==============================] - 108s 41ms/step - loss: 0.6046 - accuracy: 0.6673\n",
      "Epoch 3/10\n",
      "2625/2625 [==============================] - ETA: 0s - loss: 0.5679 - accuracy: 0.7029\n",
      "Epoch 00003: saving model to training/bert_individual/batch8-epoch10-2\\cp.ckpt\n",
      "2625/2625 [==============================] - 107s 41ms/step - loss: 0.5679 - accuracy: 0.7029\n",
      "Epoch 4/10\n",
      "2625/2625 [==============================] - ETA: 0s - loss: 0.5316 - accuracy: 0.7358\n",
      "Epoch 00004: saving model to training/bert_individual/batch8-epoch10-2\\cp.ckpt\n",
      "2625/2625 [==============================] - 107s 41ms/step - loss: 0.5316 - accuracy: 0.7358\n",
      "Epoch 5/10\n",
      "2625/2625 [==============================] - ETA: 0s - loss: 0.5011 - accuracy: 0.7546\n",
      "Epoch 00005: saving model to training/bert_individual/batch8-epoch10-2\\cp.ckpt\n",
      "2625/2625 [==============================] - 107s 41ms/step - loss: 0.5011 - accuracy: 0.7546\n",
      "Epoch 6/10\n",
      "2625/2625 [==============================] - ETA: 0s - loss: 0.4671 - accuracy: 0.7750\n",
      "Epoch 00006: saving model to training/bert_individual/batch8-epoch10-2\\cp.ckpt\n",
      "2625/2625 [==============================] - 107s 41ms/step - loss: 0.4671 - accuracy: 0.7750\n",
      "Epoch 7/10\n",
      "2625/2625 [==============================] - ETA: 0s - loss: 0.4400 - accuracy: 0.7923\n",
      "Epoch 00007: saving model to training/bert_individual/batch8-epoch10-2\\cp.ckpt\n",
      "2625/2625 [==============================] - 107s 41ms/step - loss: 0.4400 - accuracy: 0.7923\n",
      "Epoch 8/10\n",
      "2625/2625 [==============================] - ETA: 0s - loss: 0.4087 - accuracy: 0.8102\n",
      "Epoch 00008: saving model to training/bert_individual/batch8-epoch10-2\\cp.ckpt\n",
      "2625/2625 [==============================] - 107s 41ms/step - loss: 0.4087 - accuracy: 0.8102\n",
      "Epoch 9/10\n",
      "2625/2625 [==============================] - ETA: 0s - loss: 0.3807 - accuracy: 0.8289\n",
      "Epoch 00009: saving model to training/bert_individual/batch8-epoch10-2\\cp.ckpt\n",
      "2625/2625 [==============================] - 107s 41ms/step - loss: 0.3807 - accuracy: 0.8289\n",
      "Epoch 10/10\n",
      "2625/2625 [==============================] - ETA: 0s - loss: 0.3548 - accuracy: 0.8443\n",
      "Epoch 00010: saving model to training/bert_individual/batch8-epoch10-2\\cp.ckpt\n",
      "2625/2625 [==============================] - 107s 41ms/step - loss: 0.3548 - accuracy: 0.8443\n",
      "Epoch 1/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.6614 - accuracy: 0.6000\n",
      "Epoch 00001: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.6613 - accuracy: 0.6000\n",
      "Epoch 2/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.6254 - accuracy: 0.6505\n",
      "Epoch 00002: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.6254 - accuracy: 0.6505\n",
      "Epoch 3/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.5992 - accuracy: 0.6759\n",
      "Epoch 00003: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.5991 - accuracy: 0.6759\n",
      "Epoch 4/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.5774 - accuracy: 0.6946\n",
      "Epoch 00004: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.5775 - accuracy: 0.6945\n",
      "Epoch 5/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.5550 - accuracy: 0.7134\n",
      "Epoch 00005: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.5549 - accuracy: 0.7135\n",
      "Epoch 6/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.5297 - accuracy: 0.7307\n",
      "Epoch 00006: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.5297 - accuracy: 0.7307\n",
      "Epoch 7/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.5085 - accuracy: 0.7505\n",
      "Epoch 00007: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.5085 - accuracy: 0.7505\n",
      "Epoch 8/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.4907 - accuracy: 0.7606\n",
      "Epoch 00008: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.4907 - accuracy: 0.7607\n",
      "Epoch 9/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.4708 - accuracy: 0.7731\n",
      "Epoch 00009: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.4707 - accuracy: 0.7731\n",
      "Epoch 10/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.4483 - accuracy: 0.7924\n",
      "Epoch 00010: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.4483 - accuracy: 0.7924\n",
      "Epoch 11/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.4309 - accuracy: 0.8037\n",
      "Epoch 00011: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.4310 - accuracy: 0.8037\n",
      "Epoch 12/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.4132 - accuracy: 0.8134\n",
      "Epoch 00012: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.4132 - accuracy: 0.8133\n",
      "Epoch 13/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.3969 - accuracy: 0.8208\n",
      "Epoch 00013: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.3971 - accuracy: 0.8207\n",
      "Epoch 14/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.3808 - accuracy: 0.8285\n",
      "Epoch 00014: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.3808 - accuracy: 0.8284\n",
      "Epoch 15/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.3649 - accuracy: 0.8409\n",
      "Epoch 00015: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.3648 - accuracy: 0.8410\n",
      "Epoch 16/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.3509 - accuracy: 0.8427\n",
      "Epoch 00016: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.3510 - accuracy: 0.8427\n",
      "Epoch 17/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.3288 - accuracy: 0.8554\n",
      "Epoch 00017: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.3287 - accuracy: 0.8554\n",
      "Epoch 18/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.3209 - accuracy: 0.8613\n",
      "Epoch 00018: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.3209 - accuracy: 0.8613\n",
      "Epoch 19/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.3050 - accuracy: 0.8691\n",
      "Epoch 00019: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.3050 - accuracy: 0.8691\n",
      "Epoch 20/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.2915 - accuracy: 0.8760\n",
      "Epoch 00020: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.2917 - accuracy: 0.8759\n",
      "Epoch 21/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.2766 - accuracy: 0.8825\n",
      "Epoch 00021: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.2766 - accuracy: 0.8825\n",
      "Epoch 22/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.2652 - accuracy: 0.8904\n",
      "Epoch 00022: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.2651 - accuracy: 0.8904\n",
      "Epoch 23/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.2529 - accuracy: 0.8950\n",
      "Epoch 00023: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.2531 - accuracy: 0.8949\n",
      "Epoch 24/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.2400 - accuracy: 0.9009\n",
      "Epoch 00024: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.2400 - accuracy: 0.9009\n",
      "Epoch 25/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.2302 - accuracy: 0.9038\n",
      "Epoch 00025: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.2302 - accuracy: 0.9037\n",
      "Epoch 26/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.2240 - accuracy: 0.9079\n",
      "Epoch 00026: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.2239 - accuracy: 0.9079\n",
      "Epoch 27/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.2133 - accuracy: 0.9137\n",
      "Epoch 00027: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.2132 - accuracy: 0.9138\n",
      "Epoch 28/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.1972 - accuracy: 0.9205\n",
      "Epoch 00028: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.1972 - accuracy: 0.9205\n",
      "Epoch 29/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.1896 - accuracy: 0.9246\n",
      "Epoch 00029: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.1895 - accuracy: 0.9246\n",
      "Epoch 30/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.1812 - accuracy: 0.9278\n",
      "Epoch 00030: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.1812 - accuracy: 0.9277\n",
      "Epoch 31/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.1708 - accuracy: 0.9303\n",
      "Epoch 00031: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.1709 - accuracy: 0.9303\n",
      "Epoch 32/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.1697 - accuracy: 0.9320\n",
      "Epoch 00032: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.1698 - accuracy: 0.9319\n",
      "Epoch 33/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.1574 - accuracy: 0.9384\n",
      "Epoch 00033: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.1574 - accuracy: 0.9384\n",
      "Epoch 34/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.1513 - accuracy: 0.9406\n",
      "Epoch 00034: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.1513 - accuracy: 0.9406\n",
      "Epoch 35/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.1479 - accuracy: 0.9419\n",
      "Epoch 00035: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.1479 - accuracy: 0.9419\n",
      "Epoch 36/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.1405 - accuracy: 0.9440\n",
      "Epoch 00036: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.1405 - accuracy: 0.9440\n",
      "Epoch 37/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.1320 - accuracy: 0.9489\n",
      "Epoch 00037: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.1320 - accuracy: 0.9489\n",
      "Epoch 38/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.1254 - accuracy: 0.9516\n",
      "Epoch 00038: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.1255 - accuracy: 0.9516\n",
      "Epoch 39/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.1245 - accuracy: 0.9512\n",
      "Epoch 00039: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 133ms/step - loss: 0.1245 - accuracy: 0.9512\n",
      "Epoch 40/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.1187 - accuracy: 0.9540\n",
      "Epoch 00040: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.1187 - accuracy: 0.9540\n",
      "Epoch 41/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.1086 - accuracy: 0.9570\n",
      "Epoch 00041: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 91s 138ms/step - loss: 0.1085 - accuracy: 0.9570\n",
      "Epoch 42/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.1100 - accuracy: 0.9570\n",
      "Epoch 00042: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.1100 - accuracy: 0.9570\n",
      "Epoch 43/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.1025 - accuracy: 0.9588\n",
      "Epoch 00043: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.1024 - accuracy: 0.9589\n",
      "Epoch 44/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.1009 - accuracy: 0.9606\n",
      "Epoch 00044: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.1009 - accuracy: 0.9606\n",
      "Epoch 45/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0961 - accuracy: 0.9629\n",
      "Epoch 00045: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0961 - accuracy: 0.9629\n",
      "Epoch 46/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0965 - accuracy: 0.9626\n",
      "Epoch 00046: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0965 - accuracy: 0.9626\n",
      "Epoch 47/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0904 - accuracy: 0.9653\n",
      "Epoch 00047: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0904 - accuracy: 0.9653\n",
      "Epoch 48/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0844 - accuracy: 0.9676\n",
      "Epoch 00048: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0844 - accuracy: 0.9676\n",
      "Epoch 49/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0836 - accuracy: 0.9682\n",
      "Epoch 00049: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0836 - accuracy: 0.9682\n",
      "Epoch 50/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0815 - accuracy: 0.9707\n",
      "Epoch 00050: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0816 - accuracy: 0.9706\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "656/657 [============================>.] - ETA: 0s - loss: 0.0753 - accuracy: 0.9708\n",
      "Epoch 00051: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0753 - accuracy: 0.9708\n",
      "Epoch 52/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0790 - accuracy: 0.9698\n",
      "Epoch 00052: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0790 - accuracy: 0.9698\n",
      "Epoch 53/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0745 - accuracy: 0.9726\n",
      "Epoch 00053: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0745 - accuracy: 0.9726\n",
      "Epoch 54/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0681 - accuracy: 0.9737\n",
      "Epoch 00054: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0681 - accuracy: 0.9737\n",
      "Epoch 55/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0699 - accuracy: 0.9730\n",
      "Epoch 00055: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0699 - accuracy: 0.9730\n",
      "Epoch 56/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0684 - accuracy: 0.9754\n",
      "Epoch 00056: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0684 - accuracy: 0.9754\n",
      "Epoch 57/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0651 - accuracy: 0.9764\n",
      "Epoch 00057: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0651 - accuracy: 0.9764\n",
      "Epoch 58/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0659 - accuracy: 0.9765\n",
      "Epoch 00058: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0659 - accuracy: 0.9764\n",
      "Epoch 59/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0642 - accuracy: 0.9752\n",
      "Epoch 00059: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0641 - accuracy: 0.9752\n",
      "Epoch 60/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0608 - accuracy: 0.9773\n",
      "Epoch 00060: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0608 - accuracy: 0.9773\n",
      "Epoch 61/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0574 - accuracy: 0.9780\n",
      "Epoch 00061: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0574 - accuracy: 0.9780\n",
      "Epoch 62/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0578 - accuracy: 0.9790\n",
      "Epoch 00062: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0580 - accuracy: 0.9790\n",
      "Epoch 63/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0542 - accuracy: 0.9801\n",
      "Epoch 00063: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0543 - accuracy: 0.9800\n",
      "Epoch 64/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0560 - accuracy: 0.9801\n",
      "Epoch 00064: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0560 - accuracy: 0.9801\n",
      "Epoch 65/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0532 - accuracy: 0.9796\n",
      "Epoch 00065: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0534 - accuracy: 0.9795\n",
      "Epoch 66/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0523 - accuracy: 0.9798\n",
      "Epoch 00066: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0523 - accuracy: 0.9798\n",
      "Epoch 67/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0518 - accuracy: 0.9804\n",
      "Epoch 00067: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0518 - accuracy: 0.9804\n",
      "Epoch 68/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0511 - accuracy: 0.9804\n",
      "Epoch 00068: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0511 - accuracy: 0.9804\n",
      "Epoch 69/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0470 - accuracy: 0.9824\n",
      "Epoch 00069: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0470 - accuracy: 0.9824\n",
      "Epoch 70/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0453 - accuracy: 0.9832\n",
      "Epoch 00070: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0453 - accuracy: 0.9831\n",
      "Epoch 71/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0449 - accuracy: 0.9832\n",
      "Epoch 00071: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0449 - accuracy: 0.9832\n",
      "Epoch 72/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0427 - accuracy: 0.9840\n",
      "Epoch 00072: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0426 - accuracy: 0.9840\n",
      "Epoch 73/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0450 - accuracy: 0.9840\n",
      "Epoch 00073: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0450 - accuracy: 0.9840\n",
      "Epoch 74/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0420 - accuracy: 0.9847\n",
      "Epoch 00074: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0420 - accuracy: 0.9847\n",
      "Epoch 75/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0425 - accuracy: 0.9846\n",
      "Epoch 00075: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0425 - accuracy: 0.9846\n",
      "Epoch 76/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0423 - accuracy: 0.9840\n",
      "Epoch 00076: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0423 - accuracy: 0.9840\n",
      "Epoch 77/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0385 - accuracy: 0.9856\n",
      "Epoch 00077: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0385 - accuracy: 0.9856\n",
      "Epoch 78/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0376 - accuracy: 0.9857\n",
      "Epoch 00078: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0376 - accuracy: 0.9857\n",
      "Epoch 79/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0410 - accuracy: 0.9848\n",
      "Epoch 00079: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0409 - accuracy: 0.9848\n",
      "Epoch 80/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0364 - accuracy: 0.9869\n",
      "Epoch 00080: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0364 - accuracy: 0.9869\n",
      "Epoch 81/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0344 - accuracy: 0.9862\n",
      "Epoch 00081: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0343 - accuracy: 0.9862\n",
      "Epoch 82/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0374 - accuracy: 0.9861\n",
      "Epoch 00082: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0374 - accuracy: 0.9861\n",
      "Epoch 83/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0368 - accuracy: 0.9868\n",
      "Epoch 00083: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0367 - accuracy: 0.9868\n",
      "Epoch 84/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0342 - accuracy: 0.9875\n",
      "Epoch 00084: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0342 - accuracy: 0.9875\n",
      "Epoch 85/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0324 - accuracy: 0.9885\n",
      "Epoch 00085: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0324 - accuracy: 0.9885\n",
      "Epoch 86/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0355 - accuracy: 0.9860\n",
      "Epoch 00086: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0355 - accuracy: 0.9860\n",
      "Epoch 87/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0347 - accuracy: 0.9867\n",
      "Epoch 00087: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0347 - accuracy: 0.9867\n",
      "Epoch 88/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0343 - accuracy: 0.9870\n",
      "Epoch 00088: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0343 - accuracy: 0.9870\n",
      "Epoch 89/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0323 - accuracy: 0.9878\n",
      "Epoch 00089: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 87s 132ms/step - loss: 0.0323 - accuracy: 0.9878\n",
      "Epoch 90/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0310 - accuracy: 0.9884\n",
      "Epoch 00090: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 88s 133ms/step - loss: 0.0311 - accuracy: 0.9883\n",
      "Epoch 91/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0323 - accuracy: 0.9889\n",
      "Epoch 00091: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 89s 135ms/step - loss: 0.0323 - accuracy: 0.9889\n",
      "Epoch 92/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0319 - accuracy: 0.9880\n",
      "Epoch 00092: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 88s 135ms/step - loss: 0.0319 - accuracy: 0.9880\n",
      "Epoch 93/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0310 - accuracy: 0.9880\n",
      "Epoch 00093: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0310 - accuracy: 0.9880\n",
      "Epoch 94/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0292 - accuracy: 0.9889\n",
      "Epoch 00094: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0292 - accuracy: 0.9889\n",
      "Epoch 95/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0329 - accuracy: 0.9877\n",
      "Epoch 00095: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0329 - accuracy: 0.9877\n",
      "Epoch 96/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0291 - accuracy: 0.9888\n",
      "Epoch 00096: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0291 - accuracy: 0.9888\n",
      "Epoch 97/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0285 - accuracy: 0.9898\n",
      "Epoch 00097: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 88s 135ms/step - loss: 0.0285 - accuracy: 0.9898\n",
      "Epoch 98/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0322 - accuracy: 0.9880\n",
      "Epoch 00098: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0321 - accuracy: 0.9880\n",
      "Epoch 99/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0308 - accuracy: 0.9885\n",
      "Epoch 00099: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0308 - accuracy: 0.9885\n",
      "Epoch 100/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0274 - accuracy: 0.9886\n",
      "Epoch 00100: saving model to training/bert_individual/batch32-epoch100-2\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0274 - accuracy: 0.9886\n",
      "Epoch 1/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.6753 - accuracy: 0.5743\n",
      "Epoch 00001: saving model to training/bert_individual/batch64-epoch10-2\\cp.ckpt\n",
      "329/329 [==============================] - 82s 248ms/step - loss: 0.6753 - accuracy: 0.5743\n",
      "Epoch 2/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.6466 - accuracy: 0.6212\n",
      "Epoch 00002: saving model to training/bert_individual/batch64-epoch10-2\\cp.ckpt\n",
      "329/329 [==============================] - 82s 249ms/step - loss: 0.6467 - accuracy: 0.6210\n",
      "Epoch 3/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.6282 - accuracy: 0.6424\n",
      "Epoch 00003: saving model to training/bert_individual/batch64-epoch10-2\\cp.ckpt\n",
      "329/329 [==============================] - 82s 249ms/step - loss: 0.6283 - accuracy: 0.6422\n",
      "Epoch 4/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.6113 - accuracy: 0.6607\n",
      "Epoch 00004: saving model to training/bert_individual/batch64-epoch10-2\\cp.ckpt\n",
      "329/329 [==============================] - 82s 249ms/step - loss: 0.6114 - accuracy: 0.6607\n",
      "Epoch 5/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.5930 - accuracy: 0.6788\n",
      "Epoch 00005: saving model to training/bert_individual/batch64-epoch10-2\\cp.ckpt\n",
      "329/329 [==============================] - 82s 249ms/step - loss: 0.5929 - accuracy: 0.6789\n",
      "Epoch 6/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.5728 - accuracy: 0.6973\n",
      "Epoch 00006: saving model to training/bert_individual/batch64-epoch10-2\\cp.ckpt\n",
      "329/329 [==============================] - 82s 249ms/step - loss: 0.5729 - accuracy: 0.6972\n",
      "Epoch 7/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.5570 - accuracy: 0.7108\n",
      "Epoch 00007: saving model to training/bert_individual/batch64-epoch10-2\\cp.ckpt\n",
      "329/329 [==============================] - 82s 249ms/step - loss: 0.5569 - accuracy: 0.7107\n",
      "Epoch 8/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.5393 - accuracy: 0.7217\n",
      "Epoch 00008: saving model to training/bert_individual/batch64-epoch10-2\\cp.ckpt\n",
      "329/329 [==============================] - 82s 249ms/step - loss: 0.5393 - accuracy: 0.7217\n",
      "Epoch 9/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.5250 - accuracy: 0.7341\n",
      "Epoch 00009: saving model to training/bert_individual/batch64-epoch10-2\\cp.ckpt\n",
      "329/329 [==============================] - 82s 249ms/step - loss: 0.5249 - accuracy: 0.7341\n",
      "Epoch 10/10\n",
      "328/329 [============================>.] - ETA: 0s - loss: 0.5073 - accuracy: 0.7480\n",
      "Epoch 00010: saving model to training/bert_individual/batch64-epoch10-2\\cp.ckpt\n",
      "329/329 [==============================] - 82s 249ms/step - loss: 0.5073 - accuracy: 0.7481\n"
     ]
    }
   ],
   "source": [
    "# Train and save best individual models\n",
    "pairs = [(8, 10), (32, 100), (64, 10)]\n",
    "\n",
    "for batch_size, epoch in pairs:\n",
    "    with tf.device('gpu:0'):\n",
    "        # Create checkpoint\n",
    "        checkpoint = ModelCheckpoint(\n",
    "            filepath=f\"training/bert_individual/batch{batch_size}-epoch{epoch}-2/cp.ckpt\",\n",
    "            save_weights_only=True,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Create model\n",
    "        bert_encoder_individual_test = hub.KerasLayer(\n",
    "            small_bert_url, \n",
    "            trainable=True,\n",
    "        )\n",
    "        bert_model_individual_test = bclf.create_bert_model(bert_encoder_individual_test, bert_input_size_individual)\n",
    "        bert_model_individual_test.compile(Adam(lr=1e-5), 'binary_crossentropy', ['accuracy'])\n",
    "\n",
    "        bert_model_individual_test.fit(\n",
    "            x=tweet_individual_train, \n",
    "            y=label_individual_train, \n",
    "            batch_size=batch_size, \n",
    "            epochs=epoch, \n",
    "            callbacks=[checkpoint],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "send_email(\"Finished training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifying BERT predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(clf, X_train, y_train, X_val, y_val, batch_size, epochs):\n",
    "    clf.fit(X_train, y_train)\n",
    "    predictions = clf.predict(X_val)\n",
    "    return {\n",
    "        'batch_size': batch_size,\n",
    "        'epochs': epochs,\n",
    "        'predictions_val': predictions,\n",
    "        'labels_val': y_val,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights for batch_size:8, epochs: 10\n",
      "Training LR\n",
      "Training LR sorted\n",
      "Training SVM\n",
      "Training SVM sorted\n",
      "Loading weights for batch_size:32, epochs: 100\n",
      "Training LR\n",
      "Training LR sorted\n",
      "Training SVM\n",
      "Training SVM sorted\n",
      "Loading weights for batch_size:64, epochs: 10\n",
      "Training LR\n",
      "Training LR sorted\n",
      "Training SVM\n",
      "Training SVM sorted\n"
     ]
    }
   ],
   "source": [
    "pairs = [(8, 10), (32, 100), (64, 10)]\n",
    "predictions = {\n",
    "    'logistic_regression': [],\n",
    "    'logistic_regression_sorted': [],\n",
    "    'svm': [],\n",
    "    'svm_sorted': [],\n",
    "}\n",
    "\n",
    "for batch_size, epoch in pairs:\n",
    "    # Load the BERT model\n",
    "    print(f\"Loading weights for batch_size:{batch_size}, epochs: {epoch}\")\n",
    "    encoder, model = create_test_model(trainable=False)\n",
    "    model.load_weights(\n",
    "        f\"training/bert_individual/batch{batch_size}-epoch{epoch}-2/cp.ckpt\"\n",
    "    ).expect_partial()\n",
    "    \n",
    "    # Predict training and validation set data\n",
    "    X_train, y_train = calculate_user_predictions_from_individual_tweets(\n",
    "        model, \n",
    "        tweet_individual_train, \n",
    "        label_individual_train,\n",
    "    )\n",
    "    X_val, y_val = calculate_user_predictions_from_individual_tweets(\n",
    "        model, \n",
    "        tweet_individual_val, \n",
    "        label_individual_val,\n",
    "    )\n",
    "    \n",
    "    # Train Logistic Regression model\n",
    "    print(\"Training LR\")\n",
    "    predictions['logistic_regression'].append(\n",
    "        train_classifier(\n",
    "            LogisticRegression(), \n",
    "            X_train, \n",
    "            y_train, \n",
    "            X_val, \n",
    "            y_val, \n",
    "            batch_size, \n",
    "            epoch\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Train Logistic Regression when training data sorted\n",
    "    print(\"Training LR sorted\")\n",
    "    X_train_sorted = np.sort(X_train, axis=1)\n",
    "    X_val_sorted = np.sort(X_val, axis=1)\n",
    "    predictions['logistic_regression_sorted'].append(\n",
    "        train_classifier(\n",
    "            LogisticRegression(), \n",
    "            X_train_sorted, \n",
    "            y_train, \n",
    "            X_val_sorted, \n",
    "            y_val, \n",
    "            batch_size, \n",
    "            epoch\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Train SVM model\n",
    "    print(\"Training SVM\")\n",
    "    predictions['svm'].append(\n",
    "        train_classifier(\n",
    "            SVC(probability=True), \n",
    "            X_train, \n",
    "            y_train, \n",
    "            X_val, \n",
    "            y_val, \n",
    "            batch_size, \n",
    "            epoch\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Train SVM when training data sorted\n",
    "    print(\"Training SVM sorted\")\n",
    "    predictions['svm_sorted'].append(\n",
    "        train_classifier(\n",
    "            SVC(probability=True), \n",
    "            X_train_sorted, \n",
    "            y_train, \n",
    "            X_val_sorted, \n",
    "            y_val, \n",
    "            batch_size, \n",
    "            epoch\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logistic_regression': [{'batch_size': 8,\n",
       "   'epochs': 10,\n",
       "   'predictions_val': array([0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "          1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "          1]),\n",
       "   'labels_val': array([0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "          1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "          1])},\n",
       "  {'batch_size': 32,\n",
       "   'epochs': 100,\n",
       "   'predictions_val': array([0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "          1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "          1]),\n",
       "   'labels_val': array([0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "          1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "          1])},\n",
       "  {'batch_size': 64,\n",
       "   'epochs': 10,\n",
       "   'predictions_val': array([0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "          1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "          1]),\n",
       "   'labels_val': array([0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "          1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "          1])}],\n",
       " 'logistic_regression_sorted': [{'batch_size': 8,\n",
       "   'epochs': 10,\n",
       "   'predictions_val': array([0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "          1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "          1]),\n",
       "   'labels_val': array([0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "          1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "          1])},\n",
       "  {'batch_size': 32,\n",
       "   'epochs': 100,\n",
       "   'predictions_val': array([0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "          1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "          1]),\n",
       "   'labels_val': array([0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "          1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "          1])},\n",
       "  {'batch_size': 64,\n",
       "   'epochs': 10,\n",
       "   'predictions_val': array([0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "          1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "          1]),\n",
       "   'labels_val': array([0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "          1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "          1])}],\n",
       " 'svm': [{'batch_size': 8,\n",
       "   'epochs': 10,\n",
       "   'predictions_val': array([0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "          1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "          1]),\n",
       "   'labels_val': array([0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "          1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "          1])},\n",
       "  {'batch_size': 32,\n",
       "   'epochs': 100,\n",
       "   'predictions_val': array([0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "          1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "          1]),\n",
       "   'labels_val': array([0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "          1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "          1])},\n",
       "  {'batch_size': 64,\n",
       "   'epochs': 10,\n",
       "   'predictions_val': array([0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "          1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "          1]),\n",
       "   'labels_val': array([0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "          1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "          1])}],\n",
       " 'svm_sorted': [{'batch_size': 8,\n",
       "   'epochs': 10,\n",
       "   'predictions_val': array([0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "          1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "          1]),\n",
       "   'labels_val': array([0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "          1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "          1])},\n",
       "  {'batch_size': 32,\n",
       "   'epochs': 100,\n",
       "   'predictions_val': array([0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "          1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "          1]),\n",
       "   'labels_val': array([0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "          1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "          1])},\n",
       "  {'batch_size': 64,\n",
       "   'epochs': 10,\n",
       "   'predictions_val': array([0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "          1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "          1]),\n",
       "   'labels_val': array([0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "          1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "          1])}]}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "send_email(f\"Finished training, predictions:\\n{predictions}\")\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "for key, val in predictions.items():\n",
    "    for clf_info in val:\n",
    "        res = []\n",
    "        res.append(key)\n",
    "        res.append(clf_info['batch_size'])\n",
    "        res.append(clf_info['epochs'])\n",
    "        \n",
    "        eval_scores = evaluate_model(\n",
    "            clf_info['predictions_val'], \n",
    "            clf_info['labels_val']\n",
    "        )\n",
    "        res.append(eval_scores['accuracy'])\n",
    "        res.append(eval_scores['precision'])\n",
    "        res.append(eval_scores['recall'])\n",
    "        res.append(eval_scores['f1'])\n",
    "        results.append(res)\n",
    "\n",
    "df = pd.DataFrame(results, columns=['final classifier', 'batch_size', 'epochs', 'accuracy', 'precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>final classifier</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>32</td>\n",
       "      <td>100</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.807692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>svm_sorted</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.765957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>svm</td>\n",
       "      <td>32</td>\n",
       "      <td>100</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.739130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>logistic_regression_sorted</td>\n",
       "      <td>32</td>\n",
       "      <td>100</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.734694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.723404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>svm_sorted</td>\n",
       "      <td>32</td>\n",
       "      <td>100</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.723404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.711111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>logistic_regression_sorted</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.711111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>svm</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.697674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>logistic_regression_sorted</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.682927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>svm</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.681818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>svm_sorted</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              final classifier  batch_size  epochs  accuracy  precision  \\\n",
       "1          logistic_regression          32     100  0.777778   0.750000   \n",
       "9                   svm_sorted           8      10  0.755556   0.782609   \n",
       "7                          svm          32     100  0.733333   0.772727   \n",
       "4   logistic_regression_sorted          32     100  0.711111   0.720000   \n",
       "2          logistic_regression          64      10  0.711111   0.739130   \n",
       "10                  svm_sorted          32     100  0.711111   0.739130   \n",
       "0          logistic_regression           8      10  0.711111   0.761905   \n",
       "3   logistic_regression_sorted           8      10  0.711111   0.761905   \n",
       "8                          svm          64      10  0.711111   0.789474   \n",
       "5   logistic_regression_sorted          64      10  0.711111   0.823529   \n",
       "6                          svm           8      10  0.688889   0.750000   \n",
       "11                  svm_sorted          64      10  0.688889   0.777778   \n",
       "\n",
       "      recall        f1  \n",
       "1   0.875000  0.807692  \n",
       "9   0.750000  0.765957  \n",
       "7   0.708333  0.739130  \n",
       "4   0.750000  0.734694  \n",
       "2   0.708333  0.723404  \n",
       "10  0.708333  0.723404  \n",
       "0   0.666667  0.711111  \n",
       "3   0.666667  0.711111  \n",
       "8   0.625000  0.697674  \n",
       "5   0.583333  0.682927  \n",
       "6   0.625000  0.681818  \n",
       "11  0.583333  0.666667  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['accuracy', 'f1'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "send_email(\"Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict the probability of a user being a fake news spreader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights for batch_size: 32, epochs: 100\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LR\n",
      "Training SVM\n",
      "Training LR sorted\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the BERT model\n",
    "print(f\"Loading weights for batch_size: 32, epochs: 100\")\n",
    "encoder, model = create_test_model()\n",
    "model.load_weights(\n",
    "    f\"training/bert_individual/batch32-epoch100/cp.ckpt\"\n",
    ").expect_partial()\n",
    "\n",
    "# Predict training and validation set data\n",
    "X_train, y_train = calculate_user_predictions_from_individual_tweets(\n",
    "    model, \n",
    "    tweet_individual_train, \n",
    "    label_individual_train,\n",
    ")\n",
    "X_val, y_val = calculate_user_predictions_from_individual_tweets(\n",
    "    model, \n",
    "    tweet_individual_val, \n",
    "    label_individual_val,\n",
    ")\n",
    "\n",
    "# Train Logistic Regression model\n",
    "print(\"Training LR\")\n",
    "log_reg_clf = LogisticRegression()\n",
    "log_reg_clf.fit(X_train, y_train)\n",
    "\n",
    "# Train SVM\n",
    "print(\"Training SVM\")\n",
    "svm_clf = SVC(probability=True)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# Train Logistic Regression when training data sorted\n",
    "print(\"Training LR sorted\")\n",
    "X_train_sorted = np.sort(X_train, axis=1)\n",
    "X_val_sorted = np.sort(X_val, axis=1)\n",
    "log_reg_sorted_clf = LogisticRegression()\n",
    "log_reg_sorted_clf.fit(X_train_sorted, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR User 1 predict probability: [[0.52118894 0.47881106]]\n",
      "LR User 1 prediction: [0]\n",
      "LR sorted User 1 predict probability: [[0.74938058 0.25061942]]\n",
      "LR sorted User 1 prediction: [0]\n",
      "SVM User 1 predict probability: [[0.792287 0.207713]]\n",
      "SVM User 1 prediction: [0]\n",
      "User 1 label: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"LR User 1 predict probability:\", \n",
    "      log_reg_clf.predict_proba([X_val[0]]))\n",
    "print(\"LR User 1 prediction:\", log_reg_clf.predict([X_val[0]]))\n",
    "print(\"LR sorted User 1 predict probability:\", \n",
    "      log_reg_sorted_clf.predict_proba([X_val_sorted[0]]))\n",
    "print(\"LR sorted User 1 prediction:\", log_reg_sorted_clf.predict([X_val_sorted[0]]))\n",
    "print(\"SVM User 1 predict probability:\", \n",
    "\n",
    "      svm_clf.predict_proba([X_val[0]]))\n",
    "print(\"SVM User 1 prediction:\", svm_clf.predict([X_val[0]]))\n",
    "print(\"User 1 label:\", y_val[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training BERT individual + Logistic Regression sorted\n",
    "BERT Model:\n",
    "* BERT L-12, Input 128\n",
    "* Individual tweets\n",
    "* batch_size 32, epochs 100\n",
    "\n",
    "Logistic Regression Model:\n",
    "* Predict training set using BERT and sort each datapoint - this will be the LR training data\n",
    "* Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipynb.fs.full.bert_fake_news_classifier as bclf\n",
    "\n",
    "# Encoder\n",
    "bert_individual_size = 128\n",
    "bert_individual_encoder = hub.KerasLayer(\n",
    "    \"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1\", \n",
    "    trainable=True,\n",
    ")\n",
    "\n",
    "# Model\n",
    "individual_tokenizer = bclf.BertIndividualTweetTokenizer(\n",
    "    bert_individual_encoder, \n",
    "    bert_individual_size,\n",
    ")\n",
    "bert_individual_model = bclf.create_bert_model(\n",
    "    bert_individual_encoder, \n",
    "    bert_individual_size,\n",
    ")\n",
    "bert_individual_model.compile(\n",
    "    Adam(lr=1e-5), \n",
    "    'binary_crossentropy', \n",
    "    ['accuracy']\n",
    ")\n",
    "\n",
    "# Checkpoint\n",
    "checkpoint_path_individual = \"training/bert_individual/best-batch_size32-epochs-100-2/bert/cp.ckpt\"\n",
    "bert_individual_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path_individual,\n",
    "    save_weights_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.6654 - accuracy: 0.5928\n",
      "Epoch 00001: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.6654 - accuracy: 0.5927\n",
      "Epoch 2/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.6331 - accuracy: 0.6413\n",
      "Epoch 00002: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.6332 - accuracy: 0.6412\n",
      "Epoch 3/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.6054 - accuracy: 0.6687\n",
      "Epoch 00003: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.6053 - accuracy: 0.6687\n",
      "Epoch 4/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.5824 - accuracy: 0.6915\n",
      "Epoch 00004: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.5824 - accuracy: 0.6916\n",
      "Epoch 5/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.5570 - accuracy: 0.7156\n",
      "Epoch 00005: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.5570 - accuracy: 0.7156\n",
      "Epoch 6/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.5333 - accuracy: 0.7298\n",
      "Epoch 00006: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 135ms/step - loss: 0.5333 - accuracy: 0.7298\n",
      "Epoch 7/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.5144 - accuracy: 0.7452\n",
      "Epoch 00007: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 135ms/step - loss: 0.5145 - accuracy: 0.7451\n",
      "Epoch 8/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.4904 - accuracy: 0.7606\n",
      "Epoch 00008: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 89s 135ms/step - loss: 0.4904 - accuracy: 0.7606\n",
      "Epoch 9/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.4707 - accuracy: 0.7732\n",
      "Epoch 00009: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 89s 135ms/step - loss: 0.4707 - accuracy: 0.7731\n",
      "Epoch 10/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.4519 - accuracy: 0.7839\n",
      "Epoch 00010: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 89s 135ms/step - loss: 0.4520 - accuracy: 0.7838\n",
      "Epoch 11/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.4349 - accuracy: 0.7943\n",
      "Epoch 00011: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 135ms/step - loss: 0.4350 - accuracy: 0.7942\n",
      "Epoch 12/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.4166 - accuracy: 0.8054\n",
      "Epoch 00012: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 89s 135ms/step - loss: 0.4166 - accuracy: 0.8054\n",
      "Epoch 13/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.3974 - accuracy: 0.8189\n",
      "Epoch 00013: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 89s 135ms/step - loss: 0.3974 - accuracy: 0.8189\n",
      "Epoch 14/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8297\n",
      "Epoch 00014: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 135ms/step - loss: 0.3825 - accuracy: 0.8297\n",
      "Epoch 15/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.3669 - accuracy: 0.8337\n",
      "Epoch 00015: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 89s 135ms/step - loss: 0.3669 - accuracy: 0.8338\n",
      "Epoch 16/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.3541 - accuracy: 0.8426\n",
      "Epoch 00016: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.3540 - accuracy: 0.8426\n",
      "Epoch 17/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.3309 - accuracy: 0.8533\n",
      "Epoch 00017: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 135ms/step - loss: 0.3309 - accuracy: 0.8533\n",
      "Epoch 18/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.3215 - accuracy: 0.8566\n",
      "Epoch 00018: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 135ms/step - loss: 0.3215 - accuracy: 0.8566\n",
      "Epoch 19/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.3089 - accuracy: 0.8649\n",
      "Epoch 00019: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 135ms/step - loss: 0.3088 - accuracy: 0.8650\n",
      "Epoch 20/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.2977 - accuracy: 0.8710\n",
      "Epoch 00020: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 135ms/step - loss: 0.2977 - accuracy: 0.8710\n",
      "Epoch 21/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.2796 - accuracy: 0.8790\n",
      "Epoch 00021: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 135ms/step - loss: 0.2796 - accuracy: 0.8791\n",
      "Epoch 22/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.2735 - accuracy: 0.8867\n",
      "Epoch 00022: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 89s 135ms/step - loss: 0.2734 - accuracy: 0.8867\n",
      "Epoch 23/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.2544 - accuracy: 0.8925\n",
      "Epoch 00023: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 89s 135ms/step - loss: 0.2544 - accuracy: 0.8926\n",
      "Epoch 24/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.2401 - accuracy: 0.8990\n",
      "Epoch 00024: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 89s 135ms/step - loss: 0.2401 - accuracy: 0.8990\n",
      "Epoch 25/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.2339 - accuracy: 0.9032\n",
      "Epoch 00025: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 89s 135ms/step - loss: 0.2339 - accuracy: 0.9032\n",
      "Epoch 26/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.2267 - accuracy: 0.9051\n",
      "Epoch 00026: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 89s 135ms/step - loss: 0.2267 - accuracy: 0.9051\n",
      "Epoch 27/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.2166 - accuracy: 0.9088\n",
      "Epoch 00027: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 89s 135ms/step - loss: 0.2166 - accuracy: 0.9088\n",
      "Epoch 28/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.2036 - accuracy: 0.9142\n",
      "Epoch 00028: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 89s 135ms/step - loss: 0.2036 - accuracy: 0.9141\n",
      "Epoch 29/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.1956 - accuracy: 0.9199\n",
      "Epoch 00029: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657/657 [==============================] - 89s 135ms/step - loss: 0.1957 - accuracy: 0.9199\n",
      "Epoch 30/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.1902 - accuracy: 0.9220\n",
      "Epoch 00030: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.1903 - accuracy: 0.9220\n",
      "Epoch 31/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.1818 - accuracy: 0.9259\n",
      "Epoch 00031: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.1817 - accuracy: 0.9260\n",
      "Epoch 32/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.1702 - accuracy: 0.9322\n",
      "Epoch 00032: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.1702 - accuracy: 0.9322\n",
      "Epoch 33/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.1643 - accuracy: 0.9337\n",
      "Epoch 00033: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.1643 - accuracy: 0.9337\n",
      "Epoch 34/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.1537 - accuracy: 0.9386\n",
      "Epoch 00034: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.1537 - accuracy: 0.9387\n",
      "Epoch 35/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.1534 - accuracy: 0.9383\n",
      "Epoch 00035: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.1535 - accuracy: 0.9382\n",
      "Epoch 36/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.1486 - accuracy: 0.9405\n",
      "Epoch 00036: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.1487 - accuracy: 0.9405\n",
      "Epoch 37/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.1377 - accuracy: 0.9446\n",
      "Epoch 00037: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.1378 - accuracy: 0.9446\n",
      "Epoch 38/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.1336 - accuracy: 0.9485\n",
      "Epoch 00038: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.1336 - accuracy: 0.9485\n",
      "Epoch 39/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.1274 - accuracy: 0.9502\n",
      "Epoch 00039: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.1274 - accuracy: 0.9502\n",
      "Epoch 40/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.1220 - accuracy: 0.9524\n",
      "Epoch 00040: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.1220 - accuracy: 0.9524\n",
      "Epoch 41/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.1143 - accuracy: 0.9552\n",
      "Epoch 00041: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.1144 - accuracy: 0.9552\n",
      "Epoch 42/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.1130 - accuracy: 0.9554\n",
      "Epoch 00042: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.1130 - accuracy: 0.9553\n",
      "Epoch 43/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.1064 - accuracy: 0.9597\n",
      "Epoch 00043: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.1064 - accuracy: 0.9598\n",
      "Epoch 44/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.1037 - accuracy: 0.9590\n",
      "Epoch 00044: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.1037 - accuracy: 0.9590\n",
      "Epoch 45/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0964 - accuracy: 0.9629\n",
      "Epoch 00045: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0965 - accuracy: 0.9629\n",
      "Epoch 46/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0997 - accuracy: 0.9619\n",
      "Epoch 00046: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0996 - accuracy: 0.9620\n",
      "Epoch 47/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0967 - accuracy: 0.9627\n",
      "Epoch 00047: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0967 - accuracy: 0.9627\n",
      "Epoch 48/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0897 - accuracy: 0.9648\n",
      "Epoch 00048: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0897 - accuracy: 0.9649\n",
      "Epoch 49/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0844 - accuracy: 0.9685\n",
      "Epoch 00049: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0845 - accuracy: 0.9684\n",
      "Epoch 50/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0860 - accuracy: 0.9657\n",
      "Epoch 00050: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0862 - accuracy: 0.9657\n",
      "Epoch 51/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0836 - accuracy: 0.9670\n",
      "Epoch 00051: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0836 - accuracy: 0.9670\n",
      "Epoch 52/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0757 - accuracy: 0.9721\n",
      "Epoch 00052: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0757 - accuracy: 0.9721\n",
      "Epoch 53/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0785 - accuracy: 0.9705\n",
      "Epoch 00053: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0785 - accuracy: 0.9705\n",
      "Epoch 54/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0714 - accuracy: 0.9729\n",
      "Epoch 00054: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0714 - accuracy: 0.9729\n",
      "Epoch 55/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0711 - accuracy: 0.9733\n",
      "Epoch 00055: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0711 - accuracy: 0.9733\n",
      "Epoch 56/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0701 - accuracy: 0.9748\n",
      "Epoch 00056: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0701 - accuracy: 0.9748\n",
      "Epoch 57/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0670 - accuracy: 0.9750\n",
      "Epoch 00057: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0669 - accuracy: 0.9750\n",
      "Epoch 58/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0655 - accuracy: 0.9746\n",
      "Epoch 00058: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0655 - accuracy: 0.9746\n",
      "Epoch 59/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0610 - accuracy: 0.9773\n",
      "Epoch 00059: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0609 - accuracy: 0.9773\n",
      "Epoch 60/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0616 - accuracy: 0.9769\n",
      "Epoch 00060: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0616 - accuracy: 0.9769\n",
      "Epoch 61/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0620 - accuracy: 0.9762\n",
      "Epoch 00061: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0620 - accuracy: 0.9762\n",
      "Epoch 62/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0584 - accuracy: 0.9788\n",
      "Epoch 00062: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0584 - accuracy: 0.9788\n",
      "Epoch 63/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0561 - accuracy: 0.9789\n",
      "Epoch 00063: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0561 - accuracy: 0.9789\n",
      "Epoch 64/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0580 - accuracy: 0.9785\n",
      "Epoch 00064: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0580 - accuracy: 0.9785\n",
      "Epoch 65/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0525 - accuracy: 0.9799\n",
      "Epoch 00065: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0525 - accuracy: 0.9800\n",
      "Epoch 66/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0549 - accuracy: 0.9798\n",
      "Epoch 00066: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0549 - accuracy: 0.9798\n",
      "Epoch 67/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0541 - accuracy: 0.9798\n",
      "Epoch 00067: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0541 - accuracy: 0.9798\n",
      "Epoch 68/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0481 - accuracy: 0.9829\n",
      "Epoch 00068: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0481 - accuracy: 0.9830\n",
      "Epoch 69/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0462 - accuracy: 0.9827\n",
      "Epoch 00069: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0462 - accuracy: 0.9827\n",
      "Epoch 70/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0464 - accuracy: 0.9830\n",
      "Epoch 00070: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0464 - accuracy: 0.9830\n",
      "Epoch 71/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0473 - accuracy: 0.9829\n",
      "Epoch 00071: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0473 - accuracy: 0.9829\n",
      "Epoch 72/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0450 - accuracy: 0.9830\n",
      "Epoch 00072: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0450 - accuracy: 0.9830\n",
      "Epoch 73/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0468 - accuracy: 0.9826\n",
      "Epoch 00073: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0468 - accuracy: 0.9826\n",
      "Epoch 74/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0422 - accuracy: 0.9841\n",
      "Epoch 00074: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0421 - accuracy: 0.9841\n",
      "Epoch 75/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0434 - accuracy: 0.9839\n",
      "Epoch 00075: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0434 - accuracy: 0.9840\n",
      "Epoch 76/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0403 - accuracy: 0.9851\n",
      "Epoch 00076: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0403 - accuracy: 0.9851\n",
      "Epoch 77/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0400 - accuracy: 0.9852\n",
      "Epoch 00077: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0400 - accuracy: 0.9852\n",
      "Epoch 78/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0387 - accuracy: 0.9861\n",
      "Epoch 00078: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 89s 135ms/step - loss: 0.0387 - accuracy: 0.9861\n",
      "Epoch 79/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0397 - accuracy: 0.9863\n",
      "Epoch 00079: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0396 - accuracy: 0.9863\n",
      "Epoch 80/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0418 - accuracy: 0.9844\n",
      "Epoch 00080: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0418 - accuracy: 0.9844\n",
      "Epoch 81/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0394 - accuracy: 0.9848\n",
      "Epoch 00081: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0393 - accuracy: 0.9848\n",
      "Epoch 82/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0368 - accuracy: 0.9858\n",
      "Epoch 00082: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0368 - accuracy: 0.9858\n",
      "Epoch 83/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0373 - accuracy: 0.9864\n",
      "Epoch 00083: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0373 - accuracy: 0.9864\n",
      "Epoch 84/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0351 - accuracy: 0.9869\n",
      "Epoch 00084: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0351 - accuracy: 0.9869\n",
      "Epoch 85/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0385 - accuracy: 0.9855\n",
      "Epoch 00085: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0385 - accuracy: 0.9855\n",
      "Epoch 86/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0346 - accuracy: 0.9863\n",
      "Epoch 00086: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0346 - accuracy: 0.9863\n",
      "Epoch 87/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0342 - accuracy: 0.9874\n",
      "Epoch 00087: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0342 - accuracy: 0.9874\n",
      "Epoch 88/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0338 - accuracy: 0.9876\n",
      "Epoch 00088: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0338 - accuracy: 0.9876\n",
      "Epoch 89/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0320 - accuracy: 0.9880\n",
      "Epoch 00089: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0320 - accuracy: 0.9880\n",
      "Epoch 90/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0308 - accuracy: 0.9885\n",
      "Epoch 00090: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0308 - accuracy: 0.9885\n",
      "Epoch 91/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0297 - accuracy: 0.9886\n",
      "Epoch 00091: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0297 - accuracy: 0.9886\n",
      "Epoch 92/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0331 - accuracy: 0.9874\n",
      "Epoch 00092: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0331 - accuracy: 0.9874\n",
      "Epoch 93/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0318 - accuracy: 0.9878\n",
      "Epoch 00093: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0318 - accuracy: 0.9878\n",
      "Epoch 94/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0312 - accuracy: 0.9876\n",
      "Epoch 00094: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0312 - accuracy: 0.9876\n",
      "Epoch 95/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0315 - accuracy: 0.9880\n",
      "Epoch 00095: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0315 - accuracy: 0.9880\n",
      "Epoch 96/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0290 - accuracy: 0.9886\n",
      "Epoch 00096: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0290 - accuracy: 0.9886\n",
      "Epoch 97/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0296 - accuracy: 0.9886\n",
      "Epoch 00097: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 135ms/step - loss: 0.0296 - accuracy: 0.9886\n",
      "Epoch 98/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0285 - accuracy: 0.9882\n",
      "Epoch 00098: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0285 - accuracy: 0.9882\n",
      "Epoch 99/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0283 - accuracy: 0.9891\n",
      "Epoch 00099: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0283 - accuracy: 0.9891\n",
      "Epoch 100/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0299 - accuracy: 0.9879\n",
      "Epoch 00100: saving model to training/bert_individual/best-batch_size32-epochs-100-2/bert\\cp.ckpt\n",
      "657/657 [==============================] - 88s 134ms/step - loss: 0.0299 - accuracy: 0.9880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x139c8c0f988>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train BERT\n",
    "bert_individual_model.fit(\n",
    "    x=tweet_individual_train,\n",
    "    y=label_individual_train,\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    callbacks=[bert_individual_checkpoint_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 6s 42ms/step - loss: 2.2917 - accuracy: 0.5707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.2916836738586426, 0.5706666707992554]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_individual_model.evaluate(tweet_individual_val, label_individual_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1398e39eac8>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bert_individual_model = bclf.create_bert_model(\n",
    "#     bert_individual_encoder, \n",
    "#     bert_individual_size,\n",
    "# )\n",
    "# bert_individual_model.load_weights(\n",
    "#     f\"training/bert_individual/batch32-epoch100/cp.ckpt\"\n",
    "# ).expect_partial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['training/bert_individual/best-batch_size32-epochs-100-2/logistic_regressor.joblib']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "# Train Logistic Regression classifier\n",
    "X_train, y_train = calculate_user_predictions_from_individual_tweets(\n",
    "    bert_individual_model, \n",
    "    tweet_individual_train, \n",
    "    label_individual_train,\n",
    ")\n",
    "X_train_sorted = np.sort(X_train, axis=1)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_sorted, y_train)\n",
    "dump(clf, \"training/bert_individual/best-batch_size32-epochs-100-2/logistic_regressor.joblib\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = load(\"training/bert_individual/best-batch_size32-epochs-100-2/logistic_regressor.joblib\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation eval:\n",
      "{'true_positives': 19, 'false_positives': 8, 'false_negatives': 5, 'true_negatives': 13, 'accuracy': 0.7111111111111111, 'precision': 0.7037037037037037, 'recall': 0.7916666666666666, 'f1': 0.7450980392156864}\n",
      "Test eval:\n",
      "{'true_positives': 14, 'false_positives': 12, 'false_negatives': 4, 'true_negatives': 15, 'accuracy': 0.6444444444444445, 'precision': 0.5384615384615384, 'recall': 0.7777777777777778, 'f1': 0.6363636363636364}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "X_val, y_val = calculate_user_predictions_from_individual_tweets(\n",
    "    bert_individual_model, \n",
    "    tweet_individual_val, \n",
    "    label_individual_val,\n",
    ")\n",
    "X_val_sorted = np.sort(X_val, axis=1)\n",
    "\n",
    "X_test, y_test = calculate_user_predictions_from_individual_tweets(\n",
    "    bert_individual_model, \n",
    "    tweet_individual_test, \n",
    "    label_individual_test,\n",
    ")\n",
    "X_test_sorted = np.sort(X_test, axis=1)\n",
    "\n",
    "pred_val = clf.predict(X_val_sorted)\n",
    "pred_test = clf.predict(X_test_sorted)\n",
    "\n",
    "result = f\"Validation eval:\\n{evaluate_model(pred_val, y_val)}\\nTest eval:\\n{evaluate_model(pred_test, y_test)}\"\n",
    "send_email(result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Tweet Feed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_bert_url = \"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1\"\n",
    "bert_encoder_feed = hub.KerasLayer(\n",
    "    medium_bert_url, \n",
    "    trainable=True,\n",
    ")\n",
    "\n",
    "bert_input_size_feed = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_tokenizer = clf.BertTweetFeedTokenizer(bert_encoder_feed, bert_input_size_feed)\n",
    "bert_model_feed = bclf.create_bert_model(bert_encoder_feed, bert_input_size_feed)\n",
    "bert_model_feed.compile(Adam(lr=1e-5), 'binary_crossentropy', ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a checkpoint for training\n",
    "checkpoint_path_feed = \"training/bert_training_feed_2/cp.ckpt\"\n",
    "\n",
    "bert_checkpoint_callback_feed = ModelCheckpoint(\n",
    "    filepath=checkpoint_path_feed,\n",
    "    save_weights_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_feed_train = feed_tokenizer.tokenize_input(tweet_train)\n",
    "label_feed_train = feed_tokenizer.tokenize_labels(label_train)\n",
    "tweet_feed_val = feed_tokenizer.tokenize_input(tweet_val)\n",
    "label_feed_val = feed_tokenizer.tokenize_labels(label_val)\n",
    "tweet_feed_test = feed_tokenizer.tokenize_input(tweet_test)\n",
    "label_feed_test = feed_tokenizer.tokenize_labels(label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('gpu:0'):\n",
    "    # Fit\n",
    "    bert_model_feed.fit(\n",
    "        x=tweet_feed_train, \n",
    "        y=label_feed_train, \n",
    "        batch_size=10, \n",
    "        epochs=5, \n",
    "        callbacks=[bert_checkpoint_callback_feed], \n",
    "        validation_data=(tweet_feed_val, label_feed_val),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from official.nlp.bert.tokenization import FullTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bert_model_2(encoder, input_size=128, num_tweets=100):\n",
    "    input_layer = Input(shape=(num_tweets, 3, input_size), dtype=tf.int32) # (100, 3, 128)\n",
    "\n",
    "    dense = Dense(1, activation='sigmoid')\n",
    "    def inner(inner_inputs):\n",
    "        encoder_pooled_output = encoder(inner_inputs)['pooled_output']\n",
    "        dense_output = dense(encoder_pooled_output)\n",
    "        return dense_output\n",
    "    \n",
    "    combined = tf.keras.layers.concatenate([inner({\n",
    "        'input_word_ids': input_layer[:0, i, 0],\n",
    "        'input_mask': input_layer[:0, i, 1],\n",
    "        'input_type_ids': input_layer[:0, i, 2],\n",
    "    }) for i in range(num_tweets)])\n",
    "    \n",
    "    softmax_output = Dense(1, activation='softmax')(combined)\n",
    "\n",
    "    # Create the Keras model and compile\n",
    "    return Model(input_layer, softmax_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "Tensor(\"input_32:0\", shape=(None, 5, 3, 128), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "bert_model_2 = create_bert_model_2(bert_encoder_individual, input_size=128, num_tweets=5)\n",
    "bert_model_2.compile(Adam(lr=1e-5), 'binary_crossentropy', ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_copy = tweet_individual_val\n",
    "x_copy_re = tf.convert_to_tensor([[\n",
    "    [x_copy['input_word_ids'][j*i],\n",
    "    x_copy['input_mask'][j*i],\n",
    "    x_copy['input_type_ids'][j*i],]\n",
    "    for j in range(100)\n",
    "] for i in range(45)])\n",
    "\n",
    "y_copy = label_individual_val\n",
    "y_copy_re = tf.convert_to_tensor([label_individual_val.numpy()[i] for i in range(0, 4500, 100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('gpu:0'):\n",
    "    bert_model_2.fit(\n",
    "        x=x_copy_re[0:3, :5],\n",
    "        y=y_copy_re[0:3],\n",
    "        batch_size=32,\n",
    "        epochs=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_31 (InputLayer)           [(None, 5, 3, 128)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_335 ( [(None, 128)]        0           input_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_336 ( [(None, 128)]        0           input_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_334 ( [(None, 128)]        0           input_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_338 ( [(None, 128)]        0           input_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_339 ( [(None, 128)]        0           input_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_337 ( [(None, 128)]        0           input_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_341 ( [(None, 128)]        0           input_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_342 ( [(None, 128)]        0           input_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_340 ( [(None, 128)]        0           input_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_344 ( [(None, 128)]        0           input_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_345 ( [(None, 128)]        0           input_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_343 ( [(None, 128)]        0           input_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_347 ( [(None, 128)]        0           input_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_348 ( [(None, 128)]        0           input_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_346 ( [(None, 128)]        0           input_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer (KerasLayer)        {'pooled_output': (N 6368641     tf_op_layer_strided_slice_335[0][\n",
      "                                                                 tf_op_layer_strided_slice_336[0][\n",
      "                                                                 tf_op_layer_strided_slice_334[0][\n",
      "                                                                 tf_op_layer_strided_slice_338[0][\n",
      "                                                                 tf_op_layer_strided_slice_339[0][\n",
      "                                                                 tf_op_layer_strided_slice_337[0][\n",
      "                                                                 tf_op_layer_strided_slice_341[0][\n",
      "                                                                 tf_op_layer_strided_slice_342[0][\n",
      "                                                                 tf_op_layer_strided_slice_340[0][\n",
      "                                                                 tf_op_layer_strided_slice_344[0][\n",
      "                                                                 tf_op_layer_strided_slice_345[0][\n",
      "                                                                 tf_op_layer_strided_slice_343[0][\n",
      "                                                                 tf_op_layer_strided_slice_347[0][\n",
      "                                                                 tf_op_layer_strided_slice_348[0][\n",
      "                                                                 tf_op_layer_strided_slice_346[0][\n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            129         keras_layer[108][13]             \n",
      "                                                                 keras_layer[109][13]             \n",
      "                                                                 keras_layer[110][13]             \n",
      "                                                                 keras_layer[111][13]             \n",
      "                                                                 keras_layer[112][13]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 5)            0           dense_8[0][0]                    \n",
      "                                                                 dense_8[1][0]                    \n",
      "                                                                 dense_8[2][0]                    \n",
      "                                                                 dense_8[3][0]                    \n",
      "                                                                 dense_8[4][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            6           concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 6,368,776\n",
      "Trainable params: 6,368,775\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert_model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COPIED FROM https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch\n",
    "bert_model = bclf.create_bert_model(bert_encoder_individual, 128)\n",
    "bert_optimizer = Adam(lr=1e-5)\n",
    "bert_loss_fn = tf.keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clf_model():\n",
    "    input_layer = Input(shape=(100,))\n",
    "    dense_out = Dense(1, activation=\"sigmoid\")(input_layer)\n",
    "    return tf.keras.Model(inputs=input_layer, outputs=dense_out)\n",
    "\n",
    "clf_model = create_clf_model()\n",
    "clf_optimizer = Adam(lr=1e-5)\n",
    "clf_loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "clf_train_acc_metric = tf.keras.metrics.BinaryAccuracy()\n",
    "clf_val_acc_metric = tf.keras.metrics.BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 100, 3, 128), (None,)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_copy_re, y_copy_re))\n",
    "train_dataset = train_dataset.batch(6) # users per batch\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweets_to_bert_batch(tweets_batch):\n",
    "    res = {\n",
    "        'input_word_ids': tweets_batch[:, 0],\n",
    "        'input_mask': tweets_batch[:, 1],\n",
    "        'input_type_ids': tweets_batch[:, 2],\n",
    "    }\n",
    "    return res\n",
    "\n",
    "def to_tweet_batches(x_train, num_tweets, tweet_batch_size):\n",
    "    return [\n",
    "        tweets_to_bert_batch(x_train[i:i+tweet_batch_size]) \n",
    "        for i in range(0, num_tweets, tweet_batch_size)\n",
    "    ]\n",
    "\n",
    "def train_step(x_batch_train, y_batch_train, num_tweets=100, tweet_batch_size=20):\n",
    "    with tf.GradientTape(watch_accessed_variables=False) as bert_tape, tf.GradientTape(watch_accessed_variables=False) as clf_tape:\n",
    "        bert_tape.watch(bert_model.variables)\n",
    "        bert_tape.watch(clf_model.variables)\n",
    "        clf_tape.watch(clf_model.variables)\n",
    "        \n",
    "        clf_batch_logits = []\n",
    "\n",
    "        # For each user in the batch\n",
    "        for x_user_train in x_batch_train:\n",
    "\n",
    "            # Predict tweet batches using BERT\n",
    "            bert_user_logits = tf.convert_to_tensor([])\n",
    "\n",
    "            for tweet_batch in to_tweet_batches(x_user_train, num_tweets, tweet_batch_size):\n",
    "                bert_batch_logits = tf.reshape(\n",
    "                    bert_model(tweet_batch, training=True), \n",
    "                    shape=(-1,),\n",
    "                )\n",
    "                bert_user_logits = tf.concat(\n",
    "                    (bert_user_logits, bert_batch_logits), \n",
    "                    axis=0,\n",
    "                )\n",
    "\n",
    "            # Predict using Classifier\n",
    "            clf_inputs = tf.reshape(bert_user_logits, shape=(1, -1))\n",
    "            clf_logits = clf_model(clf_inputs, training=True)\n",
    "            clf_batch_logits.append(clf_logits)\n",
    "\n",
    "        # Take the loss of entire batch\n",
    "        clf_batch_logits_concat = tf.concat((clf_batch_logits), axis=0)\n",
    "\n",
    "        y_batch_train = tf.reshape(y_batch_train, shape=(-1, 1))\n",
    "        clf_batch_loss = clf_loss_fn(y_batch_train, clf_batch_logits_concat)\n",
    "\n",
    "    # Update gradients after batch\n",
    "    bert_grads = bert_tape.gradient(clf_batch_loss, bert_model.trainable_weights)\n",
    "    bert_optimizer.apply_gradients(zip(bert_grads, bert_model.trainable_weights))\n",
    "\n",
    "    clf_grads = clf_tape.gradient(clf_batch_loss, clf_model.trainable_weights)\n",
    "    clf_optimizer.apply_gradients(zip(clf_grads, clf_model.trainable_weights))\n",
    "\n",
    "    # Update training metric\n",
    "    clf_train_acc_metric.update_state(y_batch_train, clf_batch_logits_concat)\n",
    "    \n",
    "    # Return batch loss\n",
    "    return clf_batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0/10\n",
      "WARNING:tensorflow:The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.bool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.bool\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batch 0: loss=0.7131641507148743, accuracy=0.4888888895511627\n",
      "WARNING:tensorflow:The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.bool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.bool\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batch 1: loss=0.7168457508087158, accuracy=0.4901960790157318\n",
      "WARNING:tensorflow:The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.bool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.bool\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batch 2: loss=0.7257969975471497, accuracy=0.4912280738353729\n",
      "WARNING:tensorflow:The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.bool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.bool\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batch 3: loss=0.6994034647941589, accuracy=0.4920634925365448\n",
      "WARNING:tensorflow:The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.bool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.bool\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Batch 4: loss=0.5383312702178955, accuracy=0.5362318754196167\n",
      "> Batch 5: loss=0.6871833801269531, accuracy=0.5333333611488342\n",
      "> Batch 6: loss=0.7790965437889099, accuracy=0.5185185074806213\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-72cb134bfdaf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_batch_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0mbatch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[0mepoch_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"> Batch {step}: loss={batch_loss}, accuracy={clf_train_acc_metric.result()}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-56-aaaa9eea81e1>\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(x_batch_train, y_batch_train, num_tweets, tweet_batch_size)\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mtweet_batch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mto_tweet_batches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_user_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_tweets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtweet_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                 bert_batch_logits = tf.reshape(\n\u001b[1;32m---> 30\u001b[1;33m                     \u001b[0mbert_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m                     \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m                 )\n",
      "\u001b[1;32mc:\\users\\joshh\\desktop\\uni\\soton year 3\\comp3200\\fake-news-profiling\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joshh\\desktop\\uni\\soton year 3\\comp3200\\fake-news-profiling\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    384\u001b[0m     \"\"\"\n\u001b[0;32m    385\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m--> 386\u001b[1;33m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joshh\\desktop\\uni\\soton year 3\\comp3200\\fake-news-profiling\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joshh\\desktop\\uni\\soton year 3\\comp3200\\fake-news-profiling\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joshh\\desktop\\uni\\soton year 3\\comp3200\\fake-news-profiling\\venv\\lib\\site-packages\\tensorflow_hub\\keras_layer.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m    235\u001b[0m       result = smart_cond.smart_cond(training,\n\u001b[0;32m    236\u001b[0m                                      \u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m                                      lambda: f(training=False))\n\u001b[0m\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m     \u001b[1;31m# Unwrap dicts returned by signatures.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joshh\\desktop\\uni\\soton year 3\\comp3200\\fake-news-profiling\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\smart_cond.py\u001b[0m in \u001b[0;36msmart_cond\u001b[1;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mpred_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpred_value\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joshh\\desktop\\uni\\soton year 3\\comp3200\\fake-news-profiling\\venv\\lib\\site-packages\\tensorflow_hub\\keras_layer.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    234\u001b[0m         \u001b[0mtraining\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m       result = smart_cond.smart_cond(training,\n\u001b[1;32m--> 236\u001b[1;33m                                      \u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m                                      lambda: f(training=False))\n\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joshh\\desktop\\uni\\soton year 3\\comp3200\\fake-news-profiling\\venv\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py\u001b[0m in \u001b[0;36m_call_attribute\u001b[1;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_call_attribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 509\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    510\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joshh\\desktop\\uni\\soton year 3\\comp3200\\fake-news-profiling\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joshh\\desktop\\uni\\soton year 3\\comp3200\\fake-news-profiling\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    812\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32mc:\\users\\joshh\\desktop\\uni\\soton year 3\\comp3200\\fake-news-profiling\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joshh\\desktop\\uni\\soton year 3\\comp3200\\fake-news-profiling\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joshh\\desktop\\uni\\soton year 3\\comp3200\\fake-news-profiling\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1931\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m   1932\u001b[0m           \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs_with_tangents\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1933\u001b[1;33m           cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1934\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1935\u001b[0m       with default_graph._override_gradient_function(  # pylint: disable=protected-access\n",
      "\u001b[1;32mc:\\users\\joshh\\desktop\\uni\\soton year 3\\comp3200\\fake-news-profiling\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\joshh\\desktop\\uni\\soton year 3\\comp3200\\fake-news-profiling\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Modified FROM https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch\n",
    "import time\n",
    "\n",
    "total_loss = []\n",
    "\n",
    "with tf.device('cpu:0'):\n",
    "    epochs = 10\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoch {epoch}/{epochs}\")\n",
    "        epoch_loss = []\n",
    "\n",
    "        for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "            batch_loss = train_step(x_batch_train, y_batch_train)\n",
    "            epoch_loss.append(batch_loss)\n",
    "            print(f\"> Batch {step}: loss={batch_loss}, accuracy={clf_train_acc_metric.result()}\")\n",
    "        \n",
    "        print(\"Training acc over epoch: %.4f\" % (float(clf_train_acc_metric.result()),))\n",
    "\n",
    "        # Reset training metrics at the end of each epoch\n",
    "        clf_train_acc_metric.reset_states()\n",
    "        total_loss.append(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x256097d3048>]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(0, 90, 1), total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_word_ids': (None, 128),\n",
       " 'input_mask': (None, 128),\n",
       " 'input_type_ids': (None, 128)}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
