{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "preprocessing_path = 'C:\\\\Users\\\\joshh\\\\Desktop\\\\Uni\\\\Soton Uni - Yr 3\\\\COMP3200\\\\fake-news-profiling\\\\classifier\\\\preprocessing'\n",
    "if preprocessing_path not in sys.path:\n",
    "    sys.path.insert(1, preprocessing_path)\n",
    "\n",
    "notif_path = 'C:\\\\Users\\\\joshh\\\\Desktop\\\\Uni\\\\Soton Uni - Yr 3\\\\COMP3200\\\\fake-news-profiling\\\\classifier\\\\notifications'\n",
    "if notif_path not in sys.path:\n",
    "    sys.path.insert(1, notif_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import ipynb.fs.full.parse_datasets as datasets\n",
    "import ipynb.fs.full.preprocessing as pp\n",
    "import ipynb.fs.full.bert_fake_news_classifier as bclf\n",
    "from ipynb.fs.full.notif_email import send_email"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data, label_data = datasets.parse_dataset(\"datasets\", \"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data extractor\n",
    "* Extract statistical features from tweet text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import string\n",
    "import demoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats extraction helper functions\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "digits = set(\"0123456789\")\n",
    "printable = set(string.printable)\n",
    "punctuation = set(string.punctuation)\n",
    "punctuation.remove('#')\n",
    "\n",
    "\n",
    "def clean_text(text, remove_punc=True, remove_non_print=True, remove_emojis=True, \n",
    "              remove_digits=True):\n",
    "    \"\"\" Clean text by removing certain characters (e.g. punctuation) \"\"\"\n",
    "    if remove_emojis:\n",
    "        text = demoji.replace(text, \"\")\n",
    "        \n",
    "    chars = []\n",
    "    for char in text:\n",
    "        if not ((remove_punc and char in punctuation) or\n",
    "            (remove_non_print and char not in printable) or\n",
    "            (remove_digits and char in digits)):\n",
    "            chars.append(char)\n",
    "        \n",
    "    return \"\".join(chars)\n",
    "\n",
    "\n",
    "def polarity_scores(text):\n",
    "    polarity_dict = analyzer.polarity_scores(text)\n",
    "    return np.asarray([\n",
    "        polarity_dict['pos'],\n",
    "        polarity_dict['neu'],\n",
    "        polarity_dict['neg'],\n",
    "    ])\n",
    "\n",
    "\n",
    "def tweets_to_words(user_tweets):\n",
    "    return np.asarray([clean_text(tweet.text).split() for tweet in user_tweets])\n",
    "\n",
    "\n",
    "def std_dev(datapoints, mean, num_datapoints=100):\n",
    "    diff = datapoints - mean\n",
    "    return np.sqrt(np.sum(diff ** 2, axis=0)/100)\n",
    "\n",
    "\n",
    "def average_tweet_lengths(user_tweets):\n",
    "    return np.mean([len(tweet) for tweet in user_tweets])\n",
    "\n",
    "\n",
    "def std_dev_tweet_lengths(user_tweets):\n",
    "    tweet_lens = [len(tweet) for tweet in user_tweets]\n",
    "    return std_dev(\n",
    "        np.asarray(tweet_lens),\n",
    "        np.mean(tweet_lens),\n",
    "    )\n",
    "\n",
    "\n",
    "def cased_chars(user_tweets, cased):\n",
    "    return [\n",
    "        sum([c.isupper() if cased else c.islower() for c in tweet.text]) \n",
    "        for tweet in user_tweets\n",
    "    ]\n",
    "\n",
    "\n",
    "def emoji_chars(user_tweets):\n",
    "    return [len(demoji.findall_list(tweet.text)) for tweet in user_tweets]\n",
    "\n",
    "\n",
    "def punctuation_chars(user_tweets):\n",
    "    return [\n",
    "        len([c for c in tweet.text if c in punctuation]) \n",
    "        for tweet in user_tweets\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extractor functions (to be used in TweetStatsExtractor)\n",
    "def average_chars(user_tweets):\n",
    "    \"\"\" Returns the average tweet lengths, in characters, for the user \"\"\"\n",
    "    return average_tweet_lengths([tweet.text for tweet in user_tweets])\n",
    "\n",
    "\n",
    "def std_dev_chars(user_tweets):\n",
    "    \"\"\" Returns the standard deviations of tweet lengths, in characters, for the user \"\"\"\n",
    "    return std_dev_tweet_lengths([tweet.text for tweet in user_tweets])\n",
    "\n",
    "\n",
    "def average_words(user_tweets):\n",
    "    \"\"\" Returns the average tweet lengths, in words, for the user \"\"\"\n",
    "    return average_tweet_lengths(tweets_to_words(user_tweets))\n",
    "\n",
    "\n",
    "def std_dev_words(user_tweets):\n",
    "    \"\"\" Returns the standard deviations of tweet lengths, in words, for the user \"\"\"\n",
    "    return std_dev_tweet_lengths(tweets_to_words(user_tweets))\n",
    "\n",
    "\n",
    "def average_sentiment(user_tweets):\n",
    "    \"\"\" Returns the average sentiment scores of the user \"\"\"\n",
    "    return np.mean([polarity_scores(tweet.text) for tweet in user_tweets], axis=0)\n",
    "\n",
    "\n",
    "def std_dev_sentiment(user_tweets):\n",
    "    \"\"\" Returns the average sentiment scores of the user \"\"\"\n",
    "    sentiment = np.asarray([polarity_scores(tweet.text) for tweet in user_tweets])\n",
    "    return std_dev(sentiment, np.mean(sentiment, axis=0))\n",
    "\n",
    "\n",
    "def average_word_lengths(user_tweets):\n",
    "    \"\"\" Returns the average length of words used by this user \"\"\"\n",
    "    return np.mean([\n",
    "        len(word) \n",
    "        for tweet in user_tweets\n",
    "        for word in clean_text(tweet.text).split()\n",
    "    ])\n",
    "\n",
    "\n",
    "def average_tags(user_tweets, tags=['RT', '#USER#', '#HASHTAG#', '#URL#']):\n",
    "    \"\"\" Returns the average number of tags used by this user \"\"\"\n",
    "    return np.mean([\n",
    "        np.asarray([tweet.text.count(tag) for tag in tags])\n",
    "                   for tweet in user_tweets\n",
    "    ], axis=0)\n",
    "\n",
    "\n",
    "def average_cased_chars(user_tweets):\n",
    "    \"\"\" Returns the average number of cased (uppercase) characters per tweet, for the user \"\"\"\n",
    "    return np.mean(cased_chars(user_tweets, True))\n",
    "    \n",
    "\n",
    "def std_dev_cased_chars(user_tweets):\n",
    "    \"\"\" Returns the standard deviation of cased characters per tweet, for the user \"\"\"\n",
    "    return std_dev(cased_chars(user_tweets, True), average_cased_chars(user_tweets))\n",
    "    \n",
    "    \n",
    "def average_uncased_chars(user_tweets):\n",
    "    \"\"\" Returns the average number of uncased (lowercase) characters per tweet, for the user \"\"\"\n",
    "    return np.mean(cased_chars(user_tweets, False))\n",
    "\n",
    "\n",
    "def std_dev_uncased_chars(user_tweets):\n",
    "    \"\"\" Returns the standard deviation of cased characters per tweet, for the user \"\"\"\n",
    "    return std_dev(cased_chars(user_tweets, False), average_uncased_chars(user_tweets))\n",
    "\n",
    "    \n",
    "def average_emojis(user_tweets):\n",
    "    \"\"\" Returns the average number of emojis per tweet, for the user \"\"\"\n",
    "    return np.mean(emoji_chars(user_tweets))\n",
    "    \n",
    "    \n",
    "def std_dev_emojis(user_tweets):\n",
    "    \"\"\" Returns the standard deviation of emojis per tweet, for the user \"\"\"\n",
    "    return std_dev(emoji_chars(user_tweets), average_emojis(user_tweets))\n",
    "\n",
    "\n",
    "def average_punctuation_chars(user_tweets):\n",
    "    \"\"\" Returns the average number of punctuation characters per tweet, for the user \"\"\"\n",
    "    return np.mean(punctuation_chars(user_tweets))\n",
    "\n",
    "    \n",
    "def std_dev_punctuation_chars(user_tweets):\n",
    "    \"\"\" Returns the standard deviation of punctuation characters emojis per tweet, for the user \"\"\"\n",
    "    return std_dev(punctuation_chars(user_tweets), average_punctuation_chars(user_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Iterable\n",
    "\n",
    "class TweetStatsExtractor:\n",
    "    def __init__(self, funcs=[\n",
    "        average_chars,\n",
    "        std_dev_chars,\n",
    "        average_words,\n",
    "        std_dev_words,\n",
    "        average_word_lengths,\n",
    "        average_cased_chars,\n",
    "        std_dev_cased_chars,\n",
    "        average_uncased_chars,\n",
    "        std_dev_uncased_chars,\n",
    "        average_emojis,\n",
    "        std_dev_emojis,\n",
    "        average_punctuation_chars,\n",
    "        std_dev_punctuation_chars,\n",
    "        average_tags,\n",
    "        average_sentiment,\n",
    "        std_dev_sentiment,\n",
    "    ]):\n",
    "        self.funcs = funcs\n",
    "    \n",
    "    def transform(self, X, normalize_data=True):\n",
    "        result = np.asarray([\n",
    "            np.concatenate([self._apply(f, tweet_feed) for f in self.funcs])\n",
    "            for tweet_feed in X\n",
    "        ])\n",
    "        \n",
    "        return normalize(result) if normalize_data else result\n",
    "    \n",
    "    def _apply(self, func, data):\n",
    "        result = func(data)\n",
    "        if isinstance(result, Iterable):\n",
    "            return result\n",
    "        else:\n",
    "            return np.asarray([result])\n",
    "\n",
    "feature_names = [\n",
    "    \"Average number of characters per tweet\",\n",
    "    \"Standard deviation of characters per tweet\",\n",
    "    \"Average number of words per tweet\",\n",
    "    \"Standard deviation of words per tweet\",\n",
    "    \"Average word lengths\",\n",
    "    \"Average number of cased characters per tweet\",\n",
    "    \"Standard deviation of cased characters per tweet\",\n",
    "    \"Average number of uncased characters per tweet\",\n",
    "    \"Standard deviation of uncased characters per tweet\",\n",
    "    \"Average number of emojis per tweet\",\n",
    "    \"Standard deviation of emojis per tweet\",\n",
    "    \"Average number of punctuation characters per tweet\",\n",
    "    \"Standard deviation number of punctuation characters per tweet\",\n",
    "    \"Average number of 'RT' tags per tweet\",\n",
    "    \"Average number of '#USER#' tags per tweet\",\n",
    "    \"Average number of '#HASHTAG#' tags per tweet\",\n",
    "    \"Average number of '#URL#' tags per tweet\",\n",
    "    \"Average positive sentiment per tweet\",\n",
    "    \"Average neutral sentiment per tweet\",\n",
    "    \"Average negative sentiment per tweet\",\n",
    "    \"Standard deviation positive sentiment per tweet\",\n",
    "    \"Standard deviation neutral sentiment per tweet\",\n",
    "    \"Standard deviation negative sentiment per tweet\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier models\n",
    "* Classify users based on their (normalized) statistical features\n",
    "* Used a GridSearch to find model optimal parameters as well as TweetStatsExtractor optimal parameters\n",
    "* We can look at model weights to find the stats which are least and most useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats data\n",
    "stats_extractor = TweetStatsExtractor()\n",
    "tweet_stats_data = stats_extractor.transform(tweet_data)\n",
    "\n",
    "(tweet_train, label_train, \n",
    " tweet_val, label_val, \n",
    " tweet_test, label_test) = datasets.split_dataset(tweet_stats_data, label_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Features = 1\n",
      "LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        25\n",
      "           1       0.44      1.00      0.62        20\n",
      "\n",
      "    accuracy                           0.44        45\n",
      "   macro avg       0.22      0.50      0.31        45\n",
      "weighted avg       0.20      0.44      0.27        45\n",
      "\n",
      "SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.60      0.68        25\n",
      "           1       0.62      0.80      0.70        20\n",
      "\n",
      "    accuracy                           0.69        45\n",
      "   macro avg       0.70      0.70      0.69        45\n",
      "weighted avg       0.71      0.69      0.69        45\n",
      "\n",
      "RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.60      0.64        25\n",
      "           1       0.57      0.65      0.60        20\n",
      "\n",
      "    accuracy                           0.62        45\n",
      "   macro avg       0.62      0.62      0.62        45\n",
      "weighted avg       0.63      0.62      0.62        45\n",
      "\n",
      "GradientBoostingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.60      0.65        25\n",
      "           1       0.58      0.70      0.64        20\n",
      "\n",
      "    accuracy                           0.64        45\n",
      "   macro avg       0.65      0.65      0.64        45\n",
      "weighted avg       0.66      0.64      0.65        45\n",
      "\n",
      "-------------Features = 2\n",
      "LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        25\n",
      "           1       0.44      1.00      0.62        20\n",
      "\n",
      "    accuracy                           0.44        45\n",
      "   macro avg       0.22      0.50      0.31        45\n",
      "weighted avg       0.20      0.44      0.27        45\n",
      "\n",
      "SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.20      0.31        25\n",
      "           1       0.47      0.90      0.62        20\n",
      "\n",
      "    accuracy                           0.51        45\n",
      "   macro avg       0.59      0.55      0.47        45\n",
      "weighted avg       0.61      0.51      0.45        45\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\joshh\\desktop\\uni\\soton uni - yr 3\\comp3200\\fake-news-profiling\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\joshh\\desktop\\uni\\soton uni - yr 3\\comp3200\\fake-news-profiling\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.52      0.57        25\n",
      "           1       0.50      0.60      0.55        20\n",
      "\n",
      "    accuracy                           0.56        45\n",
      "   macro avg       0.56      0.56      0.56        45\n",
      "weighted avg       0.57      0.56      0.56        45\n",
      "\n",
      "GradientBoostingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.48      0.53        25\n",
      "           1       0.48      0.60      0.53        20\n",
      "\n",
      "    accuracy                           0.53        45\n",
      "   macro avg       0.54      0.54      0.53        45\n",
      "weighted avg       0.55      0.53      0.53        45\n",
      "\n",
      "-------------Features = 3\n",
      "LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        25\n",
      "           1       0.44      1.00      0.62        20\n",
      "\n",
      "    accuracy                           0.44        45\n",
      "   macro avg       0.22      0.50      0.31        45\n",
      "weighted avg       0.20      0.44      0.27        45\n",
      "\n",
      "SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.28      0.41        25\n",
      "           1       0.50      0.90      0.64        20\n",
      "\n",
      "    accuracy                           0.56        45\n",
      "   macro avg       0.64      0.59      0.53        45\n",
      "weighted avg       0.65      0.56      0.51        45\n",
      "\n",
      "RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.56      0.60        25\n",
      "           1       0.52      0.60      0.56        20\n",
      "\n",
      "    accuracy                           0.58        45\n",
      "   macro avg       0.58      0.58      0.58        45\n",
      "weighted avg       0.59      0.58      0.58        45\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\joshh\\desktop\\uni\\soton uni - yr 3\\comp3200\\fake-news-profiling\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\joshh\\desktop\\uni\\soton uni - yr 3\\comp3200\\fake-news-profiling\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.60      0.67        25\n",
      "           1       0.60      0.75      0.67        20\n",
      "\n",
      "    accuracy                           0.67        45\n",
      "   macro avg       0.68      0.68      0.67        45\n",
      "weighted avg       0.68      0.67      0.67        45\n",
      "\n",
      "-------------Features = 4\n",
      "LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        25\n",
      "           1       0.44      1.00      0.62        20\n",
      "\n",
      "    accuracy                           0.44        45\n",
      "   macro avg       0.22      0.50      0.31        45\n",
      "weighted avg       0.20      0.44      0.27        45\n",
      "\n",
      "SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.36      0.50        25\n",
      "           1       0.53      0.90      0.67        20\n",
      "\n",
      "    accuracy                           0.60        45\n",
      "   macro avg       0.67      0.63      0.58        45\n",
      "weighted avg       0.69      0.60      0.57        45\n",
      "\n",
      "RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.56      0.60        25\n",
      "           1       0.52      0.60      0.56        20\n",
      "\n",
      "    accuracy                           0.58        45\n",
      "   macro avg       0.58      0.58      0.58        45\n",
      "weighted avg       0.59      0.58      0.58        45\n",
      "\n",
      "GradientBoostingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.60      0.64        25\n",
      "           1       0.57      0.65      0.60        20\n",
      "\n",
      "    accuracy                           0.62        45\n",
      "   macro avg       0.62      0.62      0.62        45\n",
      "weighted avg       0.63      0.62      0.62        45\n",
      "\n",
      "-------------Features = 5\n",
      "LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        25\n",
      "           1       0.44      1.00      0.62        20\n",
      "\n",
      "    accuracy                           0.44        45\n",
      "   macro avg       0.22      0.50      0.31        45\n",
      "weighted avg       0.20      0.44      0.27        45\n",
      "\n",
      "SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.36      0.50        25\n",
      "           1       0.53      0.90      0.67        20\n",
      "\n",
      "    accuracy                           0.60        45\n",
      "   macro avg       0.67      0.63      0.58        45\n",
      "weighted avg       0.69      0.60      0.57        45\n",
      "\n",
      "RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.60      0.65        25\n",
      "           1       0.58      0.70      0.64        20\n",
      "\n",
      "    accuracy                           0.64        45\n",
      "   macro avg       0.65      0.65      0.64        45\n",
      "weighted avg       0.66      0.64      0.65        45\n",
      "\n",
      "GradientBoostingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.56      0.64        25\n",
      "           1       0.58      0.75      0.65        20\n",
      "\n",
      "    accuracy                           0.64        45\n",
      "   macro avg       0.66      0.66      0.64        45\n",
      "weighted avg       0.67      0.64      0.64        45\n",
      "\n",
      "-------------Features = 6\n",
      "LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        25\n",
      "           1       0.44      1.00      0.62        20\n",
      "\n",
      "    accuracy                           0.44        45\n",
      "   macro avg       0.22      0.50      0.31        45\n",
      "weighted avg       0.20      0.44      0.27        45\n",
      "\n",
      "SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.28      0.41        25\n",
      "           1       0.50      0.90      0.64        20\n",
      "\n",
      "    accuracy                           0.56        45\n",
      "   macro avg       0.64      0.59      0.53        45\n",
      "weighted avg       0.65      0.56      0.51        45\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\joshh\\desktop\\uni\\soton uni - yr 3\\comp3200\\fake-news-profiling\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\joshh\\desktop\\uni\\soton uni - yr 3\\comp3200\\fake-news-profiling\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.52      0.58        25\n",
      "           1       0.52      0.65      0.58        20\n",
      "\n",
      "    accuracy                           0.58        45\n",
      "   macro avg       0.58      0.58      0.58        45\n",
      "weighted avg       0.59      0.58      0.58        45\n",
      "\n",
      "GradientBoostingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.56      0.62        25\n",
      "           1       0.56      0.70      0.62        20\n",
      "\n",
      "    accuracy                           0.62        45\n",
      "   macro avg       0.63      0.63      0.62        45\n",
      "weighted avg       0.64      0.62      0.62        45\n",
      "\n",
      "-------------Features = 7\n",
      "LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.28      0.42        25\n",
      "           1       0.51      0.95      0.67        20\n",
      "\n",
      "    accuracy                           0.58        45\n",
      "   macro avg       0.69      0.61      0.55        45\n",
      "weighted avg       0.71      0.58      0.53        45\n",
      "\n",
      "SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.36      0.51        25\n",
      "           1       0.54      0.95      0.69        20\n",
      "\n",
      "    accuracy                           0.62        45\n",
      "   macro avg       0.72      0.66      0.60        45\n",
      "weighted avg       0.74      0.62      0.59        45\n",
      "\n",
      "RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.56      0.61        25\n",
      "           1       0.54      0.65      0.59        20\n",
      "\n",
      "    accuracy                           0.60        45\n",
      "   macro avg       0.60      0.60      0.60        45\n",
      "weighted avg       0.61      0.60      0.60        45\n",
      "\n",
      "GradientBoostingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.56      0.62        25\n",
      "           1       0.56      0.70      0.62        20\n",
      "\n",
      "    accuracy                           0.62        45\n",
      "   macro avg       0.63      0.63      0.62        45\n",
      "weighted avg       0.64      0.62      0.62        45\n",
      "\n",
      "-------------Features = 8\n",
      "LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.28      0.42        25\n",
      "           1       0.51      0.95      0.67        20\n",
      "\n",
      "    accuracy                           0.58        45\n",
      "   macro avg       0.69      0.61      0.55        45\n",
      "weighted avg       0.71      0.58      0.53        45\n",
      "\n",
      "SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.36      0.51        25\n",
      "           1       0.54      0.95      0.69        20\n",
      "\n",
      "    accuracy                           0.62        45\n",
      "   macro avg       0.72      0.66      0.60        45\n",
      "weighted avg       0.74      0.62      0.59        45\n",
      "\n",
      "RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.60      0.61        25\n",
      "           1       0.52      0.55      0.54        20\n",
      "\n",
      "    accuracy                           0.58        45\n",
      "   macro avg       0.57      0.57      0.57        45\n",
      "weighted avg       0.58      0.58      0.58        45\n",
      "\n",
      "GradientBoostingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.60      0.63        25\n",
      "           1       0.55      0.60      0.57        20\n",
      "\n",
      "    accuracy                           0.60        45\n",
      "   macro avg       0.60      0.60      0.60        45\n",
      "weighted avg       0.60      0.60      0.60        45\n",
      "\n",
      "-------------Features = 9\n",
      "LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.28      0.42        25\n",
      "           1       0.51      0.95      0.67        20\n",
      "\n",
      "    accuracy                           0.58        45\n",
      "   macro avg       0.69      0.61      0.55        45\n",
      "weighted avg       0.71      0.58      0.53        45\n",
      "\n",
      "SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.36      0.51        25\n",
      "           1       0.54      0.95      0.69        20\n",
      "\n",
      "    accuracy                           0.62        45\n",
      "   macro avg       0.72      0.66      0.60        45\n",
      "weighted avg       0.74      0.62      0.59        45\n",
      "\n",
      "RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.64      0.67        25\n",
      "           1       0.59      0.65      0.62        20\n",
      "\n",
      "    accuracy                           0.64        45\n",
      "   macro avg       0.64      0.65      0.64        45\n",
      "weighted avg       0.65      0.64      0.65        45\n",
      "\n",
      "GradientBoostingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.60      0.64        25\n",
      "           1       0.57      0.65      0.60        20\n",
      "\n",
      "    accuracy                           0.62        45\n",
      "   macro avg       0.62      0.62      0.62        45\n",
      "weighted avg       0.63      0.62      0.62        45\n",
      "\n",
      "-------------Features = 10\n",
      "LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.28      0.42        25\n",
      "           1       0.51      0.95      0.67        20\n",
      "\n",
      "    accuracy                           0.58        45\n",
      "   macro avg       0.69      0.61      0.55        45\n",
      "weighted avg       0.71      0.58      0.53        45\n",
      "\n",
      "SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.36      0.51        25\n",
      "           1       0.54      0.95      0.69        20\n",
      "\n",
      "    accuracy                           0.62        45\n",
      "   macro avg       0.72      0.66      0.60        45\n",
      "weighted avg       0.74      0.62      0.59        45\n",
      "\n",
      "RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.60      0.67        25\n",
      "           1       0.60      0.75      0.67        20\n",
      "\n",
      "    accuracy                           0.67        45\n",
      "   macro avg       0.68      0.68      0.67        45\n",
      "weighted avg       0.68      0.67      0.67        45\n",
      "\n",
      "GradientBoostingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.56      0.60        25\n",
      "           1       0.52      0.60      0.56        20\n",
      "\n",
      "    accuracy                           0.58        45\n",
      "   macro avg       0.58      0.58      0.58        45\n",
      "weighted avg       0.59      0.58      0.58        45\n",
      "\n",
      "-------------Features = 11\n",
      "LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.24      0.35        25\n",
      "           1       0.47      0.85      0.61        20\n",
      "\n",
      "    accuracy                           0.51        45\n",
      "   macro avg       0.57      0.54      0.48        45\n",
      "weighted avg       0.58      0.51      0.47        45\n",
      "\n",
      "SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.36      0.46        25\n",
      "           1       0.48      0.75      0.59        20\n",
      "\n",
      "    accuracy                           0.53        45\n",
      "   macro avg       0.56      0.55      0.52        45\n",
      "weighted avg       0.57      0.53      0.52        45\n",
      "\n",
      "RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.60      0.65        25\n",
      "           1       0.58      0.70      0.64        20\n",
      "\n",
      "    accuracy                           0.64        45\n",
      "   macro avg       0.65      0.65      0.64        45\n",
      "weighted avg       0.66      0.64      0.65        45\n",
      "\n",
      "GradientBoostingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.60      0.63        25\n",
      "           1       0.55      0.60      0.57        20\n",
      "\n",
      "    accuracy                           0.60        45\n",
      "   macro avg       0.60      0.60      0.60        45\n",
      "weighted avg       0.60      0.60      0.60        45\n",
      "\n",
      "-------------Features = 12\n",
      "LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.24      0.35        25\n",
      "           1       0.47      0.85      0.61        20\n",
      "\n",
      "    accuracy                           0.51        45\n",
      "   macro avg       0.57      0.54      0.48        45\n",
      "weighted avg       0.58      0.51      0.47        45\n",
      "\n",
      "SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.36      0.46        25\n",
      "           1       0.48      0.75      0.59        20\n",
      "\n",
      "    accuracy                           0.53        45\n",
      "   macro avg       0.56      0.55      0.52        45\n",
      "weighted avg       0.57      0.53      0.52        45\n",
      "\n",
      "RandomForestClassifier\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64        25\n",
      "           1       0.55      0.55      0.55        20\n",
      "\n",
      "    accuracy                           0.60        45\n",
      "   macro avg       0.59      0.59      0.59        45\n",
      "weighted avg       0.60      0.60      0.60        45\n",
      "\n",
      "GradientBoostingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.60      0.65        25\n",
      "           1       0.58      0.70      0.64        20\n",
      "\n",
      "    accuracy                           0.64        45\n",
      "   macro avg       0.65      0.65      0.64        45\n",
      "weighted avg       0.66      0.64      0.65        45\n",
      "\n",
      "-------------Features = 13\n",
      "LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.24      0.35        25\n",
      "           1       0.47      0.85      0.61        20\n",
      "\n",
      "    accuracy                           0.51        45\n",
      "   macro avg       0.57      0.54      0.48        45\n",
      "weighted avg       0.58      0.51      0.47        45\n",
      "\n",
      "SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.36      0.47        25\n",
      "           1       0.50      0.80      0.62        20\n",
      "\n",
      "    accuracy                           0.56        45\n",
      "   macro avg       0.60      0.58      0.54        45\n",
      "weighted avg       0.61      0.56      0.54        45\n",
      "\n",
      "RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.64      0.68        25\n",
      "           1       0.61      0.70      0.65        20\n",
      "\n",
      "    accuracy                           0.67        45\n",
      "   macro avg       0.67      0.67      0.67        45\n",
      "weighted avg       0.67      0.67      0.67        45\n",
      "\n",
      "GradientBoostingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.60      0.65        25\n",
      "           1       0.58      0.70      0.64        20\n",
      "\n",
      "    accuracy                           0.64        45\n",
      "   macro avg       0.65      0.65      0.64        45\n",
      "weighted avg       0.66      0.64      0.65        45\n",
      "\n",
      "-------------Features = 14\n",
      "LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.20      0.28        25\n",
      "           1       0.41      0.70      0.52        20\n",
      "\n",
      "    accuracy                           0.42        45\n",
      "   macro avg       0.43      0.45      0.40        45\n",
      "weighted avg       0.44      0.42      0.38        45\n",
      "\n",
      "SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.32      0.43        25\n",
      "           1       0.48      0.80      0.60        20\n",
      "\n",
      "    accuracy                           0.53        45\n",
      "   macro avg       0.58      0.56      0.52        45\n",
      "weighted avg       0.59      0.53      0.51        45\n",
      "\n",
      "RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.64      0.67        25\n",
      "           1       0.59      0.65      0.62        20\n",
      "\n",
      "    accuracy                           0.64        45\n",
      "   macro avg       0.64      0.65      0.64        45\n",
      "weighted avg       0.65      0.64      0.65        45\n",
      "\n",
      "GradientBoostingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.56      0.60        25\n",
      "           1       0.52      0.60      0.56        20\n",
      "\n",
      "    accuracy                           0.58        45\n",
      "   macro avg       0.58      0.58      0.58        45\n",
      "weighted avg       0.59      0.58      0.58        45\n",
      "\n",
      "-------------Features = 15\n",
      "LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.20      0.28        25\n",
      "           1       0.41      0.70      0.52        20\n",
      "\n",
      "    accuracy                           0.42        45\n",
      "   macro avg       0.43      0.45      0.40        45\n",
      "weighted avg       0.44      0.42      0.38        45\n",
      "\n",
      "SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.32      0.43        25\n",
      "           1       0.48      0.80      0.60        20\n",
      "\n",
      "    accuracy                           0.53        45\n",
      "   macro avg       0.58      0.56      0.52        45\n",
      "weighted avg       0.59      0.53      0.51        45\n",
      "\n",
      "RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.64      0.68        25\n",
      "           1       0.61      0.70      0.65        20\n",
      "\n",
      "    accuracy                           0.67        45\n",
      "   macro avg       0.67      0.67      0.67        45\n",
      "weighted avg       0.67      0.67      0.67        45\n",
      "\n",
      "GradientBoostingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.56      0.61        25\n",
      "           1       0.54      0.65      0.59        20\n",
      "\n",
      "    accuracy                           0.60        45\n",
      "   macro avg       0.60      0.60      0.60        45\n",
      "weighted avg       0.61      0.60      0.60        45\n",
      "\n",
      "-------------Features = 16\n",
      "LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.20      0.28        25\n",
      "           1       0.41      0.70      0.52        20\n",
      "\n",
      "    accuracy                           0.42        45\n",
      "   macro avg       0.43      0.45      0.40        45\n",
      "weighted avg       0.44      0.42      0.38        45\n",
      "\n",
      "SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.32      0.43        25\n",
      "           1       0.48      0.80      0.60        20\n",
      "\n",
      "    accuracy                           0.53        45\n",
      "   macro avg       0.58      0.56      0.52        45\n",
      "weighted avg       0.59      0.53      0.51        45\n",
      "\n",
      "RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.64      0.68        25\n",
      "           1       0.61      0.70      0.65        20\n",
      "\n",
      "    accuracy                           0.67        45\n",
      "   macro avg       0.67      0.67      0.67        45\n",
      "weighted avg       0.67      0.67      0.67        45\n",
      "\n",
      "GradientBoostingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.56      0.62        25\n",
      "           1       0.56      0.70      0.62        20\n",
      "\n",
      "    accuracy                           0.62        45\n",
      "   macro avg       0.63      0.63      0.62        45\n",
      "weighted avg       0.64      0.62      0.62        45\n",
      "\n",
      "-------------Features = 17\n",
      "LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.24      0.34        25\n",
      "           1       0.46      0.80      0.58        20\n",
      "\n",
      "    accuracy                           0.49        45\n",
      "   macro avg       0.53      0.52      0.46        45\n",
      "weighted avg       0.54      0.49      0.45        45\n",
      "\n",
      "SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.24      0.34        25\n",
      "           1       0.46      0.80      0.58        20\n",
      "\n",
      "    accuracy                           0.49        45\n",
      "   macro avg       0.53      0.52      0.46        45\n",
      "weighted avg       0.54      0.49      0.45        45\n",
      "\n",
      "RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.68      0.71        25\n",
      "           1       0.64      0.70      0.67        20\n",
      "\n",
      "    accuracy                           0.69        45\n",
      "   macro avg       0.69      0.69      0.69        45\n",
      "weighted avg       0.69      0.69      0.69        45\n",
      "\n",
      "GradientBoostingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.56      0.65        25\n",
      "           1       0.59      0.80      0.68        20\n",
      "\n",
      "    accuracy                           0.67        45\n",
      "   macro avg       0.69      0.68      0.67        45\n",
      "weighted avg       0.70      0.67      0.66        45\n",
      "\n",
      "-------------Features = 18\n",
      "LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.24      0.34        25\n",
      "           1       0.46      0.80      0.58        20\n",
      "\n",
      "    accuracy                           0.49        45\n",
      "   macro avg       0.53      0.52      0.46        45\n",
      "weighted avg       0.54      0.49      0.45        45\n",
      "\n",
      "SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.20      0.29        25\n",
      "           1       0.44      0.80      0.57        20\n",
      "\n",
      "    accuracy                           0.47        45\n",
      "   macro avg       0.50      0.50      0.43        45\n",
      "weighted avg       0.51      0.47      0.42        45\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.76      0.78        25\n",
      "           1       0.71      0.75      0.73        20\n",
      "\n",
      "    accuracy                           0.76        45\n",
      "   macro avg       0.75      0.76      0.75        45\n",
      "weighted avg       0.76      0.76      0.76        45\n",
      "\n",
      "GradientBoostingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.56      0.62        25\n",
      "           1       0.56      0.70      0.62        20\n",
      "\n",
      "    accuracy                           0.62        45\n",
      "   macro avg       0.63      0.63      0.62        45\n",
      "weighted avg       0.64      0.62      0.62        45\n",
      "\n",
      "-------------Features = 19\n",
      "LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.28      0.39        25\n",
      "           1       0.47      0.80      0.59        20\n",
      "\n",
      "    accuracy                           0.51        45\n",
      "   macro avg       0.55      0.54      0.49        45\n",
      "weighted avg       0.56      0.51      0.48        45\n",
      "\n",
      "SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.28      0.39        25\n",
      "           1       0.47      0.80      0.59        20\n",
      "\n",
      "    accuracy                           0.51        45\n",
      "   macro avg       0.55      0.54      0.49        45\n",
      "weighted avg       0.56      0.51      0.48        45\n",
      "\n",
      "RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.60      0.64        25\n",
      "           1       0.57      0.65      0.60        20\n",
      "\n",
      "    accuracy                           0.62        45\n",
      "   macro avg       0.62      0.62      0.62        45\n",
      "weighted avg       0.63      0.62      0.62        45\n",
      "\n",
      "GradientBoostingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.60      0.65        25\n",
      "           1       0.58      0.70      0.64        20\n",
      "\n",
      "    accuracy                           0.64        45\n",
      "   macro avg       0.65      0.65      0.64        45\n",
      "weighted avg       0.66      0.64      0.65        45\n",
      "\n",
      "-------------Features = 20\n",
      "LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.28      0.39        25\n",
      "           1       0.47      0.80      0.59        20\n",
      "\n",
      "    accuracy                           0.51        45\n",
      "   macro avg       0.55      0.54      0.49        45\n",
      "weighted avg       0.56      0.51      0.48        45\n",
      "\n",
      "SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.28      0.39        25\n",
      "           1       0.47      0.80      0.59        20\n",
      "\n",
      "    accuracy                           0.51        45\n",
      "   macro avg       0.55      0.54      0.49        45\n",
      "weighted avg       0.56      0.51      0.48        45\n",
      "\n",
      "RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.64      0.68        25\n",
      "           1       0.61      0.70      0.65        20\n",
      "\n",
      "    accuracy                           0.67        45\n",
      "   macro avg       0.67      0.67      0.67        45\n",
      "weighted avg       0.67      0.67      0.67        45\n",
      "\n",
      "GradientBoostingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68        25\n",
      "           1       0.60      0.60      0.60        20\n",
      "\n",
      "    accuracy                           0.64        45\n",
      "   macro avg       0.64      0.64      0.64        45\n",
      "weighted avg       0.64      0.64      0.64        45\n",
      "\n",
      "-------------Features = 21\n",
      "LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.28      0.39        25\n",
      "           1       0.47      0.80      0.59        20\n",
      "\n",
      "    accuracy                           0.51        45\n",
      "   macro avg       0.55      0.54      0.49        45\n",
      "weighted avg       0.56      0.51      0.48        45\n",
      "\n",
      "SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.24      0.34        25\n",
      "           1       0.46      0.80      0.58        20\n",
      "\n",
      "    accuracy                           0.49        45\n",
      "   macro avg       0.53      0.52      0.46        45\n",
      "weighted avg       0.54      0.49      0.45        45\n",
      "\n",
      "RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.72      0.72        25\n",
      "           1       0.65      0.65      0.65        20\n",
      "\n",
      "    accuracy                           0.69        45\n",
      "   macro avg       0.69      0.69      0.69        45\n",
      "weighted avg       0.69      0.69      0.69        45\n",
      "\n",
      "GradientBoostingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.60      0.64        25\n",
      "           1       0.57      0.65      0.60        20\n",
      "\n",
      "    accuracy                           0.62        45\n",
      "   macro avg       0.62      0.62      0.62        45\n",
      "weighted avg       0.63      0.62      0.62        45\n",
      "\n",
      "-------------Features = 22\n",
      "LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.28      0.39        25\n",
      "           1       0.47      0.80      0.59        20\n",
      "\n",
      "    accuracy                           0.51        45\n",
      "   macro avg       0.55      0.54      0.49        45\n",
      "weighted avg       0.56      0.51      0.48        45\n",
      "\n",
      "SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.24      0.35        25\n",
      "           1       0.47      0.85      0.61        20\n",
      "\n",
      "    accuracy                           0.51        45\n",
      "   macro avg       0.57      0.54      0.48        45\n",
      "weighted avg       0.58      0.51      0.47        45\n",
      "\n",
      "RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.56      0.61        25\n",
      "           1       0.54      0.65      0.59        20\n",
      "\n",
      "    accuracy                           0.60        45\n",
      "   macro avg       0.60      0.60      0.60        45\n",
      "weighted avg       0.61      0.60      0.60        45\n",
      "\n",
      "GradientBoostingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.64      0.68        25\n",
      "           1       0.61      0.70      0.65        20\n",
      "\n",
      "    accuracy                           0.67        45\n",
      "   macro avg       0.67      0.67      0.67        45\n",
      "weighted avg       0.67      0.67      0.67        45\n",
      "\n",
      "-------------Features = 23\n",
      "LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.28      0.39        25\n",
      "           1       0.47      0.80      0.59        20\n",
      "\n",
      "    accuracy                           0.51        45\n",
      "   macro avg       0.55      0.54      0.49        45\n",
      "weighted avg       0.56      0.51      0.48        45\n",
      "\n",
      "SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.24      0.35        25\n",
      "           1       0.47      0.85      0.61        20\n",
      "\n",
      "    accuracy                           0.51        45\n",
      "   macro avg       0.57      0.54      0.48        45\n",
      "weighted avg       0.58      0.51      0.47        45\n",
      "\n",
      "RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.60      0.67        25\n",
      "           1       0.60      0.75      0.67        20\n",
      "\n",
      "    accuracy                           0.67        45\n",
      "   macro avg       0.68      0.68      0.67        45\n",
      "weighted avg       0.68      0.67      0.67        45\n",
      "\n",
      "GradientBoostingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.64      0.65        25\n",
      "           1       0.57      0.60      0.59        20\n",
      "\n",
      "    accuracy                           0.62        45\n",
      "   macro avg       0.62      0.62      0.62        45\n",
      "weighted avg       0.62      0.62      0.62        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "\n",
    "# Training models, selecting the best features\n",
    "for i in range(1, len(tweet_train[0])+1):\n",
    "    select = SelectKBest(k=i)\n",
    "    X_train = select.fit_transform(tweet_train, label_train) \n",
    "    X_val = select.transform(tweet_val)\n",
    "    \n",
    "    print(\"-------------Features =\", i)\n",
    "    # Logistic Regression\n",
    "    log_reg_clf = LogisticRegression(\"l2\")\n",
    "    log_reg_clf.fit(X_train, label_train)\n",
    "    print(\"LogisticRegression\")\n",
    "    print(classification_report(label_val, log_reg_clf.predict(X_val)))\n",
    "\n",
    "    # Support Vector Classifier\n",
    "    svc_clf = SVC()\n",
    "    svc_clf.fit(X_train, label_train)\n",
    "    print(\"SVC\")\n",
    "    print(classification_report(label_val, svc_clf.predict(X_val)))\n",
    "    \n",
    "    # Random Forest\n",
    "    forest_clf = RandomForestClassifier()\n",
    "    forest_clf.fit(X_train, label_train)\n",
    "    print(\"RandomForestClassifier\")\n",
    "    print(classification_report(label_val, forest_clf.predict(X_val)))\n",
    "    \n",
    "    # Gradient Boosting\n",
    "    grad_boost_clf = GradientBoostingClassifier()\n",
    "    grad_boost_clf.fit(X_train, label_train)\n",
    "    print(\"GradientBoostingClassifier\")\n",
    "    print(classification_report(label_val, grad_boost_clf.predict(X_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best classifiers\n",
    "* Select the best performing classifiers\n",
    "* Do a grid search for their best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Average negative sentiment per tweet', 16.98501592327074),\n",
       " ('Average number of punctuation characters per tweet', 9.755842009119732),\n",
       " ('Average number of words per tweet', 7.910577870055184),\n",
       " ('Standard deviation of emojis per tweet', 7.842691211800912),\n",
       " ('Average positive sentiment per tweet', 7.036855751571707),\n",
       " ('Standard deviation negative sentiment per tweet', 6.073945243556848),\n",
       " ('Average number of uncased characters per tweet', 4.095469612930164),\n",
       " (\"Average number of '#USER#' tags per tweet\", 4.044184545734733),\n",
       " (\"Average number of 'RT' tags per tweet\", 3.5192819489583638),\n",
       " ('Standard deviation of words per tweet', 3.517345947563265),\n",
       " ('Standard deviation of uncased characters per tweet', 2.840796589938319),\n",
       " ('Standard deviation positive sentiment per tweet', 2.757120898898489),\n",
       " ('Average number of emojis per tweet', 2.697001810004565),\n",
       " ('Standard deviation of characters per tweet', 2.36117832377876),\n",
       " ('Standard deviation number of punctuation characters per tweet',\n",
       "  1.534020105727729),\n",
       " ('Average neutral sentiment per tweet', 1.4108920143073589),\n",
       " ('Average number of characters per tweet', 0.7537797861356142),\n",
       " (\"Average number of '#HASHTAG#' tags per tweet\", 0.5487083737195987),\n",
       " ('Average number of cased characters per tweet', 0.25958846773363875),\n",
       " ('Standard deviation neutral sentiment per tweet', 0.17304124744498273),\n",
       " ('Average word lengths', 0.10738941541188174),\n",
       " (\"Average number of '#URL#' tags per tweet\", 0.011839780508837992),\n",
       " ('Standard deviation of cased characters per tweet', 0.0025141566256084956)]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importance of each feature\n",
    "selected_scores = sorted(zip(feature_names, select.scores_), key=lambda a: a[1], reverse=True)\n",
    "selected_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val accuracy (LogisticRegression): 0.5777777777777777\n",
      "Val accuracy (SVC): 0.5111111111111111\n",
      "Val accuracy (RandomForestClassifier): 0.7555555555555555\n",
      "Val accuracy (GradientBoostingClassifier): 0.7111111111111111\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "log_reg_clf = LogisticRegression(\"l2\")\n",
    "log_reg_clf.fit(tweet_train, label_train)\n",
    "print(\"Val accuracy (LogisticRegression):\", log_reg_clf.score(tweet_val, label_val))\n",
    "\n",
    "# Support Vector Classifier\n",
    "svc_clf = SVC()\n",
    "svc_clf.fit(tweet_train, label_train)\n",
    "print(\"Val accuracy (SVC):\", svc_clf.score(tweet_val, label_val))\n",
    "\n",
    "# Random Forest\n",
    "forest_clf = RandomForestClassifier()\n",
    "forest_clf.fit(tweet_train, label_train)\n",
    "print(\"Val accuracy (RandomForestClassifier):\", forest_clf.score(tweet_val, label_val))\n",
    "\n",
    "# Gradient Boosting\n",
    "grad_boost_clf = GradientBoostingClassifier()\n",
    "grad_boost_clf.fit(tweet_train, label_train)\n",
    "print(\"Val accuracy (GradientBoostingClassifier):\", grad_boost_clf.score(tweet_val, label_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining the Ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
