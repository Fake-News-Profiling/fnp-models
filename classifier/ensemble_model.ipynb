{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "preprocessing_path = 'C:\\\\Users\\\\joshh\\\\Desktop\\\\Uni\\\\Soton Uni - Yr 3\\\\COMP3200\\\\fake-news-profiling\\\\classifier\\\\preprocessing'\n",
    "if preprocessing_path not in sys.path:\n",
    "    sys.path.insert(1, preprocessing_path)\n",
    "\n",
    "notif_path = 'C:\\\\Users\\\\joshh\\\\Desktop\\\\Uni\\\\Soton Uni - Yr 3\\\\COMP3200\\\\fake-news-profiling\\\\classifier\\\\notifications'\n",
    "if notif_path not in sys.path:\n",
    "    sys.path.insert(1, notif_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import ipynb.fs.full.parse_datasets as datasets\n",
    "import ipynb.fs.full.preprocessing as pp\n",
    "import ipynb.fs.full.bert_fake_news_classifier as bclf\n",
    "from ipynb.fs.full.notif_email import send_email"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data, label_data = datasets.parse_dataset(\"datasets\", \"en\")\n",
    "\n",
    "(tweet_train, label_train, \n",
    " tweet_val, label_val, \n",
    " tweet_test, label_test) = datasets.split_dataset(tweet_data, label_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import string\n",
    "import demoji\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats extraction helper functions\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "digits = set(\"0123456789\")\n",
    "printable = set(string.printable)\n",
    "punctuation = set(string.punctuation)\n",
    "punctuation.remove('#')\n",
    "\n",
    "\n",
    "def clean_text(text, remove_punc=True, remove_non_print=True, remove_emojis=True, \n",
    "              remove_digits=True, remove_tags=False):\n",
    "    \"\"\" Clean text by removing certain characters (e.g. punctuation) \"\"\"\n",
    "    if remove_emojis:\n",
    "        text = demoji.replace(text, \"\")\n",
    "        \n",
    "    chars = []\n",
    "    for char in text:\n",
    "        if not ((remove_punc and char in punctuation) or\n",
    "            (remove_non_print and char not in printable) or\n",
    "            (remove_digits and char in digits)):\n",
    "            chars.append(char)\n",
    "        \n",
    "    cleaned = \"\".join(chars)\n",
    "    if remove_tags:\n",
    "        return re.sub('#[A-Z]+#', \"\", cleaned)\n",
    "    \n",
    "    return cleaned\n",
    "\n",
    "\n",
    "def polarity_scores(text):\n",
    "    polarity_dict = analyzer.polarity_scores(text)\n",
    "    return np.asarray([\n",
    "        polarity_dict['pos'],\n",
    "        polarity_dict['neu'],\n",
    "        polarity_dict['neg'],\n",
    "    ])\n",
    "\n",
    "\n",
    "def tweets_to_words(user_tweets):\n",
    "    return np.asarray([\n",
    "        np.asarray(clean_text(tweet.text).split()) \n",
    "        for tweet in user_tweets\n",
    "    ])\n",
    "\n",
    "\n",
    "def std_dev(datapoints, mean, num_datapoints=100):\n",
    "    diff = datapoints - mean\n",
    "    return np.sqrt(np.sum(diff ** 2, axis=0)/100)\n",
    "\n",
    "\n",
    "def average_tweet_lengths(user_tweets):\n",
    "    return np.mean([len(tweet) for tweet in user_tweets])\n",
    "\n",
    "\n",
    "def std_dev_tweet_lengths(user_tweets):\n",
    "    tweet_lens = [len(tweet) for tweet in user_tweets]\n",
    "    return std_dev(\n",
    "        np.asarray(tweet_lens),\n",
    "        np.mean(tweet_lens),\n",
    "    )\n",
    "\n",
    "\n",
    "def cased_chars(user_tweets, cased):\n",
    "    return [\n",
    "        sum([c.isupper() if cased else c.islower() for c in tweet.text]) \n",
    "        for tweet in user_tweets\n",
    "    ]\n",
    "\n",
    "\n",
    "def emoji_chars(user_tweets):\n",
    "    return [len(demoji.findall_list(tweet.text)) for tweet in user_tweets]\n",
    "\n",
    "\n",
    "def punctuation_chars(user_tweets):\n",
    "    return [\n",
    "        len([c for c in tweet.text if c in punctuation]) \n",
    "        for tweet in user_tweets\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Iterable\n",
    "\n",
    "class TweetStatsExtractor:\n",
    "    def __init__(self, extractors):\n",
    "        if len(extractors) == 0:\n",
    "            raise Exception(\"Must pass at least one extracting function\")\n",
    "\n",
    "        self.extractors = extractors\n",
    "    \n",
    "    def transform(self, X, normalize_data=False):\n",
    "        result = []\n",
    "        for tweet_feed in X:\n",
    "            if len(self.extractors) > 1:\n",
    "                result.append(np.concatenate([self._apply(f, tweet_feed) for f in self.extractors]))\n",
    "            else:\n",
    "                result.append(self._apply(self.extractors[0], tweet_feed))\n",
    "        \n",
    "        return normalize(result) if normalize_data else result\n",
    "    \n",
    "    def _apply(self, extractor, data):\n",
    "        result = extractor(data)\n",
    "        if isinstance(result, Iterable):\n",
    "            return result\n",
    "        else:\n",
    "            return np.asarray([result])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, trange\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, accuracy_score, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_estimators = [LogisticRegression, SVC, RandomForestClassifier, GradientBoostingClassifier, KNeighborsClassifier]\n",
    "grid_search_param_grids = [\n",
    "    {\"Estimator__penalty\": [\"l1\", \"l2\"], \n",
    "     \"Estimator__C\": [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 768, 1024, 1280], \n",
    "     \"Estimator__solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\"]},\n",
    "    {\"Estimator__C\": [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 768, 1024, 1280], \n",
    "     \"Estimator__kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"], \n",
    "     \"Estimator__probability\": [True]},\n",
    "    {\"Estimator__n_estimators\": [25, 50, 100, 200, 400, 800], \n",
    "     \"Estimator__criterion\": [\"gini\", \"entropy\"], \n",
    "     \"Estimator__min_samples_leaf\": [1, 2, 4, 6, 8, 10, 12, 14, 16]},\n",
    "    {\"Estimator__loss\": [\"deviance\", \"exponential\"], \n",
    "     \"Estimator__learning_rate\": [0.01, 0.05, 0.1, 0.2], \n",
    "     \"Estimator__n_estimators\": [25, 50, 100, 200, 400, 800], \n",
    "     \"Estimator__min_samples_leaf\": [1, 2, 4, 6, 8, 10, 12, 14, 16]},\n",
    "    {\"Estimator__n_neighbors\": [2, 3, 4, 5, 6, 7, 8, 9, 10], \n",
    "     \"Estimator__weights\": [\"uniform\", \"distance\", ]},\n",
    "]\n",
    "\n",
    "def grid_search(X_train, y_train, X_val, y_val, estimators=grid_search_estimators, param_grids=grid_search_param_grids):\n",
    "    \"\"\" \n",
    "    Performs a GridSearchCV on the training data, and then evaluates using the validation data.\n",
    "    Uses a pipeline to find the best K features to use from the training data.\n",
    "    Returns a list of each estimator with their best parameters, as well as a dataframe containing \n",
    "    evaluation data.\n",
    "    \"\"\"\n",
    "    best_df = pd.DataFrame(columns=[\"Estimator\", \"K best features\", \"Mean CV Loss\", \"Mean CV F1\", \"Mean CV Accuracy\", \"Val Loss\", \"Val Precision\", \"Val Recall\", \"Val F1\", \"Val Accuracy\"])\n",
    "    best_params = []\n",
    "    ks = list(range(1, len(X_train[0])+1))\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_val = scaler.transform(X_val)\n",
    "    \n",
    "    for i, (estimator, param_grid) in tqdm(enumerate(zip(estimators, param_grids)), desc=\"Estimators\"):\n",
    "        # Perform a GridSearchCV\n",
    "        param_grid['SelectKBest__k'] = ks\n",
    "        search = GridSearchCV(\n",
    "            Pipeline([('SelectKBest', SelectKBest()), ('Estimator', estimator())]), \n",
    "            param_grid, \n",
    "            n_jobs=-1, \n",
    "            scoring={\n",
    "                \"accuracy\": make_scorer(accuracy_score), \n",
    "                \"f1\": make_scorer(f1_score, pos_label=\"1\"),\n",
    "                \"loss\": make_scorer(log_loss, greater_is_better=False, needs_proba=True),\n",
    "            }, \n",
    "            refit=\"loss\",\n",
    "        )\n",
    "        search.fit(X_train, y_train)\n",
    "        \n",
    "        # Collect results\n",
    "        best_index = search.cv_results_['params'].index(search.best_params_)\n",
    "        y_train_pred = search.predict(X_train)\n",
    "        y_val_pred = search.predict(X_val)\n",
    "        best_df.loc[i] = [estimator.__name__, \n",
    "                          search.best_params_['SelectKBest__k'], \n",
    "                          search.cv_results_['mean_test_loss'][best_index], \n",
    "                          search.cv_results_['mean_test_f1'][best_index],\n",
    "                          search.cv_results_['mean_test_accuracy'][best_index],\n",
    "                          log_loss(y_val, search.predict_proba(X_val)), \n",
    "                          precision_score(y_val, y_val_pred, pos_label=\"1\"),\n",
    "                          recall_score(y_val, y_val_pred, pos_label=\"1\"),\n",
    "                          f1_score(y_val, y_val_pred, pos_label=\"1\"),\n",
    "                          accuracy_score(y_val, y_val_pred)]\n",
    "        best_params.append((estimator.__name__, search.best_params_))\n",
    "    \n",
    "    return best_params, best_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical model\n",
    "* Extract statistical features from user tweets\n",
    "* \"An Ensemble Model Using N-grams and Statistical Features to Identify Fake News Spreaders on Twitter\" paper built a statistical model to support their N-gram model for this task (and won). \"FacTweet: Profiling Fake News Twitter Accounts\" used statistical information, such as emotions, style and sentiment to profile fake news spreading users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extractor functions (to be used in TweetStatsExtractor)\n",
    "def average_chars(user_tweets):\n",
    "    \"\"\" Returns the average tweet lengths, in characters, for the user \"\"\"\n",
    "    return average_tweet_lengths([tweet.text for tweet in user_tweets])\n",
    "\n",
    "\n",
    "def std_dev_chars(user_tweets):\n",
    "    \"\"\" Returns the standard deviations of tweet lengths, in characters, for the user \"\"\"\n",
    "    return std_dev_tweet_lengths([tweet.text for tweet in user_tweets])\n",
    "\n",
    "\n",
    "def average_words(user_tweets):\n",
    "    \"\"\" Returns the average tweet lengths, in words, for the user \"\"\"\n",
    "    return average_tweet_lengths(tweets_to_words(user_tweets))\n",
    "\n",
    "\n",
    "def std_dev_words(user_tweets):\n",
    "    \"\"\" Returns the standard deviations of tweet lengths, in words, for the user \"\"\"\n",
    "    return std_dev_tweet_lengths(tweets_to_words(user_tweets))\n",
    "\n",
    "\n",
    "def average_sentiment(user_tweets):\n",
    "    \"\"\" Returns the average sentiment scores of the user \"\"\"\n",
    "    return np.mean([polarity_scores(tweet.text) for tweet in user_tweets], axis=0)\n",
    "\n",
    "\n",
    "def std_dev_sentiment(user_tweets):\n",
    "    \"\"\" Returns the average sentiment scores of the user \"\"\"\n",
    "    sentiment = np.asarray([polarity_scores(tweet.text) for tweet in user_tweets])\n",
    "    return std_dev(sentiment, np.mean(sentiment, axis=0))\n",
    "\n",
    "\n",
    "def average_word_lengths(user_tweets):\n",
    "    \"\"\" Returns the average length of words used by this user \"\"\"\n",
    "    return np.mean([\n",
    "        len(word) \n",
    "        for tweet in user_tweets\n",
    "        for word in clean_text(tweet.text).split()\n",
    "    ])\n",
    "\n",
    "\n",
    "def average_tags(user_tweets, tags=['RT', '#USER#', '#HASHTAG#', '#URL#']):\n",
    "    \"\"\" Returns the average number of tags used by this user \"\"\"\n",
    "    return np.mean([\n",
    "        np.asarray([tweet.text.count(tag) for tag in tags])\n",
    "                   for tweet in user_tweets\n",
    "    ], axis=0)\n",
    "\n",
    "\n",
    "def average_cased_chars(user_tweets):\n",
    "    \"\"\" Returns the average number of cased (uppercase) characters per tweet, for the user \"\"\"\n",
    "    return np.mean(cased_chars(user_tweets, True))\n",
    "    \n",
    "\n",
    "def std_dev_cased_chars(user_tweets):\n",
    "    \"\"\" Returns the standard deviation of cased characters per tweet, for the user \"\"\"\n",
    "    return std_dev(cased_chars(user_tweets, True), average_cased_chars(user_tweets))\n",
    "    \n",
    "    \n",
    "def average_uncased_chars(user_tweets):\n",
    "    \"\"\" Returns the average number of uncased (lowercase) characters per tweet, for the user \"\"\"\n",
    "    return np.mean(cased_chars(user_tweets, False))\n",
    "\n",
    "\n",
    "def std_dev_uncased_chars(user_tweets):\n",
    "    \"\"\" Returns the standard deviation of cased characters per tweet, for the user \"\"\"\n",
    "    return std_dev(cased_chars(user_tweets, False), average_uncased_chars(user_tweets))\n",
    "\n",
    "    \n",
    "def average_emojis(user_tweets):\n",
    "    \"\"\" Returns the average number of emojis per tweet, for the user \"\"\"\n",
    "    return np.mean(emoji_chars(user_tweets))\n",
    "    \n",
    "    \n",
    "def std_dev_emojis(user_tweets):\n",
    "    \"\"\" Returns the standard deviation of emojis per tweet, for the user \"\"\"\n",
    "    return std_dev(emoji_chars(user_tweets), average_emojis(user_tweets))\n",
    "\n",
    "\n",
    "def average_punctuation_chars(user_tweets):\n",
    "    \"\"\" Returns the average number of punctuation characters per tweet, for the user \"\"\"\n",
    "    return np.mean(punctuation_chars(user_tweets))\n",
    "\n",
    "    \n",
    "def std_dev_punctuation_chars(user_tweets):\n",
    "    \"\"\" Returns the standard deviation of punctuation characters emojis per tweet, for the user \"\"\"\n",
    "    return std_dev(punctuation_chars(user_tweets), average_punctuation_chars(user_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats data\n",
    "stats_extractor = TweetStatsExtractor(extractors=[\n",
    "    average_chars,\n",
    "    std_dev_chars,\n",
    "    average_words,\n",
    "    std_dev_words,\n",
    "    average_word_lengths,\n",
    "    average_cased_chars,\n",
    "    std_dev_cased_chars,\n",
    "    average_uncased_chars,\n",
    "    std_dev_uncased_chars,\n",
    "    average_emojis,\n",
    "    std_dev_emojis,\n",
    "    average_punctuation_chars,\n",
    "    std_dev_punctuation_chars,\n",
    "    average_tags,\n",
    "    average_sentiment,\n",
    "    std_dev_sentiment,\n",
    "])\n",
    "tweet_stats_train = stats_extractor.transform(tweet_train)\n",
    "tweet_stats_val = stats_extractor.transform(tweet_val)\n",
    "tweet_stats_test = stats_extractor.transform(tweet_test)\n",
    "\n",
    "feature_names = [\n",
    "    \"Average number of characters per tweet\",\n",
    "    \"Standard deviation of characters per tweet\",\n",
    "    \"Average number of words per tweet\",\n",
    "    \"Standard deviation of words per tweet\",\n",
    "    \"Average word lengths\",\n",
    "    \"Average number of cased characters per tweet\",\n",
    "    \"Standard deviation of cased characters per tweet\",\n",
    "    \"Average number of uncased characters per tweet\",\n",
    "    \"Standard deviation of uncased characters per tweet\",\n",
    "    \"Average number of emojis per tweet\",\n",
    "    \"Standard deviation of emojis per tweet\",\n",
    "    \"Average number of punctuation characters per tweet\",\n",
    "    \"Standard deviation number of punctuation characters per tweet\",\n",
    "    \"Average number of 'RT' tags per tweet\",\n",
    "    \"Average number of '#USER#' tags per tweet\",\n",
    "    \"Average number of '#HASHTAG#' tags per tweet\",\n",
    "    \"Average number of '#URL#' tags per tweet\",\n",
    "    \"Average positive sentiment per tweet\",\n",
    "    \"Average neutral sentiment per tweet\",\n",
    "    \"Average negative sentiment per tweet\",\n",
    "    \"Standard deviation positive sentiment per tweet\",\n",
    "    \"Standard deviation neutral sentiment per tweet\",\n",
    "    \"Standard deviation negative sentiment per tweet\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the best Classifier\n",
    "* Classify users based on their (normalized) statistical features\n",
    "* Performing a grid search on: LogisticRegression, SVC, RandomForestClassifier, GradientBoostingClassifier, KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estimators: 3it [32:12, 517.89s/it]c:\\users\\joshh\\desktop\\uni\\soton uni - yr 3\\comp3200\\fake-news-profiling\\venv\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "Estimators: 5it [1:24:46, 1017.25s/it]\n"
     ]
    }
   ],
   "source": [
    "stats_search_best_params, stats_search_df = grid_search(tweet_stats_train, label_train, tweet_stats_val, label_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LogisticRegression',\n",
       "  {'Estimator__C': 0.5,\n",
       "   'Estimator__penalty': 'l2',\n",
       "   'Estimator__solver': 'liblinear',\n",
       "   'SelectKBest__k': 18}),\n",
       " ('SVC',\n",
       "  {'Estimator__C': 2,\n",
       "   'Estimator__kernel': 'sigmoid',\n",
       "   'Estimator__probability': True,\n",
       "   'SelectKBest__k': 23}),\n",
       " ('RandomForestClassifier',\n",
       "  {'Estimator__criterion': 'gini',\n",
       "   'Estimator__min_samples_leaf': 1,\n",
       "   'Estimator__n_estimators': 50,\n",
       "   'SelectKBest__k': 21}),\n",
       " ('GradientBoostingClassifier',\n",
       "  {'Estimator__learning_rate': 0.1,\n",
       "   'Estimator__loss': 'deviance',\n",
       "   'Estimator__min_samples_leaf': 14,\n",
       "   'Estimator__n_estimators': 25,\n",
       "   'SelectKBest__k': 18}),\n",
       " ('KNeighborsClassifier',\n",
       "  {'Estimator__n_neighbors': 10,\n",
       "   'Estimator__weights': 'distance',\n",
       "   'SelectKBest__k': 20})]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_search_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimator</th>\n",
       "      <th>K best features</th>\n",
       "      <th>Mean CV Loss</th>\n",
       "      <th>Mean CV F1</th>\n",
       "      <th>Mean CV Accuracy</th>\n",
       "      <th>Val Loss</th>\n",
       "      <th>Val Precision</th>\n",
       "      <th>Val Recall</th>\n",
       "      <th>Val F1</th>\n",
       "      <th>Val Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.636867</td>\n",
       "      <td>0.693448</td>\n",
       "      <td>0.680952</td>\n",
       "      <td>0.569532</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.755556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.602159</td>\n",
       "      <td>0.663741</td>\n",
       "      <td>0.647619</td>\n",
       "      <td>0.619748</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>21</td>\n",
       "      <td>-0.606469</td>\n",
       "      <td>0.677937</td>\n",
       "      <td>0.695238</td>\n",
       "      <td>0.590736</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.622222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.619664</td>\n",
       "      <td>0.636515</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.571609</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.682927</td>\n",
       "      <td>0.711111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.810363</td>\n",
       "      <td>0.655348</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.559821</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Estimator K best features  Mean CV Loss  Mean CV F1  \\\n",
       "0          LogisticRegression              18     -0.636867    0.693448   \n",
       "1                         SVC              23     -0.602159    0.663741   \n",
       "2      RandomForestClassifier              21     -0.606469    0.677937   \n",
       "3  GradientBoostingClassifier              18     -0.619664    0.636515   \n",
       "4        KNeighborsClassifier              20     -0.810363    0.655348   \n",
       "\n",
       "   Mean CV Accuracy  Val Loss  Val Precision  Val Recall    Val F1  \\\n",
       "0          0.680952  0.569532       0.800000    0.695652  0.744186   \n",
       "1          0.647619  0.619748       0.677419    0.913043  0.777778   \n",
       "2          0.695238  0.590736       0.687500    0.478261  0.564103   \n",
       "3          0.642857  0.571609       0.777778    0.608696  0.682927   \n",
       "4          0.614286  0.559821       0.703704    0.826087  0.760000   \n",
       "\n",
       "   Val Accuracy  \n",
       "0      0.755556  \n",
       "1      0.733333  \n",
       "2      0.622222  \n",
       "3      0.711111  \n",
       "4      0.733333  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_search_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition Model\n",
    "* Extract user usage of named entities, and create a feature vector from counts of the different named entities\n",
    "* \"TakeLab at SemEval-2019 Task 4: Hyperpartisan News Detection\" paper used an NER counter feature to help classify hyperpartisan news. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "spacy_nlp = spacy.load(\"en_core_web_sm\")\n",
    "spacy_ner_labels = [\"PERSON\", \"NORP\", \"FAC\", \"ORG\", \"GPE\", \"LOC\", \"PRODUCT\", \"EVENT\", \"WORK_OF_ART\", \"LAW\", \n",
    "                    \"LANGUAGE\", \"DATE\", \"TIME\", \"PERCENT\", \"MONEY\", \"QUANTITY\", \"ORDINAL\", \"CARDINAL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def named_entities_count_array(user_tweets):\n",
    "    \"\"\" Extract the named entities from a users tweets, and return an array of counts for each entity \"\"\"\n",
    "    freq = dict.fromkeys(spacy_ner_labels, 0)\n",
    "    for tweet in user_tweets:\n",
    "        cleaned_tweet = clean_text(tweet.text, remove_tags=True)\n",
    "        tweet_ne = spacy_nlp(cleaned_tweet).ents\n",
    "        for entity in tweet_ne:\n",
    "            freq[entity.label_] += 1\n",
    "    \n",
    "    return np.asarray(list(freq.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract NER count arrays\n",
    "ner_stats_extractor = TweetStatsExtractor(extractors=[named_entities_count_array])\n",
    "\n",
    "tweet_ner_stats_train = ner_stats_extractor.transform(tweet_train)\n",
    "tweet_ner_stats_val = ner_stats_extractor.transform(tweet_val)\n",
    "tweet_ner_stats_test = ner_stats_extractor.transform(tweet_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the best Classifier\n",
    "* Classify users based on their (normalized) counts of named entitities in their text\n",
    "* Performing a grid search on: LogisticRegression, SVC, RandomForestClassifier, GradientBoostingClassifier, KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_search_best_params, ner_search_df = grid_search(tweet_ner_stats_train, label_train, tweet_ner_stats_val, label_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_search_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_search_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Readability Model\n",
    "* Determine user readability scores, and create a feature vector of these different scores\n",
    "* In \"A stylometric Inquiry into Hyperpartisan and Fake News\" paper, they used 10 readability scores to help classify hyperpartisan news. \"Automatic Detection of Fake News\" paper also used readability features, such as the number of characters, complex words, long words, number of syllables, word types, and number of paragraphs.\n",
    "\n",
    "Readability measurements:\n",
    "* Flesch Reading Ease - Scores how easy something is to read, using the idea that shorter words and sentences are easier to read. \n",
    "    * Looks a the number of total words to total sentences ratio and total syllables to total words ratio. \n",
    "    * Range: 0 - 121.22. \n",
    "    * Source: https://simple.wikipedia.org/wiki/Flesch_Reading_Ease\n",
    "* Flesch-Kincaid grade - Similar to the Flesch Reading Ease score, but used to give a grade level to the text.\n",
    "    * This score is less affected by words with 3+ syllables\n",
    "    * It's equation is almost identical to the Flesch Reading Ease score\n",
    "    * Source: https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests\n",
    "* SMOG Index - Estimates the years of education needed to understand some text.\n",
    "    * SMOG is the preferred measure of readability ofr healthcare material. It performed better than the Flesch-Kincaid grade.\n",
    "    * Multiplies the number of words with 3+ syllables by 30 / total number of sentences.\n",
    "    * Source: https://en.wikipedia.org/wiki/SMOG\n",
    "* Coleman-Liau Index - Scores some text by what (US) grade level the reader will have to be in.\n",
    "    * It calculated the average number of letters per 100 words, and the average number of sentences per 100 words.\n",
    "    * Source: https://en.wikipedia.org/wiki/Coleman%E2%80%93Liau_index\n",
    "* Automated Readability Index - Scores how understandable a text is. It produces an approximate representation fo the US grade level needed to comprehend it.\n",
    "    * It calculates the number of characters per words and number of words per sentences\n",
    "    * Source: https://en.wikipedia.org/wiki/Automated_readability_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readability_scores(user_tweets):\n",
    "    \"\"\" \n",
    "    Extract a list of average readability scores of a user, and a SMOG score for their \n",
    "    concatenated tweets.\n",
    "    \"\"\"\n",
    "    user_scores = []\n",
    "    user_cleaned_tweets = []\n",
    "    for tweet in user_tweets:\n",
    "        cleaned_tweet = clean_text(tweet.text, remove_punc=False, remove_digits=False, \n",
    "                                   remove_tags=True)\n",
    "        user_scores.append([\n",
    "            textstat.automated_readability_index(cleaned_tweet),\n",
    "            textstat.flesch_reading_ease(cleaned_tweet),\n",
    "            textstat.flesch_kincaid_grade(cleaned_tweet),\n",
    "            textstat.coleman_liau_index(cleaned_tweet),\n",
    "        ])\n",
    "        user_cleaned_tweets.append(cleaned_tweet)\n",
    "    \n",
    "    user_scores = np.mean(user_scores, axis=0)\n",
    "    smog_score = textstat.smog_index(\". \".join(user_cleaned_tweets))\n",
    "    return np.append(user_scores, smog_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract NER count arrays\n",
    "read_stats_extractor = TweetStatsExtractor(extractors=[readability_scores])\n",
    "\n",
    "tweet_read_stats_train = read_stats_extractor.transform(tweet_train)\n",
    "tweet_read_stats_val = read_stats_extractor.transform(tweet_val)\n",
    "tweet_read_stats_test = read_stats_extractor.transform(tweet_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_search_best_params, read_search_df = grid_search(\n",
    "    tweet_read_stats_train, label_train, tweet_read_stats_val, label_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_search_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_search_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining the Ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models():\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = load_models()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
