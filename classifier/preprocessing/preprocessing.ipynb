{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import string\n",
    "from xml.sax.saxutils import unescape\n",
    "\n",
    "import demoji\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetPreprocessor:\n",
    "    def __init__(self, preprocess_funcs=None):\n",
    "        \"\"\" Constructs a new TweetPreprocessor object, given a list of tweets. \"\"\"        \n",
    "        if preprocess_funcs is None:\n",
    "            self.preprocess_funcs = [\n",
    "                self.tag_indicators,\n",
    "                self.replace_xml_and_html,\n",
    "                self.replace_emojis,\n",
    "                self.remove_punctuation,\n",
    "                self.replace_tags,\n",
    "                self.remove_hashtag_chars,\n",
    "                self.replace_accented_chars,\n",
    "                self.remove_extra_spacing,\n",
    "            ]\n",
    "        else:\n",
    "            self.preprocess_funcs = preprocess_funcs\n",
    "\n",
    "    def preprocess(self, X):\n",
    "        \"\"\" Preprocess a dataset (array of arrays of Tweets)\"\"\"\n",
    "        self.preprocessed_X = [\n",
    "            [self._process_single_tweet(tweet.text) for tweet in tweet_feed] for tweet_feed in X\n",
    "        ]\n",
    "    \n",
    "    def _process_single_tweet(self, tweet):\n",
    "        \"\"\" Process a single tweet \"\"\"\n",
    "        for f in self.preprocess_funcs:\n",
    "            tweet = f(tweet)\n",
    "\n",
    "        return tweet\n",
    "    \n",
    "    # tag urls, hashtags, user mentions\n",
    "    def tag_indicators(self, tweet):\n",
    "        \"\"\" Replace URLs, hastags and user mentions with a tag (e.g. #HASHTAG#) \"\"\"\n",
    "        hashtags_tagged = re.sub(r\"#[^\\s]*\", \"#HASHTAG#\", tweet, flags=re.MULTILINE)\n",
    "        urls_tagged = re.sub(\n",
    "            r\"https?\\:\\/\\/[^\\s]*\", \"#URL#\", hashtags_tagged, flags=re.MULTILINE\n",
    "        )\n",
    "        users_tagged = re.sub(r\"@[^\\s]*\", \"#USER#\", urls_tagged, flags=re.MULTILINE)\n",
    "        return users_tagged\n",
    "\n",
    "    def replace_xml_and_html(self, tweet):\n",
    "        \"\"\" Replace XML encodings (&amp; &lt; &gt;) and HTML tags (<br>) \"\"\"\n",
    "        replace_xml = unescape(tweet)\n",
    "        replace_html = BeautifulSoup(replace_xml, features=\"lxml\").get_text()\n",
    "        return replace_html\n",
    "\n",
    "    def remove_punctuation(self, tweet):\n",
    "        \"\"\" Remove punctuation, except hashtags '#' \"\"\"\n",
    "        punc = set(string.punctuation)\n",
    "        prin = set(string.printable)\n",
    "        punc.remove(\"#\")\n",
    "        return \"\".join(c for c in tweet if c not in punc and c in prin)\n",
    "\n",
    "    def replace_emojis(self, tweet):\n",
    "        \"\"\" Replace emojis with their meaning ':smiling_face:' \"\"\"\n",
    "        return demoji.replace_with_desc(tweet, \":\")\n",
    "\n",
    "    def replace_tags(self, tweet):\n",
    "        \"\"\" Replace #HASHTAG# and #URL# #USER# with tags [tag] and [url], [user] \"\"\"\n",
    "        tweet = tweet.replace(\"#HASHTAG#\", \"[tag]\")\n",
    "        tweet = tweet.replace(\"#URL#\", \"[url]\")\n",
    "        tweet = tweet.replace(\"#USER#\", \"[user]\")\n",
    "        return tweet\n",
    "\n",
    "    def remove_hashtag_chars(self, tweet):\n",
    "        \"\"\" Remove hashtags '#' \"\"\"\n",
    "        return \"\".join(c for c in tweet if c != \"#\")\n",
    "\n",
    "    def replace_accented_chars(self, tweet):\n",
    "        \"\"\" Replace accented characters with their ASCII equivalent \"\"\"\n",
    "        return unidecode(tweet)\n",
    "\n",
    "    def remove_extra_spacing(self, tweet):\n",
    "        \"\"\" Remove extra spaces \"\"\"\n",
    "        return \" \".join(tweet.split())\n",
    "\n",
    "    def get_individual_tweets_dataset(self):\n",
    "        \"\"\" Returns an array of preprocessed individual tweets \"\"\"\n",
    "        return np.asarray(self.preprocessed_X)\n",
    "\n",
    "    def get_tweet_feed_dataset(self):\n",
    "        \"\"\" Concatenates all tweets in each feed \"\"\"\n",
    "        return np.asarray([\" \".join(tweet_feed) for tweet_feed in self.preprocessed_X])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
