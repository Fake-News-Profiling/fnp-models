{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Preprocessing\n",
    "Following: https://towardsdatascience.com/exploratory-data-analysis-for-natural-language-processing-ff0046ab3571"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>truth_value</th>\n",
       "      <th>tweet_1</th>\n",
       "      <th>tweet_2</th>\n",
       "      <th>tweet_3</th>\n",
       "      <th>tweet_4</th>\n",
       "      <th>tweet_5</th>\n",
       "      <th>tweet_6</th>\n",
       "      <th>tweet_7</th>\n",
       "      <th>tweet_8</th>\n",
       "      <th>...</th>\n",
       "      <th>tweet_91</th>\n",
       "      <th>tweet_92</th>\n",
       "      <th>tweet_93</th>\n",
       "      <th>tweet_94</th>\n",
       "      <th>tweet_95</th>\n",
       "      <th>tweet_96</th>\n",
       "      <th>tweet_97</th>\n",
       "      <th>tweet_98</th>\n",
       "      <th>tweet_99</th>\n",
       "      <th>tweet_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06ct0t68y1acizh9eow3g5rhancrppr8</td>\n",
       "      <td>1</td>\n",
       "      <td>Courteney Cox Recreates Classic Friends Scene ...</td>\n",
       "      <td>The Jonas Brothers Have Secret Concert Days Af...</td>\n",
       "      <td>Ariana Grande Sends Heartfelt Message to Her F...</td>\n",
       "      <td>7 of the Biggest Bombshells From Jordyn Woods'...</td>\n",
       "      <td>Fyre Festival's Andy King Spills New Details o...</td>\n",
       "      <td>Watch Travis Scott Take an Adorable Phone Call...</td>\n",
       "      <td>See What Tyler Henry Really Thinks About His K...</td>\n",
       "      <td>Kim Kardashian Says She Had ''One of the Best ...</td>\n",
       "      <td>...</td>\n",
       "      <td>It's Pauly D Like You've Never Seen Him Before...</td>\n",
       "      <td>Hailey Baldwin Sends Her ''Lover'' Justin Bieb...</td>\n",
       "      <td>You Won't Believe How Much Money Property Brot...</td>\n",
       "      <td>You Have to See Nicki Minaj's $450,000 Rolls-R...</td>\n",
       "      <td>How Maddie Poppe and Caleb Lee Hutchinson Are ...</td>\n",
       "      <td>What Do the Kids of the Grey's Anatomy Cast Th...</td>\n",
       "      <td>Inside Nikki Bella's Romantic Date Night With ...</td>\n",
       "      <td>How Justin Bieber Celebrated His 25th Birthday...</td>\n",
       "      <td>Matthew McConaughey's 3 Stylish Kids Make a Ra...</td>\n",
       "      <td>Royal Bartender! Kate Middleton Pours a Pint o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>071nxc49ihpd0jlfmvn2lghtayy3b5n9</td>\n",
       "      <td>0</td>\n",
       "      <td>Amber Smith “Kandy Halloween: Return of the Ha...</td>\n",
       "      <td>Kourtney Kardashian Reveals Scott Disick 'Chec...</td>\n",
       "      <td>Serena Williams Steps Out at the 2019 Met Gala...</td>\n",
       "      <td>See the campiest looks from 2019 Met Gala pink...</td>\n",
       "      <td>Trouble in Paradise? Kris Jenner and Corey Gam...</td>\n",
       "      <td>Bethenny Frankel Wants To Sell SkinnyGirl Beca...</td>\n",
       "      <td>Everything Kim Kardashian Has Said About Surro...</td>\n",
       "      <td>Kim Kardashian Confirms 4th Baby Not Here Yet ...</td>\n",
       "      <td>...</td>\n",
       "      <td>Michelle Williams Fuels Reconciliation Rumors ...</td>\n",
       "      <td>Dream Kardashian Flaunts Her Long Curly Locks ...</td>\n",
       "      <td>Charlize Theron Finally Addresses Her Rumored ...</td>\n",
       "      <td>Scott Disick Doesn’t Want To ‘Disrespect’ Sofi...</td>\n",
       "      <td>Kim Kardashian Lobbying for Systematic Change ...</td>\n",
       "      <td>Cardi B and Nicki Minaj Both Hit Met Gala Red ...</td>\n",
       "      <td>Jennifer Lopez and Alex Rodriguez Step Out for...</td>\n",
       "      <td>Jessie J Puts Her Misspelled Tattoo on Display...</td>\n",
       "      <td>Meghan Markle Gives Birth To Baby Boy! #URL#</td>\n",
       "      <td>Amy Schumer Cradles Up to Newborn Son Gene In ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09py5qescynpnnckmzueqzr2y49moh1o</td>\n",
       "      <td>0</td>\n",
       "      <td>Rachel Bilson Was Asked Point-Blank if She’s D...</td>\n",
       "      <td>Bill Hader and Rachel Bilson make red carpet d...</td>\n",
       "      <td>What Do The Stars Say About Rachel Bilson? (12...</td>\n",
       "      <td>Celebrities front row at NYFW 2020 - Page Six ...</td>\n",
       "      <td>Rachel Bilson dating Bill Hader? - Arizona Dai...</td>\n",
       "      <td>Bill Hader and Rachel Bilson Confirm Relations...</td>\n",
       "      <td>How Did Rachel Bilson and Bill Hader Meet? - Y...</td>\n",
       "      <td>Rachel Bilson’s Golden Highlights Made For The...</td>\n",
       "      <td>...</td>\n",
       "      <td>Rachel Bilson On Helping La Marca Prosecco Lau...</td>\n",
       "      <td>Now This Is an Unexpected Couple - The Cut #UR...</td>\n",
       "      <td>Love That O.C. Reunion Pic? Well, We've Got So...</td>\n",
       "      <td>Is Rachel Bilson Loved or Hated? New Analysis ...</td>\n",
       "      <td>Never Forget When Bill Hader Parodied Rachel B...</td>\n",
       "      <td>Bill Hader and Rachel Bilson made their red ca...</td>\n",
       "      <td>Rachel Bilson shops for home furnishings and g...</td>\n",
       "      <td>Hold Up, Are Rachel Bilson and Bill Hader a Co...</td>\n",
       "      <td>Bill Hader, Rachel Bilson continue to fuel rum...</td>\n",
       "      <td>New couple alert! Bill Hader takes Rachel Bils...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          author_id truth_value  \\\n",
       "0  06ct0t68y1acizh9eow3g5rhancrppr8           1   \n",
       "1  071nxc49ihpd0jlfmvn2lghtayy3b5n9           0   \n",
       "2  09py5qescynpnnckmzueqzr2y49moh1o           0   \n",
       "\n",
       "                                             tweet_1  \\\n",
       "0  Courteney Cox Recreates Classic Friends Scene ...   \n",
       "1  Amber Smith “Kandy Halloween: Return of the Ha...   \n",
       "2  Rachel Bilson Was Asked Point-Blank if She’s D...   \n",
       "\n",
       "                                             tweet_2  \\\n",
       "0  The Jonas Brothers Have Secret Concert Days Af...   \n",
       "1  Kourtney Kardashian Reveals Scott Disick 'Chec...   \n",
       "2  Bill Hader and Rachel Bilson make red carpet d...   \n",
       "\n",
       "                                             tweet_3  \\\n",
       "0  Ariana Grande Sends Heartfelt Message to Her F...   \n",
       "1  Serena Williams Steps Out at the 2019 Met Gala...   \n",
       "2  What Do The Stars Say About Rachel Bilson? (12...   \n",
       "\n",
       "                                             tweet_4  \\\n",
       "0  7 of the Biggest Bombshells From Jordyn Woods'...   \n",
       "1  See the campiest looks from 2019 Met Gala pink...   \n",
       "2  Celebrities front row at NYFW 2020 - Page Six ...   \n",
       "\n",
       "                                             tweet_5  \\\n",
       "0  Fyre Festival's Andy King Spills New Details o...   \n",
       "1  Trouble in Paradise? Kris Jenner and Corey Gam...   \n",
       "2  Rachel Bilson dating Bill Hader? - Arizona Dai...   \n",
       "\n",
       "                                             tweet_6  \\\n",
       "0  Watch Travis Scott Take an Adorable Phone Call...   \n",
       "1  Bethenny Frankel Wants To Sell SkinnyGirl Beca...   \n",
       "2  Bill Hader and Rachel Bilson Confirm Relations...   \n",
       "\n",
       "                                             tweet_7  \\\n",
       "0  See What Tyler Henry Really Thinks About His K...   \n",
       "1  Everything Kim Kardashian Has Said About Surro...   \n",
       "2  How Did Rachel Bilson and Bill Hader Meet? - Y...   \n",
       "\n",
       "                                             tweet_8  ...  \\\n",
       "0  Kim Kardashian Says She Had ''One of the Best ...  ...   \n",
       "1  Kim Kardashian Confirms 4th Baby Not Here Yet ...  ...   \n",
       "2  Rachel Bilson’s Golden Highlights Made For The...  ...   \n",
       "\n",
       "                                            tweet_91  \\\n",
       "0  It's Pauly D Like You've Never Seen Him Before...   \n",
       "1  Michelle Williams Fuels Reconciliation Rumors ...   \n",
       "2  Rachel Bilson On Helping La Marca Prosecco Lau...   \n",
       "\n",
       "                                            tweet_92  \\\n",
       "0  Hailey Baldwin Sends Her ''Lover'' Justin Bieb...   \n",
       "1  Dream Kardashian Flaunts Her Long Curly Locks ...   \n",
       "2  Now This Is an Unexpected Couple - The Cut #UR...   \n",
       "\n",
       "                                            tweet_93  \\\n",
       "0  You Won't Believe How Much Money Property Brot...   \n",
       "1  Charlize Theron Finally Addresses Her Rumored ...   \n",
       "2  Love That O.C. Reunion Pic? Well, We've Got So...   \n",
       "\n",
       "                                            tweet_94  \\\n",
       "0  You Have to See Nicki Minaj's $450,000 Rolls-R...   \n",
       "1  Scott Disick Doesn’t Want To ‘Disrespect’ Sofi...   \n",
       "2  Is Rachel Bilson Loved or Hated? New Analysis ...   \n",
       "\n",
       "                                            tweet_95  \\\n",
       "0  How Maddie Poppe and Caleb Lee Hutchinson Are ...   \n",
       "1  Kim Kardashian Lobbying for Systematic Change ...   \n",
       "2  Never Forget When Bill Hader Parodied Rachel B...   \n",
       "\n",
       "                                            tweet_96  \\\n",
       "0  What Do the Kids of the Grey's Anatomy Cast Th...   \n",
       "1  Cardi B and Nicki Minaj Both Hit Met Gala Red ...   \n",
       "2  Bill Hader and Rachel Bilson made their red ca...   \n",
       "\n",
       "                                            tweet_97  \\\n",
       "0  Inside Nikki Bella's Romantic Date Night With ...   \n",
       "1  Jennifer Lopez and Alex Rodriguez Step Out for...   \n",
       "2  Rachel Bilson shops for home furnishings and g...   \n",
       "\n",
       "                                            tweet_98  \\\n",
       "0  How Justin Bieber Celebrated His 25th Birthday...   \n",
       "1  Jessie J Puts Her Misspelled Tattoo on Display...   \n",
       "2  Hold Up, Are Rachel Bilson and Bill Hader a Co...   \n",
       "\n",
       "                                            tweet_99  \\\n",
       "0  Matthew McConaughey's 3 Stylish Kids Make a Ra...   \n",
       "1       Meghan Markle Gives Birth To Baby Boy! #URL#   \n",
       "2  Bill Hader, Rachel Bilson continue to fuel rum...   \n",
       "\n",
       "                                           tweet_100  \n",
       "0  Royal Bartender! Kate Middleton Pours a Pint o...  \n",
       "1  Amy Schumer Cradles Up to Newborn Son Gene In ...  \n",
       "2  New couple alert! Bill Hader takes Rachel Bils...  \n",
       "\n",
       "[3 rows x 102 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting and parsing the English dataset.\n",
    "from ipynb.fs.full.parse_datasets import parse_datasets_language\n",
    "\n",
    "data = parse_datasets_language(\"../datasets\", \"en\")\n",
    "all_tweets = pd.Series(data.iloc[:, 2:].values.flatten()) # pandas Series of all tweets\n",
    "\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of characters per tweet\n",
    "Below we can see that tweet length varies greatly, between 22 and 152 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 22 , Max: 152\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lengths = all_tweets.str.len()\n",
    "lengths.hist()\n",
    "print(\"Min:\", min(lengths), \", Max:\", max(lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of words per tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 6 , Max: 30\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = all_tweets.str.split().map(lambda x: len(x))\n",
    "words.hist()\n",
    "print(\"Min:\", min(words), \", Max:\", max(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import demoji\n",
    "from unidecode import unidecode\n",
    "from bs4 import BeautifulSoup\n",
    "from xml.sax.saxutils import unescape\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputPreprocessor:\n",
    "    def __init__(self, tweets, labels):\n",
    "        \"\"\"\n",
    "        Constructs a new InputPreprocessor object.\n",
    "        \n",
    "        :param tweets: A Pandas DataFrame where each row represents a tweet feed and columns \n",
    "        are labelled 'Tweet 1' to 'Tweet 100'.\n",
    "        :param labels: A Pandas Series of the Fake News labels, where each row corresponds to \n",
    "        the same indexed row in 'tweets'.\n",
    "        \"\"\"\n",
    "        self.tweets = tweets.copy()\n",
    "        self.labels = labels.copy()\n",
    "    \n",
    "    def preprocess(self):\n",
    "        # Replace XML encodings - &amp; &lt; &gt;\n",
    "        # Then remove HTML tags - <br>\n",
    "        def replace_xml_and_html(tweet):\n",
    "            replace_xml = unescape(tweet)\n",
    "            replace_html = BeautifulSoup(replace_xml).get_text()\n",
    "            return replace_html\n",
    "\n",
    "        # Remove punctuation, apart from '#'\n",
    "        def remove_punctuation(tweet):\n",
    "            punc = set(string.punctuation)\n",
    "            prin = set(string.printable)\n",
    "            punc.remove('#')\n",
    "            return ''.join(c for c in tweet if c not in punc and c in prin)\n",
    "\n",
    "        # Replace emojis with their meaning, e.g. :smiling_face:\n",
    "        def replace_emojis(tweet):\n",
    "            return demoji.replace_with_desc(tweet, ':')\n",
    "\n",
    "        # Replace #HASHTAG# and #URL# #USER# with tags [tag] and [url], [user]\n",
    "        def replace_tags(tweet):\n",
    "            tweet = tweet.replace('#HASHTAG#', '[tag]')\n",
    "            tweet = tweet.replace('#URL#', '[url]')\n",
    "            tweet = tweet.replace('#USER#', '[user]')\n",
    "            return tweet\n",
    "\n",
    "        # Remove '#'s\n",
    "        def remove_hashtag_chars(tweet):\n",
    "            return ''.join(c for c in tweet if c != '#')\n",
    "\n",
    "        def replace_accented_chars(tweet):\n",
    "            return unidecode(tweet)\n",
    "\n",
    "        def remove_extra_spacing(tweet):\n",
    "            return ' '.join(tweet.split())\n",
    "        \n",
    "        preprocess_funcs = [\n",
    "            replace_xml_and_html, \n",
    "            replace_emojis, \n",
    "            remove_punctuation,\n",
    "            replace_tags, \n",
    "            remove_hashtag_chars, \n",
    "            replace_accented_chars, \n",
    "            remove_extra_spacing\n",
    "        ]\n",
    "        \n",
    "        # Process a column of tweets\n",
    "        def process_col(col):\n",
    "            for i in range(len(col)):\n",
    "                col[i] = process_tweet(col[i])\n",
    "\n",
    "            return col\n",
    "        \n",
    "        # Process an individual tweet\n",
    "        def process_tweet(tweet):\n",
    "            for f in preprocess_funcs:\n",
    "                tweet = f(tweet)\n",
    "\n",
    "            return tweet\n",
    "        \n",
    "        self.tweets.apply(process_col)\n",
    "        \n",
    "    def to_individual_tweets_dataset(self):\n",
    "        \"\"\"\n",
    "        :return: train, validation, test numpy array splits of the dataset, where the tweet \n",
    "        columns have been joined to create one column, and the labels expanded to match this.\n",
    "        \"\"\"\n",
    "        tweets = np.asarray([tweet for row in self.tweets.values for tweet in row])\n",
    "        labels = np.asarray([label for label in self.labels.values for i in range(100)])\n",
    "        return self.split_dataset(tweets, labels)\n",
    "    \n",
    "    def to_tweet_feed_dataset(self):\n",
    "        \"\"\"\n",
    "        :return: train, validation, test numpy array splits of the dataset, where all of the \n",
    "        tweets for each user have been concatenated into one string.\n",
    "        \"\"\"\n",
    "        tweets = np.asarray(self.tweets.agg(' '.join, axis=1))\n",
    "        labels = np.asarray(self.labels)\n",
    "        return self.split_dataset(tweets, labels)\n",
    "    \n",
    "    def split_dataset(self, tweets, labels):\n",
    "        tweet_train, tweet_other, label_train, label_other = \\\n",
    "            train_test_split(tweets, labels, test_size=0.3)\n",
    "        tweet_val, tweet_test, label_val, label_test = \\\n",
    "            train_test_split(tweet_other, label_other, test_size=0.5)\n",
    "        \n",
    "        return (tweet_train, label_train, tweet_val, label_val, tweet_test, label_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing for BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from official.nlp.bert import tokenization\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertModel():\n",
    "    def __init__(self, encoder_url, bert_input_size, encoding):\n",
    "        # Get BERT encoder and tokenizer\n",
    "        self.encoder = hub.KerasLayer(encoder_url, trainable=True)\n",
    "        self.bert_input_size = bert_input_size\n",
    "        self.encoding = encoding\n",
    "        self.tokenizer = tokenization.FullTokenizer(\n",
    "            self.encoder.resolved_object.vocab_file.asset_path.numpy(), \n",
    "            do_lower_case=self.encoder.resolved_object.do_lower_case.numpy())\n",
    "        \n",
    "    def compile(self, optimizer, loss, metrics):\n",
    "        inputs = self.compile_inputs()\n",
    "        \n",
    "        # Get the BERT pooled output\n",
    "        encoder_pooled_output = self.encoder(inputs)['pooled_output']\n",
    "        \n",
    "        # Get the Dense layer output\n",
    "        dense_output = Dense(1, activation='sigmoid')(encoder_pooled_output)\n",
    "        \n",
    "        # Create the Keras model and compile\n",
    "        self.model = Model(inputs, dense_output)\n",
    "        self.model.compile(optimizer, loss, metrics)\n",
    "    \n",
    "    def compile_inputs(self):\n",
    "        # Create BERT Input layers\n",
    "        def input_layer(input_name):\n",
    "            return Input(shape=(self.bert_input_size,), dtype=tf.int32, name=input_name)\n",
    "        \n",
    "        return dict(\n",
    "            input_word_ids=input_layer(\"inputs/input_word_ids\"),\n",
    "            input_mask=input_layer(\"inputs/input_mask\"),\n",
    "            input_type_ids=input_layer(\"inputs/input_type_ids\"))\n",
    "    \n",
    "    # Removes the Dense output layer - TODO - check that this keeps the weights of the trained model.\n",
    "    def to_plain_bert_model(self):\n",
    "        inputs = self.compile_inputs()\n",
    "        encoder_pooled_output = self.encoder(inputs)['pooled_output']\n",
    "        self.model = Model(inputs, encoder_pooled_output)\n",
    "    \n",
    "    def to_test(self):\n",
    "        inputs = self.compile_inputs()\n",
    "        encoder_pooled_output = self.encoder(inputs)\n",
    "        self.model = Model(inputs, encoder_pooled_output)\n",
    "        \n",
    "    def fit(self, x, y, batch_size=None, epochs=1, callbacks=None, validation_data=None):\n",
    "        print('Encoding input data')\n",
    "        x_encoded, y_encoded = self.encode_input(x), self.encode_labels(y)\n",
    "        \n",
    "        if (validation_data != None):\n",
    "            validation_data = (\n",
    "                self.encode_input(validation_data[0]), \n",
    "                self.encode_labels(validation_data[1]))\n",
    "        \n",
    "        print('Fitting BERTModel')\n",
    "        return self.model.fit(\n",
    "            x=x_encoded, \n",
    "            y=y_encoded, \n",
    "            batch_size=batch_size, \n",
    "            epochs=epochs,\n",
    "            callbacks=callbacks,\n",
    "            validation_data=validation_data)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        print('Predicting using BERTModel')\n",
    "        \n",
    "        if (self.encoding == 'individual'):\n",
    "            # TODO - unsure if this is correct.\n",
    "            x_encoded = self.encode_input(x)\n",
    "            return self.model.predict(x_encoded)\n",
    "        \n",
    "        elif (self.encoding == 'feed'):\n",
    "            result = []\n",
    "            for tweet_feed in x:\n",
    "                x_encoded = self.encode_input([tweet_feed])\n",
    "                prediction = self.model.predict(x_encoded)\n",
    "                result.append(prediction)\n",
    "            \n",
    "            # Returns (n, k, 768) array, where k is the number of chunks (variable),\n",
    "            # n is the number of tweet feeds (input size), and 768 is BERT's hidden layer size.\n",
    "            return np.asarray(result)\n",
    "\n",
    "    def evaluate(self, x, y, batch_size=32):\n",
    "        x_encoded, y_encoded = self.encode_input(x), self.encode_labels(y)\n",
    "        return self.model.evaluate(\n",
    "            x_encoded, \n",
    "            y_encoded, \n",
    "            batch_size)\n",
    "    \n",
    "    def encode_input(self, x): # x should always be a list or array!\n",
    "        # Encode tweets\n",
    "        def encode_tweet(tweet):\n",
    "            tokens = self.tokenizer.tokenize(tweet)[:self.bert_input_size-2]\n",
    "            tokens.append('[SEP]')\n",
    "            tokens.insert(0, '[CLS]')\n",
    "            return self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "        \n",
    "        # Encode tweet feed into chunks\n",
    "        def encode_tweet_feed(tweet_feed):\n",
    "            feed_tokens = self.tokenizer.tokenize(tweet_feed)\n",
    "            tokens = [feed_tokens[i:i+self.bert_input_size-2]\n",
    "                      for i in range(0, len(feed_tokens), self.bert_input_size-52)]\n",
    "#             tokens[-1] = feed_tokens[len(feed_tokens)-self.bert_input_size+2:len(feed_tokens)] # Remove? - fills the last chunk\n",
    "            \n",
    "            def encode_tokens(tokens):\n",
    "                tokens.append('[SEP]')\n",
    "                tokens.insert(0, '[CLS]')\n",
    "                return self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "            \n",
    "            return list(map(encode_tokens, tokens))\n",
    "        \n",
    "        if (self.encoding == 'individual'):\n",
    "            input_word_ids = tf.ragged.constant([encode_tweet(tweet) for tweet in x])\n",
    "            \n",
    "        elif (self.encoding == 'feed'):\n",
    "            encoded_tweet_feed = [encode_tweet_feed(tweet_feed) for tweet_feed in x]\n",
    "            input_word_ids = tf.ragged.constant(\n",
    "                [tweet for tweet_feed in encoded_tweet_feed for tweet in tweet_feed])\n",
    "            self.y_pattern = [len(tweet_feed) for tweet_feed in encoded_tweet_feed]\n",
    "        \n",
    "        input_mask = tf.ones_like(input_word_ids)\n",
    "        \n",
    "        # Pad word_ids and mask\n",
    "        input_word_ids = input_word_ids.to_tensor()\n",
    "        input_mask = input_mask.to_tensor()\n",
    "        \n",
    "        padding = tf.constant([[0, 0,], [0, (self.bert_input_size - input_mask.shape[1])]])\n",
    "        input_word_ids = tf.pad(input_word_ids, padding, \"CONSTANT\")\n",
    "        input_mask = tf.pad(input_mask, padding, \"CONSTANT\")\n",
    "        \n",
    "        input_type_ids = tf.zeros_like(input_mask)\n",
    "        \n",
    "        # Return encoded inputs\n",
    "        x_encoded = dict(\n",
    "            input_word_ids=input_word_ids,\n",
    "            input_mask=input_mask,\n",
    "            input_type_ids=input_type_ids)\n",
    "    \n",
    "        return x_encoded\n",
    "    \n",
    "    def encode_labels(self, y):\n",
    "        if (self.encoding == 'individual'):\n",
    "            return tf.convert_to_tensor(y, tf.int32)\n",
    "        elif (self.encoding == 'feed'):\n",
    "            return tf.convert_to_tensor(\n",
    "                [int(v) for v,n in zip(y, self.y_pattern) for i in range(n)], \n",
    "                tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a BertModel object\n",
    "bert_model = BertModel(\n",
    "    \"https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3\",\n",
    "    500,\n",
    "    \"feed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model optimizer=Adam(lr=1e-5), loss='binary_crossentropy', metrics=['accuracy']\n",
    "bert_model.compile(Adam(lr=1e-5), 'binary_crossentropy', ['accuracy'])\n",
    "\n",
    "# Set the checkpoint path for saving/loading weights\n",
    "checkpoint_path = \"training/bert_training_1/cp.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2d90dc0ac10>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the models saved weights\n",
    "bert_model.model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs/input_mask (InputLayer)  [(None, 500)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inputs/input_type_ids (InputLay [(None, 500)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inputs/input_word_ids (InputLay [(None, 500)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer (KerasLayer)        {'default': (None, 7 108310273   inputs/input_mask[0][0]          \n",
      "                                                                 inputs/input_type_ids[0][0]      \n",
      "                                                                 inputs/input_word_ids[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            769         keras_layer[0][13]               \n",
      "==================================================================================================\n",
      "Total params: 108,311,042\n",
      "Trainable params: 108,311,041\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert_model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the input dataset in tweet-feed format\n",
    "data_copy = data.copy()\n",
    "\n",
    "data_preprocessor = InputPreprocessor(data_copy.iloc[:, 2:], data_copy.iloc[:, 1])\n",
    "data_preprocessor.preprocess()\n",
    "\n",
    "tweet_train, label_train, tweet_val, label_val, tweet_test, label_test = \\\n",
    "    data_preprocessor.to_tweet_feed_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a checkpoint for training BERTModel\n",
    "bert_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model.to_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting using BERTModel\n"
     ]
    }
   ],
   "source": [
    "res = bert_model.predict([tweet_test[1]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default <class 'numpy.ndarray'>\n",
      "encoder_outputs <class 'list'>\n",
      "pooled_output <class 'numpy.ndarray'>\n",
      "sequence_output <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "for k,v in res.items():\n",
    "    print(k, type(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence_output (5, 500, 768)\n",
      "pooled_output (5, 768)\n",
      "default (5, 768)\n",
      "encoder_outputs 12\n"
     ]
    }
   ],
   "source": [
    "print(\"sequence_output\", res['sequence_output'].shape)\n",
    "print(\"pooled_output\", res['pooled_output'].shape)\n",
    "print(\"default\", res['default'].shape)\n",
    "print(\"encoder_outputs\", len(res['encoder_outputs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding input data\n",
      "Fitting BERTModel\n",
      "Epoch 1/5\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.6883 - accuracy: 0.5878  \n",
      "Epoch 00001: saving model to training/bert_training_1\\cp.ckpt\n",
      "62/62 [==============================] - 4397s 71s/step - loss: 0.6883 - accuracy: 0.5878 - val_loss: 0.6342 - val_accuracy: 0.6604\n",
      "Epoch 2/5\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.5318 - accuracy: 0.7309  \n",
      "Epoch 00002: saving model to training/bert_training_1\\cp.ckpt\n",
      "62/62 [==============================] - 4366s 70s/step - loss: 0.5318 - accuracy: 0.7309 - val_loss: 0.6193 - val_accuracy: 0.6566\n",
      "Epoch 3/5\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.3862 - accuracy: 0.8423  \n",
      "Epoch 00003: saving model to training/bert_training_1\\cp.ckpt\n",
      "62/62 [==============================] - 4359s 70s/step - loss: 0.3862 - accuracy: 0.8423 - val_loss: 0.6692 - val_accuracy: 0.6755\n",
      "Epoch 4/5\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.2510 - accuracy: 0.9033  \n",
      "Epoch 00004: saving model to training/bert_training_1\\cp.ckpt\n",
      "62/62 [==============================] - 4303s 69s/step - loss: 0.2510 - accuracy: 0.9033 - val_loss: 0.7159 - val_accuracy: 0.7245\n",
      "Epoch 5/5\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.1589 - accuracy: 0.9390  \n",
      "Epoch 00005: saving model to training/bert_training_1\\cp.ckpt\n",
      "62/62 [==============================] - 4352s 70s/step - loss: 0.1589 - accuracy: 0.9390 - val_loss: 0.7917 - val_accuracy: 0.7208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22b0f8c8ac0>"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit BERTModel using the training and validation data\n",
    "# bert_model.fit(\n",
    "#     x=tweet_train, \n",
    "#     y=label_train, \n",
    "#     batch_size=20, \n",
    "#     epochs=5, \n",
    "#     callbacks=[bert_checkpoint_callback],\n",
    "#     validation_data=(tweet_val, label_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 158s 11s/step - loss: 0.8744 - accuracy: 0.7088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.874427080154419, 0.7088122367858887]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the BERT Model on the test set\n",
    "bert_model.evaluate(tweet_test, label_test, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting using BERTModel\n"
     ]
    }
   ],
   "source": [
    "pred = bert_model.predict(tweet_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications = [(0 if i.mean() < 0.5 else 1) for i in pred]\n",
    "\n",
    "tp, fn, tn, fp = 0, 0, 0, 0\n",
    "for c,p in zip(classifications, tf.convert_to_tensor(label_test, tf.int32)):\n",
    "    if (c == 0 and p == 0):\n",
    "        tp += 1\n",
    "    elif (c == 1 and p == 0):\n",
    "        fn += 1\n",
    "    elif (c == 1 and p == 1):\n",
    "        tn += 1\n",
    "    elif (c == 0 and p == 1):\n",
    "        fp += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6888888888888889\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", (tp+tn)/(tp+tn+fp+fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output from BERTModel is max-pooled (max taken of each column)\n",
    "# Then put into a Dense layer with Sigmoid applied\n",
    "class BertMaxPoolingModel():\n",
    "    def __init__(self, bert_model, bert_checkpoint_path=None):\n",
    "        self.bert_model = bert_model\n",
    "        self.bert_model.to_plain_bert_model()\n",
    "        if (bert_checkpoint_path != None):\n",
    "            self.bert_model.model.load_weights(bert_checkpoint_path)\n",
    "    \n",
    "    def compile(self, optimizer, loss, metrics):\n",
    "        bert_output_len = self.bert_model.model.layers[-1].output_shape['pooled_output'][1]\n",
    "        encoder_pooled_output = Input(\n",
    "            shape=(bert_output_len, ), \n",
    "            dtype=tf.int32,\n",
    "            name='Max_pooling_out')\n",
    "        \n",
    "        # Dense layer is 768 (input) to 1 (output)\n",
    "        dense_output = Dense(1, activation='sigmoid')(encoder_pooled_output)\n",
    "        \n",
    "        # Create the Keras model and compile\n",
    "        self.model = Model(encoder_pooled_output, dense_output)\n",
    "        self.model.compile(optimizer, loss, metrics)\n",
    "        \n",
    "#     Model just consists of a Dense layer which applies a sigma function, so there are no weights to fit\n",
    "#     def fit(self, x, y, batch_size, epochs, validation_data=None):\n",
    "#         x_encoded, y_encoded = self.encode_x_y_inputs(x, y)\n",
    "        \n",
    "#         if (validation_data != None):\n",
    "#             validation_data = self.encode_x_y_inputs(\n",
    "#                 validation_data[0], validation_data[1])\n",
    "        \n",
    "#         print('Fitting BERTMaxPoolingModel')\n",
    "#         return self.model.fit(\n",
    "#             x_encoded, \n",
    "#             y_encoded,\n",
    "#             batch_size,\n",
    "#             epochs,\n",
    "#             validation_data=validation_data)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        print('Getting BERTModel prediction and encoding input data')\n",
    "        x_encoded = self.max_pool_bert_prediction(x)\n",
    "        \n",
    "        print('Predicting input data for BERTMaxPoolingModel')\n",
    "        return self.model.predict(x_encoded)\n",
    "    \n",
    "    def evaluate(self, x, y, batch_size=32):\n",
    "        x_encoded, y_encoded = self.encode_x_y_inputs(x, y)\n",
    "        return self.model.evaluate(\n",
    "            x_encoded, \n",
    "            y_encoded, \n",
    "            batch_size)\n",
    "    \n",
    "    def encode_x_y_inputs(self, x, y):\n",
    "        print('Getting BERTModel prediction and encoding input data')\n",
    "        x_encoded = self.max_pool_bert_prediction(x)\n",
    "        y_encoded = tf.convert_to_tensor(y, tf.int32)\n",
    "        return x_encoded, y_encoded\n",
    "    \n",
    "    def max_pool_bert_prediction(self, x):\n",
    "        bert_pooled_output = self.bert_model.predict(x)\n",
    "        # Reduce bert_pooled_output of shape (n, k, 768) to (n, 768)\n",
    "        return np.asarray([np.maximum.reduce(e, 0) for e in bert_pooled_output])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_max_pooling_model = BertMaxPoolingModel(bert_model)\n",
    "bert_max_pooling_model.compile(Adam(lr=1e-5), 'binary_crossentropy', ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_99\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Max_pooling_out (InputLayer) [(None, 768)]             0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 769       \n",
      "=================================================================\n",
      "Total params: 769\n",
      "Trainable params: 769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert_max_pooling_model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting BERTModel prediction and encoding input data\n",
      "Predicting using BERTModel\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6947 - accuracy: 0.4000WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_begin` time: 0.0010s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_begin` time: 0.0010s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6995 - accuracy: 0.3778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6995384693145752, 0.3777777850627899]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_max_pooling_model.evaluate(tweet_test, label_test, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
